{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1CkFQVsf7hBV"
   },
   "source": [
    "# Notebook 9 - GANs pour la génération de chiffres MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J5PCrI7a7hBW"
   },
   "source": [
    "CSI4506 Intelligence Artificielle   \n",
    "Automne 2021  \n",
    "Version 1 (2020) preparée par Julian Templeton, Caroline Barrière et Joel Muteba.  Version 2 (2021) mise à jour par Caroline Barrière."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Edd5V5Zy7hBW"
   },
   "source": [
    "***INTRODUCTION (Lisez ceci attentivement!)***:\n",
    "\n",
    "Avec la résurgence de l'apprentissage profond (Deep Learning) et des architectures d'apprentissage profond (Deep Learning Architectures, DLA) en raison de la puissance accrue de l'informatique moderne, il existe une multitude de façons dont les DLAs peuvent être utilisés pour s'attaquer à pratiquement tous les types de problèmes (la reconnaissance faciale, les prévisions boursières, la génération d'images, ...).\n",
    "\n",
    "L'IA générative, avec sa génération de fausses images, vidéos, musique et textes (ex: poèmes), est un sujet d'intérêt dans la société. L'IA générative peut avoir des applications pratiques, pensons par exemple à l'illustration automatique de textes pour l'apprentissage, mais cette IA peut également avoir des implications éthiques importantes. \n",
    "\n",
    "D'un point de vue technologique, l'IA générative, telle que possible à l'aide de DLAs, peut être facilement implémentée grâce à l'utilisation de bibliothèques Python Deep Learning telles que [PyTorch](https://pytorch.org/), [TensorFlow](https://www.tensorflow.org/) et [Keras](https://keras.io/). Cela dit, bien qu'il soit possible de trouver de nombreux exemples d'utilisation de ces DLAs, ils nécessitent toujours une immense puissance de calcul pour fournir des résultats de façon efficace, et comme vous pourrez le constater dans ce Notebook, ils peuvent donner des résultats variables s'il n'y a pas un effort notable de \"fine-tuning\" d'hyperparamètres (ce qui peut prendre beaucoup de temps).\n",
    "\n",
    "Dans ce notebook, nous explorerons une tâche commune de génération d'images grâce à l'utilisation d'un réseau antagoniste génératif (GAN). En commençant par des images générées aléatoirement comme celle-ci    \n",
    "\n",
    "\n",
    "![RandomNoise.png](data:image/png;base64,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)     \n",
    "\n",
    "le GAN apprendra à générer des images de chiffres comme celle-ci (dans cette image, ce chiffre est '1')\n",
    "\n",
    "![ExampleDigit.png](data:image/png;base64,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)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UwLPh9L1fJrF"
   },
   "source": [
    "Il existe de nombreux types de GAN, chacun avec des avantages et des inconvénients différents. Dans ce notebook, nous travaillerons avec un DCGAN (Deep Convolutional GAN). Un DCGAN est similaire à un GAN, mais introduit des couches convolutives dans son réseau pour augmenter les performances. Les couches convolutives sont couramment utilisées dans les réseaux de neurones convolutifs, ainsi le DCGAN utilisera ce type de couches dans le design du générateur et du discriminateur. Pour passer en revue ces concepts, vous pouvez regarder la vidéo facultative dans le module 6 sur Brightspace pour en savoir plus sur les couches convolutives dans les réseaux de neurones convolutifs (CNN).\n",
    "\n",
    "Comme évoqué ci-dessus, les DLAs tels que les GAN nécessitent un immense traitement de calcul. Cela nécessite généralement une carte graphique haut de gamme, comme les dernières cartes de NVIDIA (qui fournissent des outils, tels que [CUDA](https://developer.nvidia.com/cuda-zone) pour permettre l'exécution du code sur le GPU pour un traitement rapide). Étant donné que nous ne pouvons pas nous attendre à ce que vous ayez une carte graphique ou que vous passiez le temps à attendre qu'un processeur effectue les calculs, nous utiliserons un environnement Jupyter gratuit basé sur le cloud fourni par Google. [Google Colab](https://colab.research.google.com/) est un environnement jupyter gratuit basé sur le cloud, idéal pour effectuer des expériences d'apprentissage profond, car il permet d'accéder à des cartes graphiques très puissantes (qui ont limites, mais celles-ci ne devraient pas se produire pendant la durée de ce notebook). Ces limites incluent les contraintes de temps et les limitations de mémoire qui peuvent se produire si nous exécutons un algorithme d'entraînement pendant trop d'époques ou si nous concevons un modèle qui a trop de nœuds cachés. \n",
    "\n",
    "L'environnement colab est prévu pour des usages interactifs, ainsi, attention de ne pas laisser votre notebook \"idle\" trop longtemps, car cela pourrait mener à des coupures d'accès aux GPUs.\n",
    "\n",
    "Beaucoup d'entre vous sont déjà passés à Colab pour l'exécution des notebooks précédents, peut-être en raison de problèmes d'installation sur votre ordinateur personnel. Si vous avez déjà changé, vous savez déjà comment utiliser Colab. Si vous n'avez pas encore changé, vous devez absolument utiliser Colab pour ce notebook, à moins que vous n'ayez vos propres GPU à la maison.\n",
    "\n",
    "Contrairement aux notebooks précédents, ce notebook se concentrera sur l'exploration d'idées et l'analyse des résultats car il serait au-delà de la portée de notre cours d'introduction d'apprendre une nouvelle bibliothèque complexe et de programmer un modèle complexe d'apprentissage profond avec elle.\n",
    "\n",
    "Ce notebook est basé sur [l'exemple officiel de TensorFlow de création d'un DCGAN](https://www.tensorflow.org/tutorials/generative/dcgan). Le code utilisé ici est inspiré de l'exemple et adapté pour optimiser les performances et fonctionner dans Google Colab. Ainsi, notez que le code utilisé ici provient de cet exemple avec des modifications si nécessaire.\n",
    "\n",
    "**Lors de la soumission de ce notebook, assurez-vous de NE PAS réinitialiser les sorties de l'exécution du code (et n'oubliez pas de sauvegarder le notebook avec ctrl + s).**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JdkrlU777hBX"
   },
   "source": [
    "***DEVOIR***:\n",
    "\n",
    "Parcourez le notebook en exécutant chaque cellule, une à la fois. \\\n",
    "\n",
    "Recherchez **(TO DO)** pour les tâches que vous devez effectuer. Ne modifiez pas le code en dehors des questions auxquelles vous êtes invité à répondre à moins que cela ne vous soit spécifiquement demandé. Une fois que vous avez terminé, signez le notebook (à la fin du notebook), renommez-le *NumEtudiant-NomFamille-Notebook9.ipynb* et soumettez-le.\n",
    "\n",
    "*Le notebook sera noté le 25.  \\\n",
    "Chaque **(TO DO)** a un certain nombre de points qui lui sont associés.*\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zwn2MjEV9fUc"
   },
   "source": [
    "**1.0 - Configuration de l'environnement Google Colab**\n",
    "\n",
    "Avant d'entrer directement dans le code, nous devons d'abord configurer notre environnement Google Colab. Pour ce faire, nous devrons installer certaines bibliothèques avec pip (nous devrons le faire chaque fois que nous exécutons le notebook), nous devrons importer certaines bibliothèques et nous devrons enfin activer l'accès GPU pour ce notebook dans Google Colab."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ON0A993QGYx8"
   },
   "source": [
    "Nous allons d'abord initialiser l'accès GPU pour le notebook. Google vous demandera de l'éteindre lorsqu'il n'est pas utilisé, mais vous pourrez facilement compléter le notebook sans problème. Il existe certaines limitations sur la durée de fonctionnement consécutif (plusieurs heures) et la mémoire totale pouvant être utilisée (environ 12 Go selon la carte allouée), mais ce ne sera pas un problème pour ce notebook. De plus, Google peut attribuer différents GPU à chaque utilisateur. Cela peut signifier que vous obtenez une carte légèrement plus lente ou plus rapide, mais tous les GPUs seront plus que suffisants pour exécuter ces modèles avancés avec facilité. Si un problème lié au GPU se produit, vous devrez redémarrer le notebook ou vous déconnecter/vous reconnecter à un nouveau GPU après quelques minutes. Assurez-vous aussi de fermer votre session lorsque vous avez terminé (allez dans *Exécution* et *Gérer les sessions*).\n",
    "\n",
    "**Pour vous connecter à un GPU, allez dans *Modifier(Edit)* dans la barre d'outils, sélectionnez *Paramètres du notebook(Notebook Settings)*, sélectionnez *GPU* comme accélérateur matériel, puis cliquez sur *Enregistrer*.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BIzX2_rlQ5nI"
   },
   "source": [
    "Ensuite, exécutez les installations pip suivantes et les fonctions d'importation pour configurer TensorFlow et toutes les autres bibliothèques que nous utiliserons. Notez que plusieurs bibliothèques que nous avons utilisées dans les notebooks précédents reviennent pour résoudre ce problème."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7sUKqfFLDcWJ"
   },
   "outputs": [],
   "source": [
    "# Install the specified libraries\n",
    "!pip install -q imageio\n",
    "!pip install -q git+https://github.com/tensorflow/docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hkXguTw3-c6O"
   },
   "outputs": [],
   "source": [
    "# Import TensorFlow (note that this also will provide us with the MNIST dataset thanks to Keras)\n",
    "import tensorflow as tf\n",
    "import tensorflow_docs.vis.embed as embed\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# Install additional libraries to help define our arrays, images, and more\n",
    "import glob\n",
    "import imageio\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import PIL\n",
    "import time\n",
    "from IPython import display\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DiS37iPTJSTJ"
   },
   "source": [
    "**2.0 - Importation de l'ensemble de données**\n",
    "\n",
    "Maintenant que l'environnement est prêt, nous allons charger l'ensemble de données MNIST qui nous est fourni par les ensembles de données standard dans TensorFlow. L'ensemble de données MNIST est un ensemble de données composé d'images de chiffres manuscrits (0, 1, 2, ..., 9). Ci-dessous, nous chargeons les données qui nous serviront d'ensemble d'apprentissage (rappelons que nous n'avons pas d'ensemble de test puisque le GAN s'entraînera continuellement pour s'améliorer, contrairement à la classification des chiffres qui nécessiterait un ensemble de test). Ensuite, nous examinons le nombre d'images que nous utiliserons pour nous entraîner dans l'ensemble de données et afficherons une image d'exemple avec le chiffre qu'elle représente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fetGkFPMKD_-"
   },
   "outputs": [],
   "source": [
    "# Load the handwritten digit images and their labels from the dataset\n",
    "(train_images, train_labels), (_, _) = tf.keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3Zx5uPPqvVmX"
   },
   "outputs": [],
   "source": [
    "# Show how many images are in the dataset\n",
    "print(\"There are\", len(train_images), \"many handwritten digits that can be used for training the DCGAN.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1XlP5DFDvyyB"
   },
   "outputs": [],
   "source": [
    "# Which digit is being shown\n",
    "print(\"The following image represents the handwritten digit\", train_labels[0])\n",
    "# What are its dimensions\n",
    "print(\"The image has the dimensions:\", train_images[0].shape, \"and is grayscale.\")\n",
    "# Display the digit\n",
    "plt.imshow(train_images[0], cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9ZZoZUOi0htH"
   },
   "source": [
    "Ci-dessous, nous pouvons voir les valeurs réelles de l'image en gris. Comme vous pouvez le voir, chaque pixel reçoit une valeur unique entre 0 et 255 pour représenter l'échelle de gris à afficher pour ce pixel. Nous regardons cela car nous normaliserons ces valeurs de pixel et modifierons la structure de l'image pour qu'elle soit prête à être utilisée lors de l'entraînement par batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "54hQy9cL08a2"
   },
   "outputs": [],
   "source": [
    "# Understand the structure of the image and the pixel values used.\n",
    "train_images[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ltL0M95VKWO_"
   },
   "source": [
    "Ensuite, nous modifierons les données reçues pour qu'elles soient prêtes à être utilisées par les algorithmes d'apprentissage. Nous modifions la structure pour ajouter une dimension supplémentaire qui indique simplement que l'ensemble de pixels représente un seul chiffre. Cela aide car nos modèles devront travailler avec des lots d'images et savoir clairement quels pixels appartiennent à quelle image.\n",
    "\n",
    "Plus les dimensions d'une image sont petites moins nous avons de valeurs par pixel (c'est-à-dire 1 pour les niveaux de gris ou noir et blanc et 3 pour RGB) ce qui emmène à un entraînement plus rapide (mais une perte de données si la taille est réduite). La taille de cette image est correcte (28 par 28), mais nous normaliserons les valeurs de pixel de 0 à 255 pour être comprises entre -1 et 1. Puisque les algorithmes d'apprentissage automatique apprennent à partir de données, nous voulons généralement normaliser des valeurs plus grandes à partir de valeurs plus petites pour garantir que le modèle apprenne les modèles corrects et minimise le coût des calculs avec de grands nombres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "unO-QyN5KMZh"
   },
   "outputs": [],
   "source": [
    "# Restructure the numpy array to display the pixel values as 28 (width) by 28 (height) by 1 (one image)\n",
    "train_images = train_images.reshape(train_images.shape[0], 28, 28, 1).astype('float32')\n",
    "train_images = (train_images - 127.5) / 127.5 # Normalize the images to [-1, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GmhT_JhF2GXK"
   },
   "source": [
    "Ci-dessous, nous examinons rapidement les valeurs de pixels de la première image de notre ensemble d'entraînement modifié (pour afficher la normalisation et la nouvelle structure) ainsi qu'une vue rapide de l'image elle-même (qui aura exactement la même apparence, mais sera tracée différemment pour correspondre à sa nouvelle structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M4bd2fz02YcN"
   },
   "outputs": [],
   "source": [
    "# Look at the normalized pixel values\n",
    "print(train_images[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Afa_9yi32gpU"
   },
   "outputs": [],
   "source": [
    "# Which digit is being shown\n",
    "print(\"The following image represents the handwritten digit\", train_labels[0])\n",
    "# Look at the updated image (will look the same)\n",
    "plt.imshow(train_images[0][:, :, 0], cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jmwt69nPiLI-"
   },
   "source": [
    "Maintenant, nous réduisons à un sous-ensemble de chiffres, de sorte que le temps d'apprentissage est réduit. Ainsi, notre DCGAN apprendra à générer uniquement les chiffres 1, 5 et 8. *Vous pouvez certainement essayer avec un sous-ensemble plus grand (mais pas plus petit) si vous le souhaitez. Assurez-vous de spécifier le sous-ensemble que vous avez utilisé dans vos réponses.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7UsfdBSKiYe1"
   },
   "outputs": [],
   "source": [
    "# Sous-ensemble de 3 chiffres (vous pouvez en utiliser plus, ou tester des différents)\n",
    "reduced_train_images = []\n",
    "# Populate with only 1, 5, 8  \n",
    "for x in range(len(train_images)):\n",
    "  if train_labels[x] in [1, 5, 8]: \n",
    "    reduced_train_images.append(train_images[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "stvizJzyib-N"
   },
   "outputs": [],
   "source": [
    "#  Au lieu de 60000 images, nous en avons maintenant: \n",
    "print(len(reduced_train_images))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ycb-4MQnRMO1"
   },
   "source": [
    "**3.0 - Définition et entrainement du DCGAN**\n",
    "\n",
    "Pour la conception du DCGAN, nous définirons les différentes couches au sein des réseaux de neurones qui sont utilisées par le générateur et le discriminateur. Chacun de ces modèles nécessitera son propre réseau de neurones, car les deux sont en concurrence.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GIW9ZUH9izbm"
   },
   "source": [
    "***3.1 Définition du Générateur***\n",
    "\n",
    "Ci-dessous, nous définissons le générateur comme un ensemble séquentiel de couches convolutives et de fonctions d'activation (*Leaky ReLU est utilisé ici*) qui prend une entrée et produit une image 28 par 28 par 1. Les valeurs transmises au modèle sont des valeurs aléatoires (appelées *bruit*) basées sur une distribution de probabilité. Le nombre total de valeurs utilisées comme entrée est appelé la *dimension latente* (dans cet exemple, il est de 40). Le but du générateur est de faire passer le bruit à travers son réseau neuronal pour aboutir à un chiffre manuscrit en sortie.\n",
    "\n",
    "Le générateur a un paramètre, un *batch_size*. Ceci est utilisé pour déterminer combien d'images d'entrée sont examinées à la fois avant de réajuster les poids (exécution de la normalisation par lots). Le comportement exact de cette normalisation dépasse le cadre de note cours, mais on peut se rappeler que c'est un hyperparamètre à définir qui va influencer les résultats. En général, une taille de lot plus importante rend l'apprentissage plus rapide et plus stable, car le réseau ne modifie pas constamment les poids sur la base de quelques exemples.\n",
    "\n",
    "Le générateur défini ci-dessous a quatre couches au total. La couche d'entrée accepte le bruit aléatoire comme entrée (produisant un plus grand nombre de sorties), effectue la *normalisation par lots (batchs)* pour aider à améliorer les résultats et exécute la sortie via la fonction d'activation *Leaky ReLU*. Ceci entre ensuite dans la première des trois couches convolutives qui s'alimentent chacune après avoir effectué la *normalisation par lots* et l'utilisation de la fonction d'activation *Leaky ReLU*. Celles-ci réduisent chacune le nombre de sorties à la taille finale de l'image que l'on souhaite (28 par 28 par 1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ri4DZOt4PXwO"
   },
   "outputs": [],
   "source": [
    "def make_generator_model(batch_size):\n",
    "    '''\n",
    "    Defines a Generator to accept rnadom noise based on a probability distribution\n",
    "    and run it through a Neural Network of three convolutional layers with the Leaky ReLU\n",
    "    activiation function and Batch Normalization (which makes the learning process faster and more stable)\n",
    "    '''\n",
    "    model = tf.keras.Sequential()\n",
    "    # Layer 1\n",
    "    model.add(layers.Dense(7*7*batch_size, use_bias=False, input_shape=(40,)))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "    model.add(layers.Reshape((7, 7, batch_size)))\n",
    "    assert model.output_shape == (None, 7, 7, batch_size) # Note: None is the batch size\n",
    "\n",
    "    # Layer 2\n",
    "    model.add(layers.Conv2DTranspose(128, (5, 5), strides=(1, 1), padding='same', use_bias=False))\n",
    "    assert model.output_shape == (None, 7, 7, 128)\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "\n",
    "    # Layer 3\n",
    "    model.add(layers.Conv2DTranspose(64, (5, 5), strides=(2, 2), padding='same', use_bias=False))\n",
    "    assert model.output_shape == (None, 14, 14, 64)\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "\n",
    "    # Layer 4\n",
    "    model.add(layers.Conv2DTranspose(1, (5, 5), strides=(2, 2), padding='same', use_bias=False, activation='tanh'))\n",
    "    assert model.output_shape == (None, 28, 28, 1)\n",
    "\n",
    "    # Return the Generator\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LijKVM7bHJtu"
   },
   "source": [
    "Ci-dessous, nous créons le générateur que nous utiliserons et examinons un exemple de sortie lors du passage d'un bruit aléatoire dans le modèle non entraîné. Comme vous pouvez le voir, il n'a actuellement aucune représentation d'un chiffre manuscrit car il n'a pas appris les modèles à partir des images de chiffres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-D9r9fscPpr-"
   },
   "outputs": [],
   "source": [
    "# Setting the batch size \n",
    "BATCH_SIZE = 256\n",
    "# Define the Generator\n",
    "generator = make_generator_model(BATCH_SIZE)\n",
    "# Generate a random noise input\n",
    "noise = tf.random.normal([1, 40])\n",
    "# Retrieve the outputted image from the Generator for the input\n",
    "generated_image = generator(noise, training=False)\n",
    "# Display the image generated by the Generator\n",
    "plt.imshow(generated_image[0, :, :, 0], cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PP63JKGlJjuP"
   },
   "source": [
    "***3.2 Définition du discriminateur***\n",
    "\n",
    "Ensuite, nous définissons le discriminateur. Le discriminateur accepte une image comme entrée (avec les dimensions attendues) et l'exécute à travers un simple ensemble de couches convolutives pour afficher si l'image est réelle ou fausse. Ce modèle s'entraînera contre le générateur dans le but d'apprendre les attributs des chiffres manuscrits faux et réels. Le discriminateur est défini comme ayant deux couches convolutives qui sont essentiellement les mêmes que celles que nous avons utilisées dans le générateur. Notons que les couches convolutionnelles augmentent en taille, plutôt que de diminuer en taille."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "w_88c3ZzPq8G"
   },
   "outputs": [],
   "source": [
    "def make_discriminator_model():\n",
    "    '''\n",
    "    Create a Discriminator with two convolutional layers that accept a\n",
    "    handwritten digit image as input and outputs whether it is true or false.\n",
    "    Note that the Dropout code refers to the Dropout regularization technique that \n",
    "    can be used to enhance the performance of a Neural Network and achieve strong\n",
    "    results quicker than normal.\n",
    "    '''\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(layers.Conv2D(64, (5, 5), strides=(2, 2), padding='same',\n",
    "                                     input_shape=[28, 28, 1]))\n",
    "    model.add(layers.LeakyReLU())\n",
    "    model.add(layers.Dropout(0.3))\n",
    "\n",
    "    model.add(layers.Conv2D(128, (5, 5), strides=(2, 2), padding='same'))\n",
    "    model.add(layers.LeakyReLU())\n",
    "    model.add(layers.Dropout(0.3))\n",
    "\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(1))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NXH0E3mMKM60"
   },
   "source": [
    "Ci-dessous, nous montrons ce que le discriminateur non entraîné produit lorsque nous fournissons l'image créée par le générateur dans l'exemple ci-dessus comme entrée. Notez que les nombres négatifs signifient que l'image est prédite comme étant fausse tandis que les nombres positifs signifient que l'image est prédite comme étant réelle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1Sw7zLZePsWP"
   },
   "outputs": [],
   "source": [
    "# applying the discriminator on the random noise image generated above\n",
    "discriminator = make_discriminator_model()\n",
    "decision = discriminator(generated_image)\n",
    "print (decision)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9A_3bfIWP837"
   },
   "source": [
    "***3.3 Définition de la fonction de coût et des optimiseurs***\n",
    "\n",
    "Une fois les modèles définis, nous allons maintenant définir les fonctions de coût (appelés aussi *loss-function* - fonctions de perte) à utiliser lors de l'entraînement et les optimiseurs à utiliser. Nous n'entrerons pas dans les détails concernant le code ici, sauf pour le paramètre utilisé pour l'optimiseur Adam. Cependant, des commentaires ont été ajoutés pour expliquer le code à un niveau élevé.\n",
    "\n",
    "Et vous vous souvenez probablement de l'entropie croisée comme fonction de perte utilisée pour la classification binaire. Nous l'utilisons à nouveau ici.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gGRwZ6HnPx9f"
   },
   "outputs": [],
   "source": [
    "# This method returns a helper function to compute cross entropy loss\n",
    "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lYWWrFtTP08W"
   },
   "outputs": [],
   "source": [
    "def discriminator_loss(real_output, fake_output):\n",
    "    '''\n",
    "    The loss function for the discriminator.\n",
    "    This must consider the combined loss from how well it performs at detecting fake and\n",
    "    real images.\n",
    "    '''\n",
    "    real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n",
    "    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
    "    total_loss = real_loss + fake_loss\n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qi171flMP3Z_"
   },
   "outputs": [],
   "source": [
    "def generator_loss(fake_output):\n",
    "    '''\n",
    "    The Generator loss is simply based on whether the generated image was able to \n",
    "    trick the discriminator in believing that the fake image is real.\n",
    "    '''\n",
    "    return cross_entropy(tf.ones_like(fake_output), fake_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VWGgbZ02NRjQ"
   },
   "source": [
    "Ci-dessous, les optimiseurs utilisés pour entraîner les modèles sont sélectionnés. Nous avons également utilisé des optimiseurs lorsque nous travaillons dans le notebook MLP avec scikit-learn. La principale chose à noter ici est que le nombre passé en entrée est le taux d'apprentissage à utiliser par les modèles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oLncRgryP4Ve"
   },
   "outputs": [],
   "source": [
    "# Define the learning rate to be used by the optimizers\n",
    "lr = 1e-4\n",
    "# Set the optimizers that will be used by both models and set the learning rate.\n",
    "generator_optimizer = tf.keras.optimizers.Adam(lr)\n",
    "discriminator_optimizer = tf.keras.optimizers.Adam(lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QQCim8WVnFEt"
   },
   "source": [
    "***3.4 Définition de la méthode d'apprentissage***\n",
    "\n",
    "Nous allons maintenant définir les fonctions pour l'apprentissage. La fonction *train_step* ci-dessous accepte un lot d'images de l'ensemble d'apprentissage en entrée et a d'abord collecté un lot de fausses images du générateur. Le Discriminateur tente alors de déterminer, à partir de l'ensemble des images réelles et de l'ensemble des images fausses, quelles images sont réelles et lesquelles sont fausses. Les pertes des deux modèles sont ensuite calculées pour trouver les gradients et rétropropagées à travers les modèles pour mettre à jour le générateur et le discriminateur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "H2kjCYcWP6hm"
   },
   "outputs": [],
   "source": [
    "noise_dim = 40\n",
    "num_examples_to_generate = 16\n",
    "\n",
    "# We will reuse this seed overtime (so it's easier)\n",
    "# to visualize progress in the animated GIF)\n",
    "seed = tf.random.normal([num_examples_to_generate, noise_dim], seed=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2TTrNxuRQKQu"
   },
   "outputs": [],
   "source": [
    "# Notice the use of `tf.function`\n",
    "# This annotation causes the function to be \"compiled\".\n",
    "@tf.function\n",
    "def train_step(images, batch_size):\n",
    "    '''\n",
    "    For a single batch of images from the training set, train the Discriminator\n",
    "    and Generator.\n",
    "    This function will automatically run on the default GPU of the system if it\n",
    "    can be detected by the environment.\n",
    "    '''\n",
    "    # Generate the batch of random noise inputs to be used to create the fake images\n",
    "    noise = tf.random.normal([batch_size, noise_dim])\n",
    "\n",
    "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "      # Generate the fake images\n",
    "      generated_images = generator(noise, training=True)\n",
    "      # Have the Discriminator determine which images are real or fake from both sets of images\n",
    "      real_output = discriminator(images, training=True)\n",
    "      fake_output = discriminator(generated_images, training=True)\n",
    "      # Calculate the loss for both the generator and the discriminator\n",
    "      gen_loss = generator_loss(fake_output)\n",
    "      disc_loss = discriminator_loss(real_output, fake_output)\n",
    "\n",
    "    # Compute the gradients for both the Generator and the Dsicriminator\n",
    "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
    "    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
    "    # Update the models by applying the gradients to the models\n",
    "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
    "    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "w2eE_VSRQQAe"
   },
   "outputs": [],
   "source": [
    "def train(dataset, epochs):\n",
    "    '''\n",
    "    Trains a Generator and Discriminator with a specified dataset for a specified\n",
    "    number of Epochs. Example outputs are saved to be visualized later.\n",
    "    '''\n",
    "    for epoch in range(epochs):\n",
    "      start = time.time()\n",
    "      # Loop through each batch in the training set\n",
    "      for image_batch in dataset:\n",
    "        # Train the models with the specified batch\n",
    "        train_step(image_batch, BATCH_SIZE)\n",
    "\n",
    "      # Produce images for the GIF as we go\n",
    "      display.clear_output(wait=True)\n",
    "      generate_and_save_images(generator,\n",
    "                              epoch + 1,\n",
    "                              seed)\n",
    "\n",
    "      print ('Time for epoch {} is {} sec'.format(epoch + 1, time.time()-start))\n",
    "\n",
    "    # Generate after the final epoch\n",
    "    display.clear_output(wait=True)\n",
    "    generate_and_save_images(generator,\n",
    "                            epochs,\n",
    "                            seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "beIKnJQ-OyPj"
   },
   "source": [
    "De la même manière que ce que nous avons utilisé dans le Notebook MLP, nous créons une fonction d'entraînement qui entraîne chaque modèle avec l'intégralité de l'ensemble d'entraînement (par lots) pour un certain nombre d'époques. Après chaque époque, un ensemble de 16 exemples de fausses images est généré pour visualiser le processus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FInn6iZFQR1t"
   },
   "outputs": [],
   "source": [
    "def generate_and_save_images(model, epoch, test_input):\n",
    "  '''\n",
    "  Generates fake images based on the Generator after being trained for a \n",
    "  specified number of epochs. We set the model to not train while generating the\n",
    "  images to ensure that only the training function will train the model.\n",
    "  '''\n",
    "  # Notice `training` is set to False.\n",
    "  # This is so all layers run in inference mode (batchnorm).\n",
    "  predictions = model(test_input, training=False)\n",
    "\n",
    "  fig = plt.figure(figsize=(4,4))\n",
    "\n",
    "  for i in range(predictions.shape[0]):\n",
    "      plt.subplot(4, 4, i+1)\n",
    "      plt.imshow(predictions[i, :, :, 0] * 127.5 + 127.5, cmap='gray')\n",
    "      plt.axis('off')\n",
    "\n",
    "  plt.savefig('image_at_epoch_{:04d}.png'.format(epoch))\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KilxQSGwTtBd"
   },
   "source": [
    "***3.5 Apprentissage du DCGAN***\n",
    "\n",
    "Maintenant que le DCGAN est défini, nous devons définir quelques paramètres pour l'entraînement.\n",
    "\n",
    "De la même manière que pour le Notebook MLP, nous déterminons maintenant pour combien d'époques le modèle doit être entraîné. Bien que cela prenne quelques minutes, 50 suffiront pour voir comment évoluent les fausses images du modèle. \n",
    "\n",
    "Ensuite, nous avons le *batch_size* (comme nous l'avons vu précédemment qui est utilisé par le générateur pour la normalisation des lots).\n",
    "\n",
    "Et le *buffer_size* est un paramètre utilisé pour un *shuffle* (mélange) de l'ordre des exemples.  Nous laissons ce mélange se faire parmi tout l'ensemble."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GVPoLBXRo5UN"
   },
   "outputs": [],
   "source": [
    "EPOCHS = 50\n",
    "BATCH_SIZE = 256 # Define the batch size\n",
    "BUFFER_SIZE = len(reduced_train_images) # or 60000 if we use the full dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wer2r0C7o9wN"
   },
   "source": [
    "Maintenant, nous allons entraîner le DCGAN ! Chaque époque prendra environ 10 à 12 secondes, vous verrez donc comment elle se met à jour au cours des 50 époques pour lesquelles nous l'exécuterons. En réalité, nous pouvons optimiser davantage le modèle ou exécuter plus d'époques, mais cela suffit pour visualiser la progression dans le Notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OlFFAWk-pLPk"
   },
   "outputs": [],
   "source": [
    "# build dataset\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices(reduced_train_images).shuffle(BUFFER_SIZE, seed=0).batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZmX2U3O2QZHF"
   },
   "outputs": [],
   "source": [
    "# Remember to turn ON the GPU in Google Colab (the speed that it runs at will depend on the GPU that you are assigned;\n",
    "#                                              between 10 and 30 seconds on average on the full MNIST dataset)!!!\n",
    "# You are expected to run this through all of the epochs, not just a subset of them since everyone has the computation power for it.\n",
    "train(train_dataset, EPOCHS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hwe92a6hc1rr"
   },
   "source": [
    "Une fois l'entrainement terminé, nous afficherons une partie de la collection de fausses images que nous avons affichées pour l'époque 50."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9-BxSYmLcHVE"
   },
   "outputs": [],
   "source": [
    "# Display a single image using the epoch number\n",
    "def display_image(epoch_no):\n",
    "  return PIL.Image.open('image_at_epoch_{:04d}.png'.format(epoch_no))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_Olh_SRCcJeD"
   },
   "outputs": [],
   "source": [
    "# Display the output from the last epoch (epoch 50)\n",
    "plt.imshow(display_image(EPOCHS))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-ZoWN4FTzgAh"
   },
   "source": [
    "**(TO DO) Q1 - 7 points**\n",
    "\n",
    "Maintenant que vous avez entraîné le DCGAN pour générer des chiffres, vous allez analyser les résultats obtenus."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WEzNGBKJYNq8"
   },
   "source": [
    "**(TO DO) Q1 (a) - 2 points**    \n",
    "a) Pour vous aider à analyser l'évolution des images générées pendant l'apprentissage du générateur, définissez la fonction *display_key_epochs* ci-dessous. Cette fonction doit afficher chaque collection de fausses images qui ont été produites pour les époques *\\[10, 20, 30, 40, 50\\]*. Une fois la fonction définie, appelez-la pour afficher chaque collection de fausses images des époques spécifiées. Le code ci-dessus de cette question montre comment vous pouvez récupérer les fausses sorties pour une époque spécifique.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_U2oDRnu7Ci5"
   },
   "outputs": [],
   "source": [
    "# RÉPONSE Q1(a)\n",
    "# Define the function for the target epochs and use it to display the images.\n",
    "# Note: This function is used later in the notebook and assumes that no input parameters will be added.\n",
    "def display_key_epochs():\n",
    "  ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JyMj6i3KbRnm"
   },
   "source": [
    "**(TO DO) Q1 (b) - 2 points**   \n",
    "b) D'après les résultats observés en (a), le modèle semble-t-il bien fonctionner (c'est-à-dire que les chiffres générés ressemblent-ils à des chiffres manuscrits)?  Expliquez votre réponse en référant à des exemples spécifiques dans les résultats observés."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-B92DSLIbSrE"
   },
   "source": [
    "**RÉPONSE Q1 (b)**\n",
    "\n",
    "...    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TOZTM9HtbTC4"
   },
   "source": [
    "**(TO DO) Q1 (c) - 1.5 points**   \n",
    "\n",
    "c) Après avoir visualisé les fausses images à travers les époques, qu'arrive-t-il aux sorties générées alors qu'elles continuent à être entraînées à chaque époque? Expliquez pourquoi ce processus se produit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tmunYyTfbSH-"
   },
   "source": [
    "**RÉPONSE Q1(c)**\n",
    "\n",
    "...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1e-dfpB5bR-W"
   },
   "source": [
    "**(TO DO) Q1 (d) - 1.5 points**   \n",
    "d) Au cours des dernières époques, à quel point les changements apportés aux fausses images sont-ils drastiques? Semblent-ils s'améliorer constamment au même rythme vers la fin de l'entrainement? Pourquoi ou pourquoi pas?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3ueSO1QBbRP8"
   },
   "source": [
    "**RÉPONSE Q1(d)**\n",
    "\n",
    "...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pLYSlV-akhL9"
   },
   "source": [
    "**4.0 - Test de différents hyperparamètres**\n",
    "\n",
    "Après avoir vu comment l'ensemble du processus est effectué, vous allez essayer le même processus pour vous-même, mais en utilisant différents hyperparamètres. En apportant des modifications mineures à un petit nombre de paramètres, il est possible d'obtenir des résultats très différents. Après avoir terminé ce processus, vous discuterez de la façon dont les résultats changent par rapport au test qui vous est fourni dans l'exemple ci-dessus."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TYzn2vU5lL9G"
   },
   "source": [
    "**(TO DO) Q2 - 6 points**    \n",
    "Vous allez maintenant créer un nouveau générateur et discriminateur de telle sorte qu'ils fonctionneront avec une *taille de lot* de 64 images par lot et définiront l'optimiseur pour utiliser un *taux d'apprentissage* plus élevé de 1e-3. Cela ne nécessitera aucune mise à jour des structures définies du générateur et du discriminateur et impliquera simplement de copier du code et d'apporter des modifications mineures. Vous trouverez ci-dessous une liste de chaque tâche que vous devrez effectuer. Chacun de ces éléments doit être effectué dans la cellule de code correspondante ci-dessous. La structure est fournie pour vous, vous devez donc simplement remplir les espaces vides.\n",
    "\n",
    "1) Mettez à jour la variable de taille de lot pour spécifier que les lots doivent être constitués de 64 images et redéfinissez *train_dataset* pour utiliser la nouvelle taille de lot. \\\n",
    "2) Redéfinissez l'objet Generator avec la nouvelle taille de lot comme entrée de la fonction. \\\n",
    "3) Redéfinissez l'objet Discriminator. \\\n",
    "4) Redéfinissez la variable *cross_entropy* de la même manière qu'auparavant. \\\n",
    "5) Réglez le taux d'apprentissage sur 1e-3 et redéfinissez les variables de l'optimiseur. \\\n",
    "6) Exécutez la fonction *train_step* fournie pour recompiler le code après avoir effectué les modifications ci-dessus. \\\n",
    "7) Entrainer les nouveaux modèles pour 50 époques avec l'ensemble de données défini en 1) \\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CBwigInSdkVZ"
   },
   "outputs": [],
   "source": [
    "# TODO: 1) Update the batch size variable to specify that the batches should consist of 64 images and redefine train_dataset to use the new batch size. \n",
    "# Update the batch size\n",
    "BATCH_SIZE = ...\n",
    "# Redefine train_dataset\n",
    "train_dataset = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q9ELACgoqmru"
   },
   "outputs": [],
   "source": [
    "# TODO: 2) Redefine the Generator object with the new batch size as input to the function. \n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-0wPjNKpqpU-"
   },
   "outputs": [],
   "source": [
    "# TODO: 3) Redefine the Discriminator object.\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BL7ZReOprGbs"
   },
   "outputs": [],
   "source": [
    "# TODO: 4) Redefine the cross_entropy variable the same way it was previously\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3MouOPyjq0qX"
   },
   "outputs": [],
   "source": [
    "# TODO: 5) Set the learning rate to 1e-3 and re-define the optimizer variables\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zMniHxORyb1K"
   },
   "outputs": [],
   "source": [
    "# (6) Re-compile this function to work with the updates (just run this code cell)\n",
    "@tf.function\n",
    "def train_step(images, batch_size):\n",
    "    '''\n",
    "    For a single batch of images from the training set, train the Discriminator\n",
    "    and Generator.\n",
    "    This function will automatically run on the default GPU of the system if it\n",
    "    can be detected by the environment.\n",
    "    '''\n",
    "    # Generate the batch of random noise inputs to be used to create the fake images\n",
    "    noise = tf.random.normal([batch_size, noise_dim])\n",
    "\n",
    "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "      # Generate the fake images\n",
    "      generated_images = generator(noise, training=True)\n",
    "      # Have the Discriminator determine which images are real or fake from both sets of images\n",
    "      real_output = discriminator(images, training=True)\n",
    "      fake_output = discriminator(generated_images, training=True)\n",
    "      # Calculate the loss for both the generator and the discriminator\n",
    "      gen_loss = generator_loss(fake_output)\n",
    "      disc_loss = discriminator_loss(real_output, fake_output)\n",
    "\n",
    "    # Compute the gradients for both the Generator and the Dsicriminator\n",
    "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
    "    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
    "    # Update the models by applying the gradients to the models\n",
    "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
    "    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hi0Lfs_Arl5Y"
   },
   "outputs": [],
   "source": [
    "# TODO: 7) Train the new models for 50 epochs with the dataset defined in 1)\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fqT_1YKnzt2N"
   },
   "source": [
    "**(TO DO) Q3 - 6 points**   \n",
    "Maintenant que vous avez modifié les hyperparamètres et entrainé le nouveau DCGAN, vous expliquerez comment ce modèle se compare au modèle de la partie 3.0 de ce notebook et ferez quelques observations basées sur les résultats.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KR10X8CUaVpy"
   },
   "source": [
    "**(TO DO) Q3 (a) - 0.5 point**   \n",
    "a) Utilisez votre fonction *display_key_epochs* (fait en Q1(a)) pour afficher les résultats des époques clés à utiliser pour le reste de la question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "v4y9z_XSaWAL"
   },
   "outputs": [],
   "source": [
    "# RÉPONSE Q3(a)\n",
    "# Show results for the key epochs \n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u4-cFq8eKuqk"
   },
   "source": [
    "**(TO DO) Q3 (b) - 2 points**   \n",
    "b) Entre le modèle que vous avez défini et entraîné et l'exemple de modèle de la partie 3.0, lequel a mieux fonctionné et pourquoi pensez-vous qu'il a mieux fonctionné?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2M4SLbIAKvaT"
   },
   "source": [
    "**RÉPONSE Q3 (b)**\n",
    "\n",
    "...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uaQmjP3VKv5R"
   },
   "source": [
    "**(TO DO) Q3 (c) - 2 points**   \n",
    "\n",
    "c) Nommez un avantage et un inconvénient de l'augmentation du taux d'apprentissage (sur la base de vos observations et/ou sur base de ce que vous avez appris dans le cours en lien au taux d'apprentissage).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XbAX7-GzKwBB"
   },
   "source": [
    "**RÉPONSE Q3 (c)**\n",
    "\n",
    "...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "APej4biXKwQB"
   },
   "source": [
    "**(TO DO) Q3 (d) - 1.5 points**   \n",
    "d) Nommez un avantage et un inconvénient de diminuer la taille du lot (en fonction de vos observations et/ou en fonction de ce que vous savez qui se passe lorsque la taille du lot est réduite)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lzHyl9tiKwWL"
   },
   "source": [
    "**RÉPONSE Q3 (d)**\n",
    "\n",
    "...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "47uiDNuT0gOp"
   },
   "source": [
    "**5.0 - Test d'un DCGAN plus simple**\n",
    "\n",
    "Maintenant que vous avez exploré un DCGAN de base et que vous avez joué avec le taux d'apprentissage et les hyperparamètres comme la taille des lots, nous allons passer par un dernier test d'un DCGAN encore plus simple.\n",
    "\n",
    "Dans ce scénario, tout sera identique à votre configuration dans la section 4.0 de ce notebook, sauf que nous redéfinirons le DCGAN pour supprimer l'une des couches convolutives du générateur et du discriminateur. Cela se traduira par un modèle plus simple. En comparant les résultats obtenus ici aux résultats obtenus dans la section précédente, vous discuterez si une complexité accrue ou une complexité réduite aide le modèle à générer de meilleurs faux chiffres manuscrits."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "02Z90B-ONMEy"
   },
   "source": [
    "Le générateur ci-dessous est maintenant configuré pour être le même qu'avant, mais ne contient maintenant que trois couches, avec deux couches convolutives. Plus précisément, la plus grande couche convolutive a été supprimée, ce qui fait que la sortie de la couche d'entrée conduit à une couche convolutionnelle plus petite."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AhLrM2og2Bxa"
   },
   "outputs": [],
   "source": [
    "def make_generator_model(batch_size):\n",
    "    '''\n",
    "    Defines a Generator to accept rnadom noise based on a probability distribution\n",
    "    and run it through a Neural Network of two convolutional layers with the Leaky ReLU\n",
    "    activiation function and Batch Normalization (which makes the learning process faster and more stable)\n",
    "    '''\n",
    "    model = tf.keras.Sequential()\n",
    "    # Layer 1\n",
    "    model.add(layers.Dense(7*7*batch_size, use_bias=False, input_shape=(40,)))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "    model.add(layers.Reshape((7, 7, batch_size)))\n",
    "    assert model.output_shape == (None, 7, 7, batch_size) # Note: None is the batch size\n",
    "\n",
    "    # Layer 2\n",
    "    model.add(layers.Conv2DTranspose(64, (5, 5), strides=(2, 2), padding='same', use_bias=False))\n",
    "    assert model.output_shape == (None, 14, 14, 64)\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "\n",
    "    # Layer 3\n",
    "    model.add(layers.Conv2DTranspose(1, (5, 5), strides=(2, 2), padding='same', use_bias=False, activation='tanh'))\n",
    "    assert model.output_shape == (None, 28, 28, 1)\n",
    "\n",
    "    # Return the Generator\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "T3RPOs1F2Z4G"
   },
   "outputs": [],
   "source": [
    "# Define the Generator\n",
    "generator = make_generator_model(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JQ8LN7t5NlDu"
   },
   "source": [
    "De même, le Discriminateur a supprimé l'une de ses deux couches convolutives. Il en résulte une seule couche convolutionnelle pour apprendre à distinguer quelles images sont réelles et lesquelles sont fausses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EteEkB0D2IHW"
   },
   "outputs": [],
   "source": [
    "def make_discriminator_model():\n",
    "    '''\n",
    "    Create a Discriminator with one convolutional layer that accept a\n",
    "    handwritten digit image as input and outputs whether it is true or false.\n",
    "    Note that the Dropout code refers to the Dropout regularization technique that \n",
    "    can be used to enhance the performance of a Neural Network and achieve strong\n",
    "    results quicker than normal.\n",
    "    '''\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(layers.Conv2D(64, (5, 5), strides=(2, 2), padding='same',\n",
    "                                     input_shape=[28, 28, 1]))\n",
    "    model.add(layers.LeakyReLU())\n",
    "    model.add(layers.Dropout(0.3))\n",
    "\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(1))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sA_Q-w432cVl"
   },
   "outputs": [],
   "source": [
    "# Define the Discriminator\n",
    "discriminator = make_discriminator_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Mg9w8Zwb2hkx"
   },
   "outputs": [],
   "source": [
    "# This method returns a helper function to compute cross entropy loss\n",
    "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "\n",
    "# Set the optimizers that will be used by both models and set the learning rate.\n",
    "generator_optimizer = tf.keras.optimizers.Adam(lr)\n",
    "discriminator_optimizer = tf.keras.optimizers.Adam(lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oLNl4MyP2sYT"
   },
   "outputs": [],
   "source": [
    "# Re-compile this function to work with the updates\n",
    "# Notice the use of `tf.function`\n",
    "# This annotation causes the function to be \"compiled\".\n",
    "@tf.function\n",
    "def train_step(images, batch_size):\n",
    "    '''\n",
    "    For a single batch of images from the training set, train the Discriminator\n",
    "    and Generator.\n",
    "    This function will automatically run on the default GPU of the system if it\n",
    "    can be detected by the environment.\n",
    "    '''\n",
    "    # Generate the batch of random noise inputs to be used to create the fake images\n",
    "    noise = tf.random.normal([batch_size, noise_dim])\n",
    "\n",
    "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "      # Generate the fake images\n",
    "      generated_images = generator(noise, training=True)\n",
    "      # Have the Discriminator determine which images are real or fake from both sets of images\n",
    "      real_output = discriminator(images, training=True)\n",
    "      fake_output = discriminator(generated_images, training=True)\n",
    "      # Calculate the loss for both the generator and the discriminator\n",
    "      gen_loss = generator_loss(fake_output)\n",
    "      disc_loss = discriminator_loss(real_output, fake_output)\n",
    "\n",
    "    # Compute the gradients for both the Generator and the Dsicriminator\n",
    "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
    "    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
    "    # Update the models by applying the gradients to the models\n",
    "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
    "    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iHBceA6Y2u4b"
   },
   "outputs": [],
   "source": [
    "# Remember to turn ON the GPU in Google Colab.\n",
    "# You are expected to run this through all of the epochs, not just a subset of them since everyone has the computation power for it.\n",
    "train(train_dataset, EPOCHS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Si8tMA-N16fJ"
   },
   "source": [
    "**(TO DO) Q4 - 6 points**  \n",
    "\n",
    "Maintenant que vous avez modifié le réseau et entrainé le nouveau DCGAN, vous expliquerez comment ce modèle se compare au modèle de la partie 4.0 de ce notebook et ferez quelques observations basées sur les résultats.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "msn1rXz_bv2d"
   },
   "source": [
    "**(TO DO) Q4 (a) - 0.5 point**     \n",
    "a) Utilisez votre fonction *display_key_epochs* pour afficher les résultats des époques clés à utiliser pour le reste de la question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sYvVLq5TbwOU"
   },
   "outputs": [],
   "source": [
    "# RÉPONSE Q4(a) \n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QCigdxeRO6P5"
   },
   "source": [
    "**(TO DO) Q4 (b) - 1.5 point**    \n",
    "b) Comment la suppression d'une des couches convolutives du générateur et du discriminateur a-t-elle affecté l'entrainement?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LrryS1I5PO9k"
   },
   "source": [
    "**RÉPONSE Q4 (b)**\n",
    "\n",
    "...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RPzN2uHhPPQb"
   },
   "source": [
    "**(TO DO) Q4 (c) - 2 points**    \n",
    "c) Comment la suppression d'une des couches convolutives du générateur et du discriminateur a-t-elle affecté les résultats par rapport au modèle de la partie 4.0? En outre, comment la suppression de cela a-t-elle affecté les résultats affichés en Q4(a)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E0-CbolVPPUY"
   },
   "source": [
    "**RÉPONSE Q4 (c)**\n",
    "\n",
    "...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hsJIauTEPPC4"
   },
   "source": [
    "**(TO DO) Q4 (d) - 2 points**    \n",
    "d) Si les images que nous utilisons étaient de plus grande taille, aurait-il été préférable d'avoir un modèle complexe ou un modèle simple dans ce scénario? Pourquoi ou pourquoi pas?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JmrsUQzXPOtl"
   },
   "source": [
    "**RÉPONSE Q4(d)**\n",
    "\n",
    "...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6QLJJ7CFhnq7"
   },
   "source": [
    "***SIGNATURE:***\n",
    "Mon nom est --------------------------.\n",
    "Mon numéro d'étudiant(e) est -----------------.\n",
    "Je certifie être l'auteur(e) de ce devoir."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "CSI4506-GAN_Automne2021.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

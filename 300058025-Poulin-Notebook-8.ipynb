{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2-V6SMps1aMz"
   },
   "source": [
    "# Notebook 8 - Représentation des connaissances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LWzoA8kN1aNK"
   },
   "source": [
    "CSI4506 Intelligence Artificielle  \n",
    "Automne 2021 \\\n",
    "Versions 1 (2020) préparée par Julian Templeton, Caroline Barrière et Joel Muteba.  Version 2 (2021) modifiée par Caroline Barrière."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-f2sWDLa1aNM"
   },
   "source": [
    "***INTRODUCTION***:  \n",
    "\n",
    "Lors de la lecture de texte, comprendre les type d'entités utilisées dans le texte permet d'inférer des informations supplémentaires sur ces entités.  Par exemple, si un texte mentionne *Canada*, le fait de savoir que c'est une GPE (entité géo-politique), nous indique déjà que cette entité a une supercifie, une population, etc.  Grâce à l'utilisation de la reconnaissance d'entités nommées (Named Entity Recognition, NER), nous sommes en mesure de déterminer si une entité est une personne, une organisation, un pays, ... \n",
    "\n",
    "Lors de l'exploration de texte en version électronique, nous voyons aussi occasionnellement que les entités ont des liens cliquables vers des pages Web avec plus d'informations sur l'entité. Il s'agit d'une forme d'amélioration du texte pour permettre aux lecteurs d'accéder facilement à des informations supplémentaires.  Si nous prenons encore l'exemple de *Canada*, si nous le transformons en [Canada](https://en.wikipedia.org/wiki/Canada), à l'aide du linking d'entités (entity linking) nous accédons à d'avantage d'informations. \n",
    "\n",
    "Dans ce notebook, nous revisiterons l'ensemble de données d'actualités liées à Covid-19 du notebook 7 pour explorer comment nous pouvons améliorer les résultats de NER de spaCy et aider à la compréhension des articles de presse grâce à l'utilisation du linking d'entités. Cela se fera en trois parties, soit \n",
    "\n",
    "(1) nous explorerons d'abord les résultats du NER de spaCy \\\n",
    "(2) nous utiliserons la cohérence du texte pour un post-traitement au NER de spaCy\\\n",
    "(3) puis nous effectuons des ajouts (*enrichissement*) au texte avec le linking d'entités.\n",
    "\n",
    "Ce notebook utilise des bibliothèques qui ont été utilisées dans les notebooks précédents, notamment spaCy et pandas. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g3lw1Bam1aNP"
   },
   "source": [
    "***DEVOIR***:  \n",
    "\n",
    "Parcourez le notebook en exécutant chaque cellule, une à la fois. \\\n",
    "Recherchez **(TO DO)** pour les tâches que vous devez effectuer. Ne modifiez pas le code en dehors des questions auxquelles vous êtes invité à répondre à moins que cela ne vous soit spécifiquement demandé. Une fois que vous avez terminé, signez le notebook (à la fin du notebook), renommez-le *NumEtudiant-NomFamille-Notebook8.ipynb* et soumettez-le.\n",
    "\n",
    "*Le notebook sera noté le 30.  \\\n",
    "Chaque **(TO DO)** est associé à un certain nombre de points.*\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "IvqAEm8o1aNR"
   },
   "outputs": [],
   "source": [
    "# Before starting we will import every module that we will be using\n",
    "import spacy\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "z0Qx9Rvk1aNT"
   },
   "outputs": [],
   "source": [
    "# The core spacy object can be used for tokenization, lemmatization, POS Tagging, NER ...\n",
    "# Note that this is specifically for the English language and requires the English package to be installed\n",
    "# via pip to work as intended.\n",
    "\n",
    "# sp = spacy.load('en')\n",
    "\n",
    "# If the above causes an error then install the package as below\n",
    "# !spacy download en_core_web_sm\n",
    "sp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VmPRH8H9royU"
   },
   "source": [
    "Comme pour le dernier notebook, l'ensemble de données est fourni sur Brightspace (Module 8) avec ce notebook, mais les détails le concernant peuvent être trouvés [ici](https://www.kaggle.com/ryanxjhan/cbc-news-coronavirus-articles-march-26?select=news.csv). La première chose que nous allons faire, comme d'habitude, est de charger le fichier dans un dataframe pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "32ACx3Cy1aNY"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>authors</th>\n",
       "      <th>title</th>\n",
       "      <th>publish_date</th>\n",
       "      <th>description</th>\n",
       "      <th>text</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>'More vital now:' Gay-straight alliances go vi...</td>\n",
       "      <td>2020-05-03 1:30</td>\n",
       "      <td>Lily Overacker and Laurell Pallot start each g...</td>\n",
       "      <td>Lily Overacker and Laurell Pallot start each g...</td>\n",
       "      <td>https://www.cbc.ca/news/canada/calgary/gay-str...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "      <td>Scientists aim to 'see' invisible transmission...</td>\n",
       "      <td>2020-05-02 8:00</td>\n",
       "      <td>Some researchers aim to learn more about how t...</td>\n",
       "      <td>This is an excerpt from Second Opinion, a week...</td>\n",
       "      <td>https://www.cbc.ca/news/technology/droplet-tra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>['The Canadian Press']</td>\n",
       "      <td>Coronavirus: What's happening in Canada and ar...</td>\n",
       "      <td>2020-05-02 11:28</td>\n",
       "      <td>Canada's chief public health officer struck an...</td>\n",
       "      <td>The latest:  The lives behind the numbers: Wha...</td>\n",
       "      <td>https://www.cbc.ca/news/canada/coronavirus-cov...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>[]</td>\n",
       "      <td>B.C. announces 26 new coronavirus cases, new c...</td>\n",
       "      <td>2020-05-02 18:45</td>\n",
       "      <td>B.C. provincial health officer Dr. Bonnie Henr...</td>\n",
       "      <td>B.C. provincial health officer Dr. Bonnie Henr...</td>\n",
       "      <td>https://www.cbc.ca/news/canada/british-columbi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>[]</td>\n",
       "      <td>B.C. announces 26 new coronavirus cases, new c...</td>\n",
       "      <td>2020-05-02 18:45</td>\n",
       "      <td>B.C. provincial health officer Dr. Bonnie Henr...</td>\n",
       "      <td>B.C. provincial health officer Dr. Bonnie Henr...</td>\n",
       "      <td>https://www.cbc.ca/news/canada/british-columbi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>['Senior Writer', 'Chris Arsenault Is A Senior...</td>\n",
       "      <td>Brazil has the most confirmed COVID-19 cases i...</td>\n",
       "      <td>2020-05-02 8:00</td>\n",
       "      <td>From describing coronavirus as a \"little flu,\"...</td>\n",
       "      <td>With infection rates spiralling, some big city...</td>\n",
       "      <td>https://www.cbc.ca/news/world/brazil-has-the-m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>['Cbc News']</td>\n",
       "      <td>The latest on the coronavirus outbreak for May 1</td>\n",
       "      <td>2020-05-01 20:43</td>\n",
       "      <td>The latest on the coronavirus outbreak from CB...</td>\n",
       "      <td>Coronavirus Brief (CBC)  Canada is officiall...</td>\n",
       "      <td>https://www.cbc.ca/news/the-latest-on-the-coro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>['Cbc News']</td>\n",
       "      <td>Coronavirus: What's happening in Canada and ar...</td>\n",
       "      <td>2020-05-01 11:51</td>\n",
       "      <td>Nova Scotia announced Friday it is immediately...</td>\n",
       "      <td>The latest:  The lives behind the numbers: Wha...</td>\n",
       "      <td>https://www.cbc.ca/news/canada/coronavirus-cov...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>['Senior Writer', \"Adam Miller Is Senior Digit...</td>\n",
       "      <td>Did the WHO mishandle the global coronavirus p...</td>\n",
       "      <td>2020-04-30 8:00</td>\n",
       "      <td>The World Health Organization has come under f...</td>\n",
       "      <td>The World Health Organization has come under f...</td>\n",
       "      <td>https://www.cbc.ca/news/health/coronavirus-who...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>['Thomson Reuters']</td>\n",
       "      <td>Armed people in Michigan's legislature protest...</td>\n",
       "      <td>2020-04-30 21:37</td>\n",
       "      <td>Hundreds of protesters, some armed, gathered a...</td>\n",
       "      <td>Hundreds of protesters, some armed, gathered a...</td>\n",
       "      <td>https://www.cbc.ca/news/world/protesters-michi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Unnamed: 0                                            authors  \\\n",
       "0          0                                                 []   \n",
       "1          1                                                 []   \n",
       "2          2                             ['The Canadian Press']   \n",
       "3          3                                                 []   \n",
       "4          4                                                 []   \n",
       "5          5  ['Senior Writer', 'Chris Arsenault Is A Senior...   \n",
       "6          6                                       ['Cbc News']   \n",
       "7          7                                       ['Cbc News']   \n",
       "8          8  ['Senior Writer', \"Adam Miller Is Senior Digit...   \n",
       "9          9                                ['Thomson Reuters']   \n",
       "\n",
       "                                               title      publish_date  \\\n",
       "0  'More vital now:' Gay-straight alliances go vi...   2020-05-03 1:30   \n",
       "1  Scientists aim to 'see' invisible transmission...   2020-05-02 8:00   \n",
       "2  Coronavirus: What's happening in Canada and ar...  2020-05-02 11:28   \n",
       "3  B.C. announces 26 new coronavirus cases, new c...  2020-05-02 18:45   \n",
       "4  B.C. announces 26 new coronavirus cases, new c...  2020-05-02 18:45   \n",
       "5  Brazil has the most confirmed COVID-19 cases i...   2020-05-02 8:00   \n",
       "6   The latest on the coronavirus outbreak for May 1  2020-05-01 20:43   \n",
       "7  Coronavirus: What's happening in Canada and ar...  2020-05-01 11:51   \n",
       "8  Did the WHO mishandle the global coronavirus p...   2020-04-30 8:00   \n",
       "9  Armed people in Michigan's legislature protest...  2020-04-30 21:37   \n",
       "\n",
       "                                         description  \\\n",
       "0  Lily Overacker and Laurell Pallot start each g...   \n",
       "1  Some researchers aim to learn more about how t...   \n",
       "2  Canada's chief public health officer struck an...   \n",
       "3  B.C. provincial health officer Dr. Bonnie Henr...   \n",
       "4  B.C. provincial health officer Dr. Bonnie Henr...   \n",
       "5  From describing coronavirus as a \"little flu,\"...   \n",
       "6  The latest on the coronavirus outbreak from CB...   \n",
       "7  Nova Scotia announced Friday it is immediately...   \n",
       "8  The World Health Organization has come under f...   \n",
       "9  Hundreds of protesters, some armed, gathered a...   \n",
       "\n",
       "                                                text  \\\n",
       "0  Lily Overacker and Laurell Pallot start each g...   \n",
       "1  This is an excerpt from Second Opinion, a week...   \n",
       "2  The latest:  The lives behind the numbers: Wha...   \n",
       "3  B.C. provincial health officer Dr. Bonnie Henr...   \n",
       "4  B.C. provincial health officer Dr. Bonnie Henr...   \n",
       "5  With infection rates spiralling, some big city...   \n",
       "6    Coronavirus Brief (CBC)  Canada is officiall...   \n",
       "7  The latest:  The lives behind the numbers: Wha...   \n",
       "8  The World Health Organization has come under f...   \n",
       "9  Hundreds of protesters, some armed, gathered a...   \n",
       "\n",
       "                                                 url  \n",
       "0  https://www.cbc.ca/news/canada/calgary/gay-str...  \n",
       "1  https://www.cbc.ca/news/technology/droplet-tra...  \n",
       "2  https://www.cbc.ca/news/canada/coronavirus-cov...  \n",
       "3  https://www.cbc.ca/news/canada/british-columbi...  \n",
       "4  https://www.cbc.ca/news/canada/british-columbi...  \n",
       "5  https://www.cbc.ca/news/world/brazil-has-the-m...  \n",
       "6  https://www.cbc.ca/news/the-latest-on-the-coro...  \n",
       "7  https://www.cbc.ca/news/canada/coronavirus-cov...  \n",
       "8  https://www.cbc.ca/news/health/coronavirus-who...  \n",
       "9  https://www.cbc.ca/news/world/protesters-michi...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the dataset, show top ten rows\n",
    "df = pd.read_csv(\"news.csv\")\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N13QcJqR1aNV"
   },
   "source": [
    "**PARTIE 1 - Le NER de spaCy**  \n",
    "  \n",
    "Commençons par regarder le NER qui est effectué par spaCy. La documentation de SpaCy ne nous dit pas exactement comment leur NER est fait (certainement leur secret commercial), mais nous pouvons au moins regarder les résultats.\n",
    "\n",
    "Comme nous en avons discuté dans les notebooks précédents, lors de l'évaluation d'un processus, d'un modèle ou d'un outil, nous pouvons faire une évaluation quantitative ou une **évaluation qualitative** des résultats. Dans ce notebook, nous travaillons à un niveau qualitatif, ce qui signifie que nous ne mesurons pas des métriques telles que la précision/rappel, mais imprimons plutôt les résultats de quelques exemples et essayons de comprendre ces résultats.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kIQI-Fwi1aNa"
   },
   "source": [
    "Vous trouverez ci-dessous la même phrase exemple que dans le dernier Notebook, pour laquelle nous avions examiné l'étiquetage des parties du discours (POS tagging) et d'autres processus linguistiques.  Nous utilisons cette phrase exemple pour illustrer maintenant comment obtenir les prédictions de type NER de spaCy pour les tokens dans un texte."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "syOIDbsa1aNc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Canada\" is a GPE\n",
      "\"at least two metres\" is a CARDINAL\n",
      "\"COVID-19\" is a ORG\n"
     ]
    }
   ],
   "source": [
    "# Same example from notebook 7, recall that we loop through the iterator found in the .ents property of a parsed sentence\n",
    "sentence_example = \"Government guidelines in Canada recommend that people stay at least two metres away from others as part of physical distancing measures to curb the spread of COVID-19.\"\n",
    "sentence_example_content = sp(sentence_example)\n",
    "# Loop through all tokens that contain a NER type and print the token along with the corresponding NER type\n",
    "for token in sentence_example_content.ents:\n",
    "    print(\"\\\"\" + token.text + \"\\\" is a \" + token.label_ )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J9VAgeEA1aNe"
   },
   "source": [
    "**(TO DO) Q1 - 5 points**  \n",
    "\n",
    "Dans le texte du ***second document*** (index 1) de notre corpus de documents, quels mots sont *PER* (spaCy utilise le type *PERSON*, plutôt que *PER*), *ORG* (Organisation) et *GPE* (entité géopolitique). Vous devez effectuer les opérations suivantes pour cette question:\n",
    "\n",
    "a) (2 points) Imprimez chaque *PERSON*, *ORG* et *GPE* avec son type NER tel que trouvé par spaCy.\n",
    "\n",
    "b) (1 points) Est-ce que la majorité des prédictions de spaCy sont correctes? Donnez deux exemples de sorties obtenues en (a) qui sont incorrectes selon vous.\n",
    "\n",
    "c) (2 points) Il arrive parfois que des problèmes avec les prédictions de type NER proviennent d'erreurs dans des étapes antérieures dans la pipeline TAL (e.g. tokenization, POS tagging).  Utilisez 2 exemples de sorties obtenues en (a) pour illustrer cette possibilité, et tentez d'offrir un diagnostic (que s'est-il passé?)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "7bIvPeBI1aNf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"COVID-19\": PERSON\n",
      "\"the World Health Organization\": ORG\n",
      "\"WHO\": ORG\n",
      "\"the Public Health Agency\": ORG\n",
      "\"Canada\": GPE\n",
      "\"W.F. Wells\": PERSON\n",
      "\"the Harvard School of Public Health\": ORG\n",
      "\"Wells\": ORG\n",
      "\"Canada\": GPE\n",
      "\"Lydia Bourouiba\": PERSON\n",
      "\"the Fluid Dynamics of Disease Transmission Laboratory\": ORG\n",
      "\"the Massachusetts Institute of Technology\": ORG\n",
      "\"Bourouiba\": PERSON\n",
      "\"Mark Loeb\": PERSON\n",
      "\"McMaster University\": ORG\n",
      "\"RNA\": ORG\n",
      "\"Wuhan\": GPE\n",
      "\"China\": GPE\n",
      "\"Nebraska\": GPE\n",
      "\"Canada\": GPE\n",
      "\"COVID-19\": ORG\n",
      "\"Gary Moore/CBC\": PERSON\n",
      "\"Allison McGeer\": PERSON\n",
      "\"Sinai Health\": ORG\n",
      "\"Toronto\": GPE\n",
      "\"COVID-19\": PERSON\n",
      "\"McGeer\": ORG\n",
      "\"McGeer\": ORG\n",
      "\"Bourouiba\": PERSON\n",
      "\"Bourouiba\": PERSON\n",
      "\"Credit Lydia Bourouiba/MIT/JAMA Networks\": ORG\n",
      "\"Samira Mubareka\": PERSON\n",
      "\"Toronto\": GPE\n",
      "\"Bourouiba\": PERSON\n",
      "\"COVID-19\": ORG\n",
      "\"McMaster\": PERSON\n",
      "\"N95\": ORG\n",
      "\"U.S.\": GPE\n",
      "\"Justin Trudeau\": PERSON\n",
      "\"Mubareka\": PERSON\n",
      "\"the New England Journal of Medicine\": ORG\n",
      "\"the U.S. National Institutes of Health\": ORG\n",
      "\"U.S. National Institutes of Health\": ORG\n",
      "\"COVID-19?\": ORG\n",
      "\"Journal of the Royal Society Interface\": ORG\n",
      "\"U.S.\": GPE\n",
      "\"Singapore\": GPE\n",
      "\"N95\": ORG\n",
      "\"Gary S. Settles\": PERSON\n",
      "\"Penn State University/Journal of the Royal Society Interface\": ORG\n",
      "\"The World Health Organization\": ORG\n",
      "\"Los Angeles\": GPE\n",
      "\"Italy\": GPE\n",
      "\"Austria\": GPE\n"
     ]
    }
   ],
   "source": [
    "# RÉPONSE Q1(a) - 2 points\n",
    "# Select the second document (index 1)\n",
    "doc = df[\"text\"][1]\n",
    "# SHOW PERSON, ORG, GPE\n",
    "content = sp(doc)\n",
    "for token in content.ents:\n",
    "    if(token.label_ == \"PERSON\" or token.label_ == \"ORG\" or token.label_ == \"GPE\"):\n",
    "        print(\"\\\"\" + token.text + \"\\\": \" + token.label_ )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xVuqciJz1aNg"
   },
   "source": [
    "**RÉPONSE Q1(b) - 1 point**   \n",
    "\"Covid-19\" est parfois associé à une organisation ou une personne ce qui n'est pas le cas.\n",
    "\"McGeer\" est associé à une organisation, mais est en réalité une personne.\n",
    "La majorité des prédictions de spaCY sont correctes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E2K3_74F1aNi"
   },
   "source": [
    "**RÉPONSE Q1 (c) - 2 points**   \n",
    "\"Gary Moore/CBC\" est une erreur de tokenization, car Gary Moore est une personne et CBC est une organisation. Cette erreur est sans doute dû au \"/\" entre les deux mots.\n",
    "\n",
    "\"McGeer\" est identifié comme une organisation, mais fait fort probablement référence à une personne, donc il y a eu une erreur de POS tagging. Cette erreur doit être dû au fait que le prénom n'était pas présent avant le nom \"McGeer\", donc spaCY à traité \"McGeer\" comme le nom d'une organisation. De plus, spaCY ne tient pas compte de l'entièreté du document."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OltjfgOl1aNj"
   },
   "source": [
    "**PARTIE 2 - Cohérence du texte et chaînes de coréférences**  \n",
    "\n",
    "Comme vous avez vu, les résultats du spaCy NER sont très bons, mais pas parfait.  Un problème principal avec NER (pas seulement dans spaCy mais dans de nombreux outils) est que l'annotation est effectuée une entité à la fois sans tenir compte du document global.\n",
    "\n",
    "Mais en regardant l'ensemble du document, et sachant que le texte est généralement cohérent, nous pouvons effectuer un post-traitement dans le module NER de spaCy et corriger certaines erreurs. Par texte cohérent, nous entendons, par exemple, que si une personne est désignée avec un nom particulier, par ex. *McGeer*, il y a de fortes chances qu'à chaque fois que l'on voit *McGeer* dans le document, ce soit la même personne.  Toutes les mentions *McGeer* formeraient une chaîne de coréférences vers la même entité.  Il est donc peu probable que *McGeer* soit une fois une personne et une fois une organisation. Ce n'est pas toujours vrai, il existe de nombreux contre-exemples, mais c'est une hypothèse courante. Cette idée est même le sujet d'un article de la PNL plus ancien et très cité intitulé « One sense per discourse » (Gale et al. 1992).\n",
    "\n",
    "Avec cette idée de \"One sense per discourse\", nous explorerons deux stratégies différentes pour utiliser la cohérence du texte pour post-traiter la sortie du module spaCy NER.\n",
    "\n",
    "La première stratégie (*explorée en Q2 / Q3*) est de trouver, parmi tous les types de NER assignés, lequel est le plus fréquent. Par exemple, l'entité *Bourouiba* s'est vu attribuer 1 fois ORG et 2 fois PERSON, donc ces informations peuvent être utilisées pour modifier le type ORG et le changer en PERSON.\n",
    "\n",
    "La deuxième stratégie (explorée à la Q4) est d'essayer de trouver une forme plus longue dans le texte. Puisque cette forme plus longue devrait être moins ambiguë, nous pouvons l'utiliser pour lever l'ambiguïté des formes plus courtes et plus ambiguës. Par exemple, *Lydia Bourouiba* apparaît dans le texte et se voit attribuer PERSON. Nous pouvons utiliser cette information pour attribuer à d'autres occurrences de la forme abrégée *Bourouiba* le même type PERSON.\n",
    "\n",
    "Bien sûr, utiliser ces méthodes pour la cohérence du texte ne fonctionnera pas à tous les coups, et introduira malheureusement quelques erreurs... Mais essayons. C'est le but des études empiriques, nous essayons des idées."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7VH5BjZl1aNk"
   },
   "source": [
    "Reprenons notre nouvelle utilisée pour Q1, mais cette fois, montrons non seulement GPE, PER, ORG, mais plutôt toutes les entités nommées trouvées par spaCy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "vMWdFIsi1aNl"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: \"weekly\" is a DATE\n",
      "1: \"Saturday\" is a DATE\n",
      "2: \"morning\" is a TIME\n",
      "3: \"two metres\" is a QUANTITY\n",
      "4: \"COVID-19\" is a PERSON\n",
      "5: \"the World Health Organization\" is a ORG\n",
      "6: \"WHO\" is a ORG\n",
      "7: \"more than one metre\" is a QUANTITY\n",
      "8: \"the Public Health Agency\" is a ORG\n",
      "9: \"Canada\" is a GPE\n",
      "10: \"at least two metres\" is a QUANTITY\n",
      "11: \"two\" is a CARDINAL\n",
      "12: \"2 metres\" is a QUANTITY\n",
      "13: \"the 19th century\" is a DATE\n",
      "14: \"1934\" is a DATE\n",
      "15: \"W.F. Wells\" is a PERSON\n",
      "16: \"the Harvard School of Public Health\" is a ORG\n",
      "17: \"two metres\" is a QUANTITY\n",
      "18: \"Wells\" is a ORG\n",
      "19: \"56,000\" is a CARDINAL\n",
      "20: \"Canada\" is a GPE\n",
      "21: \"Saturday\" is a DATE\n",
      "22: \"Lydia Bourouiba\" is a PERSON\n",
      "23: \"the Fluid Dynamics of Disease Transmission Laboratory\" is a ORG\n",
      "24: \"the Massachusetts Institute of Technology\" is a ORG\n",
      "25: \"Bourouiba\" is a PERSON\n",
      "26: \"Canadian\" is a NORP\n",
      "27: \"Mark Loeb\" is a PERSON\n",
      "28: \"McMaster University\" is a ORG\n",
      "29: \"RNA\" is a ORG\n",
      "30: \"Wuhan\" is a GPE\n",
      "31: \"China\" is a GPE\n",
      "32: \"Nebraska\" is a GPE\n",
      "33: \"Canada\" is a GPE\n",
      "34: \"at least two metres\" is a CARDINAL\n",
      "35: \"COVID-19\" is a ORG\n",
      "36: \"Gary Moore/CBC\" is a PERSON\n",
      "37: \"Allison McGeer\" is a PERSON\n",
      "38: \"Sinai Health\" is a ORG\n",
      "39: \"Toronto\" is a GPE\n",
      "40: \"COVID-19\" is a PERSON\n",
      "41: \"hundreds\" is a CARDINAL\n",
      "42: \"hours\" is a TIME\n",
      "43: \"N-95\" is a PRODUCT\n",
      "44: \"McGeer\" is a ORG\n",
      "45: \"five minutes\" is a TIME\n",
      "46: \"McGeer\" is a ORG\n",
      "47: \"Bourouiba\" is a PERSON\n",
      "48: \"Bourouiba\" is a PERSON\n",
      "49: \"farther than two metres\" is a QUANTITY\n",
      "50: \"seven or eight metres\" is a QUANTITY\n",
      "51: \"Credit Lydia Bourouiba/MIT/JAMA Networks\" is a ORG\n",
      "52: \"Canadian\" is a NORP\n",
      "53: \"about one kilometre\" is a QUANTITY\n",
      "54: \"two-metre\" is a QUANTITY\n",
      "55: \"up to three minutes\" is a TIME\n",
      "56: \"Samira Mubareka\" is a PERSON\n",
      "57: \"Sunnybrook Hospital\" is a FAC\n",
      "58: \"Toronto\" is a GPE\n",
      "59: \"2-metre\" is a QUANTITY\n",
      "60: \"Bourouiba\" is a PERSON\n",
      "61: \"two metres\" is a QUANTITY\n",
      "62: \"March\" is a DATE\n",
      "63: \"farther than two metres\" is a QUANTITY\n",
      "64: \"two metres\" is a QUANTITY\n",
      "65: \"Mubareka\" is a PRODUCT\n",
      "66: \"two-metre\" is a QUANTITY\n",
      "67: \"Second\" is a ORDINAL\n",
      "68: \"COVID-19\" is a ORG\n",
      "69: \"McMaster\" is a PERSON\n",
      "70: \"N95\" is a ORG\n",
      "71: \"U.S.\" is a GPE\n",
      "72: \"Canadian\" is a NORP\n",
      "73: \"Justin Trudeau\" is a PERSON\n",
      "74: \"Mubareka\" is a PERSON\n",
      "75: \"April 2020\" is a DATE\n",
      "76: \"the New England Journal of Medicine\" is a ORG\n",
      "77: \"the U.S. National Institutes of Health\" is a ORG\n",
      "78: \"0:42\" is a DATE\n",
      "79: \"U.S. National Institutes of Health\" is a ORG\n",
      "80: \"less than 10\" is a CARDINAL\n",
      "81: \"COVID-19?\" is a ORG\n",
      "82: \"2009\" is a DATE\n",
      "83: \"Journal of the Royal Society Interface\" is a ORG\n",
      "84: \"2009\" is a DATE\n",
      "85: \"U.S.\" is a GPE\n",
      "86: \"Singapore\" is a GPE\n",
      "87: \"N95\" is a ORG\n",
      "88: \"Gary S. Settles\" is a PERSON\n",
      "89: \"Penn State University/Journal of the Royal Society Interface\" is a ORG\n",
      "90: \"The World Health Organization\" is a ORG\n",
      "91: \"Los Angeles\" is a GPE\n",
      "92: \"Italy\" is a GPE\n",
      "93: \"Austria\" is a GPE\n",
      "94: \"Saturday\" is a DATE\n",
      "95: \"morning\" is a TIME\n"
     ]
    }
   ],
   "source": [
    "# Select document 2\n",
    "doc = df[\"text\"][1]\n",
    "# NER\n",
    "doc_sp = sp(doc)\n",
    "# Display all entities from the text along with their index in the .ents iterator and the\n",
    "# corresponding NER type\n",
    "for i, token in enumerate(doc_sp.ents):\n",
    "    print(str(i) + \": \\\"\" + token.text + \"\\\" is a \" + token.label_ )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MpPGxf9J1aNm"
   },
   "source": [
    "**(TO DO) Q2 - 3 points**  \n",
    "Comme vous pouvez le voir dans les résultats, parfois la même entité s'est vu attribuer différents types d'entités.  Par exemple, *McGeer* est une fois ORG, une fois PERSON, puisque l'algorithme NER regarde phrase par phrase. Dans la fonction suivante, le but sera de trouver tous les types d'entités possibles affectés à une seule entité.\n",
    "\n",
    "Complétez la définition de la fonction *find_entity_types* ci-dessous. Cette fonction accepte en entrée une entité spaCy spécifique définie par le paramètre *entity* et une liste de toutes les entités spaCy du définies par le paramètre *entities*.\n",
    "\n",
    "La fonction doit trouver toutes les entités ayant la même forme de surface que *entity* dans l'ensemble *entities*. Pour chaque correspondance entre les entités, ajoutez le type NER trouvé au dictionnaire *type_counts* et mettez à jour la fréquence de ce type.\n",
    "\n",
    "Le dictionnaire *type_counts* contiendrait par exemple *McGeer* avec ORG = 1, et PERSON = 1, car la fonction a trouvé 2 mentions de *McGeer*, chacune avec un type différent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "id": "6V3v0gqj1aNn"
   },
   "outputs": [],
   "source": [
    "# RÉPONSE Q2\n",
    "def find_entity_types(entity, entities):\n",
    "    '''\n",
    "    Given a specific entity and a list of entities, finds all entities from the list that match surface form of the specified\n",
    "    entity, but that could be of a different type.\n",
    "    \n",
    "    Returns the different NER types that have been classified for an entity and the count per NER type\n",
    "    as a dictionary with the keys as the NER type and the value as the count\n",
    "    '''\n",
    "    type_counts = { }\n",
    "    for token in entities:\n",
    "        if(token.text == entity.text):\n",
    "            if(token.label_ in type_counts):\n",
    "                type_counts[token.label_] += 1  \n",
    "            else:\n",
    "                type_counts[token.label_] = 1  \n",
    "    return type_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "id": "Oz_ONmNt1aNo"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All possible NER types for \"2-metre\" are {'QUANTITY': 1}\n"
     ]
    }
   ],
   "source": [
    "# Test the above to find the result when checking for the types of the entity 'Bourouiba' \n",
    "# from the document loaded above\n",
    "print(\"All possible NER types for \\\"\" + doc_sp.ents[59].text + \"\\\" are \" + str(find_entity_types(doc_sp.ents[59], doc_sp.ents)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MpkfKthN1aNp"
   },
   "source": [
    "**(TO DO) Q3 - 2 points**  \n",
    "\n",
    "Dans la méthode précédente, *find_entity_types*, nous avons trouvé tous les types d'entités possibles pour chaque mention. Par exemple, dans le cas de *McGeer*, c'est une égalité. Mais pour *Bourouiba*, il existe un type ORG et 2 types PERSON, donc le plus courant serait PERSON.\n",
    "\n",
    "Complétez la définition de la fonction *most_common_type* ci-dessous. Cette fonction accepte en entrée une entité spaCy spécifique définie par le paramètre *entity* et une liste de toutes les entités spaCy définies par le paramètre *entities*.\n",
    "\n",
    "Remarque: vous pouvez régler les cas d'égalité à votre guise.  Aussi, assurez-vous d'utiliser la méthode *find_entity_types* que vous avez écrite précédemment.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "id": "IqxDmjpk1aNq"
   },
   "outputs": [],
   "source": [
    "# RÉPONSE Q3 \n",
    "def most_common_type(entity, entities):\n",
    "    '''\n",
    "    Given a specific entity and a list of entities, find the most similar entities and assign the\n",
    "    NER type to entity based on the most common NER type assigned to entities of the same name (if there\n",
    "    is a tie, you decide how to handle this).\n",
    "    \n",
    "    Returns the most common NER type based on similar entities\n",
    "    '''\n",
    "    dic = find_entity_types(entity, entities)\n",
    "    max_key = max(dic, key=dic.get)\n",
    "    #entity.label_ = max_key\n",
    "    return max_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "id": "5akWFe_d1aNr"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The most common NER type to \"2-metre\" is QUANTITY\n"
     ]
    }
   ],
   "source": [
    "# Test the above to find the result when checking for the types of the entity 'Bourouiba' \n",
    "# from the document loaded above\n",
    "print(\"The most common NER type to \\\"\" + doc_sp.ents[59].text + \"\\\" is \" + most_common_type(doc_sp.ents[59], doc_sp.ents))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SfhMQveBvrD2"
   },
   "source": [
    "\n",
    "Notre première exploration (au Q2/Q3) portait sur la fréquence d'occurrence. Nous avons supposé que le type d'entité le plus courant pourrait être le bon. Maintenant, nous allons explorer l'idée que la mention la moins ambiguë à une entité pourrait être la bonne. Par exemple, *McGeer* est plus ambigu (forme plus courte) que *Allison McGeer* (forme plus longue). Souvent, la forme la plus longue de référence à une entité est la moins ambiguë. Mais parce que cette forme est longue à écrire, nous l'utilisons souvent avec parcimonie dans un texte (peut-être une seule fois) et les mentions subséquentes de la même entité utiliseront la forme courte. Par exemple, le texte peut mentionner *Allison McGeer* une fois, puis utiliser la forme abrégée *McGeer* pour faire référence à la même personne plusieurs fois dans le document.\n",
    "\n",
    "Dans les vidéos du cours, nous avons parlé de chaîne de coréférences.  Ainsi, une chaîne contient des mentions longues et courtes, référant toutes à la même entités.\n",
    "\n",
    "La forme plus longue est souvent appelée forme normalisée, et c'est une forme que nous sommes susceptibles de trouver dans une ressource externe. Nous verrons dans la partie 3 de ce Notebook, lorsque nous ferons des liens d'entités, qu'il existe une entrée Wikipedia pour *Allison McGeer* vers laquelle nous pourrions établir un lien. Nous pouvons considérer la forme plus longue de *Allison McGeer* comme la forme normalisée."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NEQ1Wek51aNr"
   },
   "source": [
    "**(TO DO) Q4 (a) - 3 points**  \n",
    "\n",
    "Vous devez écrire une fonction qui trouvera la forme la plus longue pouvant correspondre à une mention.\n",
    "\n",
    "Votre fonction aura les mêmes paramètres *entity* et *entities*, mais cette fois la fonction devra attribuer à *entité* le type NER d'une autre entité dans l'itérateur *entities*, soit le NER de la forme la plus longue.\n",
    "\n",
    "Plus précisément, vous devez parcourir les *entités* pour trouver une forme normalisée de *entité*. Dans ce scénario, l'entité avec la forme la plus longue contenant *entité* en tant que sous-chaîne sera considérée comme la forme normalisée et sera retournée.\n",
    "\n",
    "Ex : *Lydia Bourouiba* est la forme normalisée de *Bourouiba*. Ainsi, l'entité ayant cette forme doit être retournée. Mais *McMaster University* est déjà la forme la plus longue, donc si nous recherchons une forme normalisée pour cette entité, la fonction devrait renvoyer l'entité elle-même."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "id": "xEH_uYVZ1aNs"
   },
   "outputs": [],
   "source": [
    "# RÉPONSE Q4(a)\n",
    "# Find the longest surface form within \"entities\" for which the surface for of \"entity\" is a substring\n",
    "def assign_normalized_form(entity, entities):\n",
    "    tmp = entity\n",
    "    for token in entities:\n",
    "        res = token.text.find(entity.text) # -1 = not found\n",
    "        if(len(token.text) > len(tmp.text) and res != -1):\n",
    "            tmp = token\n",
    "    #entity.label_ = tmp.label_\n",
    "    return tmp  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1lZqi5gRGWmn"
   },
   "source": [
    "Testons la fonction ci-haut, en supposant que les candidats se retrouvent uniquement dans les mentions précédentes, car souvent une forme longue est d'abord donnée *Allison McGeer* et les formes subséquentes sont les formes courtes *McGeer*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "id": "P5litMpf1aNs"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: \"weekly\" is a DATE  weekly  DATE\n",
      "1: \"Saturday\" is a DATE  Saturday  DATE\n",
      "2: \"morning\" is a TIME  morning  TIME\n",
      "3: \"two metres\" is a QUANTITY  two metres  QUANTITY\n",
      "4: \"COVID-19\" is a PERSON  COVID-19  PERSON\n",
      "5: \"the World Health Organization\" is a ORG  the World Health Organization  ORG\n",
      "6: \"WHO\" is a ORG  WHO  ORG\n",
      "7: \"more than one metre\" is a QUANTITY  more than one metre  QUANTITY\n",
      "8: \"the Public Health Agency\" is a ORG  the Public Health Agency  ORG\n",
      "9: \"Canada\" is a GPE  Canada  GPE\n",
      "10: \"at least two metres\" is a QUANTITY  at least two metres  QUANTITY\n",
      "11: \"two\" is a CARDINAL  two metres  QUANTITY\n",
      "12: \"2 metres\" is a QUANTITY  2 metres  QUANTITY\n",
      "13: \"the 19th century\" is a DATE  the 19th century  DATE\n",
      "14: \"1934\" is a DATE  1934  DATE\n",
      "15: \"W.F. Wells\" is a PERSON  W.F. Wells  PERSON\n",
      "16: \"the Harvard School of Public Health\" is a ORG  the Harvard School of Public Health  ORG\n",
      "17: \"two metres\" is a QUANTITY  at least two metres  QUANTITY\n",
      "18: \"Wells\" is a ORG  W.F. Wells  PERSON\n",
      "19: \"56,000\" is a CARDINAL  56,000  CARDINAL\n",
      "20: \"Canada\" is a GPE  Canada  GPE\n",
      "21: \"Saturday\" is a DATE  Saturday  DATE\n",
      "22: \"Lydia Bourouiba\" is a PERSON  Lydia Bourouiba  PERSON\n",
      "23: \"the Fluid Dynamics of Disease Transmission Laboratory\" is a ORG  the Fluid Dynamics of Disease Transmission Laboratory  ORG\n",
      "24: \"the Massachusetts Institute of Technology\" is a ORG  the Massachusetts Institute of Technology  ORG\n",
      "25: \"Bourouiba\" is a PERSON  Lydia Bourouiba  PERSON\n",
      "26: \"Canadian\" is a NORP  Canadian  NORP\n",
      "27: \"Mark Loeb\" is a PERSON  Mark Loeb  PERSON\n",
      "28: \"McMaster University\" is a ORG  McMaster University  ORG\n",
      "29: \"RNA\" is a ORG  RNA  ORG\n",
      "30: \"Wuhan\" is a GPE  Wuhan  GPE\n",
      "31: \"China\" is a GPE  China  GPE\n",
      "32: \"Nebraska\" is a GPE  Nebraska  GPE\n",
      "33: \"Canada\" is a GPE  Canada  GPE\n",
      "34: \"at least two metres\" is a CARDINAL  at least two metres  CARDINAL\n",
      "35: \"COVID-19\" is a ORG  COVID-19  ORG\n",
      "36: \"Gary Moore/CBC\" is a PERSON  Gary Moore/CBC  PERSON\n",
      "37: \"Allison McGeer\" is a PERSON  Allison McGeer  PERSON\n",
      "38: \"Sinai Health\" is a ORG  Sinai Health  ORG\n",
      "39: \"Toronto\" is a GPE  Toronto  GPE\n",
      "40: \"COVID-19\" is a PERSON  COVID-19  PERSON\n",
      "41: \"hundreds\" is a CARDINAL  hundreds  CARDINAL\n",
      "42: \"hours\" is a TIME  hours  TIME\n",
      "43: \"N-95\" is a PRODUCT  N-95  PRODUCT\n",
      "44: \"McGeer\" is a ORG  Allison McGeer  PERSON\n",
      "45: \"five minutes\" is a TIME  five minutes  TIME\n",
      "46: \"McGeer\" is a ORG  Allison McGeer  PERSON\n",
      "47: \"Bourouiba\" is a PERSON  Lydia Bourouiba  PERSON\n",
      "48: \"Bourouiba\" is a PERSON  Lydia Bourouiba  PERSON\n",
      "49: \"farther than two metres\" is a QUANTITY  farther than two metres  QUANTITY\n",
      "50: \"seven or eight metres\" is a QUANTITY  seven or eight metres  QUANTITY\n",
      "51: \"Credit Lydia Bourouiba/MIT/JAMA Networks\" is a ORG  Credit Lydia Bourouiba/MIT/JAMA Networks  ORG\n",
      "52: \"Canadian\" is a NORP  Canadian  NORP\n",
      "53: \"about one kilometre\" is a QUANTITY  about one kilometre  QUANTITY\n",
      "54: \"two-metre\" is a QUANTITY  two-metre  QUANTITY\n",
      "55: \"up to three minutes\" is a TIME  up to three minutes  TIME\n",
      "56: \"Samira Mubareka\" is a PERSON  Samira Mubareka  PERSON\n",
      "57: \"Sunnybrook Hospital\" is a FAC  Sunnybrook Hospital  FAC\n",
      "58: \"Toronto\" is a GPE  Toronto  GPE\n",
      "59: \"2-metre\" is a QUANTITY  2-metre  QUANTITY\n",
      "60: \"Bourouiba\" is a PERSON  Credit Lydia Bourouiba/MIT/JAMA Networks  ORG\n",
      "61: \"two metres\" is a QUANTITY  farther than two metres  QUANTITY\n",
      "62: \"March\" is a DATE  March  DATE\n",
      "63: \"farther than two metres\" is a QUANTITY  farther than two metres  QUANTITY\n",
      "64: \"two metres\" is a QUANTITY  farther than two metres  QUANTITY\n",
      "65: \"Mubareka\" is a PRODUCT  Samira Mubareka  PERSON\n",
      "66: \"two-metre\" is a QUANTITY  two-metre  QUANTITY\n",
      "67: \"Second\" is a ORDINAL  Second  ORDINAL\n",
      "68: \"COVID-19\" is a ORG  COVID-19  ORG\n",
      "69: \"McMaster\" is a PERSON  McMaster University  ORG\n",
      "70: \"N95\" is a ORG  N95  ORG\n",
      "71: \"U.S.\" is a GPE  U.S.  GPE\n",
      "72: \"Canadian\" is a NORP  Canadian  NORP\n",
      "73: \"Justin Trudeau\" is a PERSON  Justin Trudeau  PERSON\n",
      "74: \"Mubareka\" is a PERSON  Samira Mubareka  PERSON\n",
      "75: \"April 2020\" is a DATE  April 2020  DATE\n",
      "76: \"the New England Journal of Medicine\" is a ORG  the New England Journal of Medicine  ORG\n",
      "77: \"the U.S. National Institutes of Health\" is a ORG  the U.S. National Institutes of Health  ORG\n",
      "78: \"0:42\" is a DATE  0:42  DATE\n",
      "79: \"U.S. National Institutes of Health\" is a ORG  the U.S. National Institutes of Health  ORG\n",
      "80: \"less than 10\" is a CARDINAL  less than 10  CARDINAL\n",
      "81: \"COVID-19?\" is a ORG  COVID-19?  ORG\n",
      "82: \"2009\" is a DATE  2009  DATE\n",
      "83: \"Journal of the Royal Society Interface\" is a ORG  Journal of the Royal Society Interface  ORG\n",
      "84: \"2009\" is a DATE  2009  DATE\n",
      "85: \"U.S.\" is a GPE  the U.S. National Institutes of Health  ORG\n",
      "86: \"Singapore\" is a GPE  Singapore  GPE\n",
      "87: \"N95\" is a ORG  N95  ORG\n",
      "88: \"Gary S. Settles\" is a PERSON  Gary S. Settles  PERSON\n",
      "89: \"Penn State University/Journal of the Royal Society Interface\" is a ORG  Penn State University/Journal of the Royal Society Interface  ORG\n",
      "90: \"The World Health Organization\" is a ORG  The World Health Organization  ORG\n",
      "91: \"Los Angeles\" is a GPE  Los Angeles  GPE\n",
      "92: \"Italy\" is a GPE  Italy  GPE\n",
      "93: \"Austria\" is a GPE  Austria  GPE\n",
      "94: \"Saturday\" is a DATE  Saturday  DATE\n",
      "95: \"morning\" is a TIME  morning  TIME\n"
     ]
    }
   ],
   "source": [
    "# Testing using only the previous references as candidates\n",
    "test = df[\"text\"][1]\n",
    "# Parse the text with spaCy\n",
    "test_sp = sp(test)\n",
    "for i, token in enumerate(test_sp.ents):\n",
    "    ent = assign_normalized_form(test_sp.ents[i], test_sp.ents[0:i-1])\n",
    "    print(str(i) + \": \\\"\" + token.text + \"\\\" is a \" + token.label_ + \"  \" + ent.text + \"  \" + ent.label_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "peqky9sNx2u-"
   },
   "source": [
    "**(TO DO) Q4(b) - 2 points**\n",
    "\n",
    "Faites d'autres tests sans vous limiter à chercher des formes de surfaces plus longues mentionnées avant une entité (voir *test_sp.ents[0:i-1]* dans le code ci-haut), et chercher avant ou après. Ou chercher dans un intervalle (par exemple, max N entités avant ou après). Est-ce que cela fait une différence? Expliquez ce que vous avez testé et fournissez au moins 2 exemples de changements que vous remarquez."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "id": "TVBUJXKz1ODh"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: \"weekly\" is a DATE  weekly  DATE\n",
      "1: \"Saturday\" is a DATE  Saturday  DATE\n",
      "2: \"morning\" is a TIME  morning  TIME\n",
      "3: \"two metres\" is a QUANTITY  two metres  QUANTITY\n",
      "4: \"COVID-19\" is a PERSON  COVID-19  PERSON\n",
      "5: \"the World Health Organization\" is a ORG  the World Health Organization  ORG\n",
      "6: \"WHO\" is a ORG  WHO  ORG\n",
      "7: \"more than one metre\" is a QUANTITY  more than one metre  QUANTITY\n",
      "8: \"the Public Health Agency\" is a ORG  the Public Health Agency  ORG\n",
      "9: \"Canada\" is a GPE  Canada  GPE\n",
      "10: \"at least two metres\" is a QUANTITY  at least two metres  QUANTITY\n",
      "11: \"two\" is a CARDINAL  at least two metres  QUANTITY\n",
      "12: \"2 metres\" is a QUANTITY  2 metres  QUANTITY\n",
      "13: \"the 19th century\" is a DATE  the 19th century  DATE\n",
      "14: \"1934\" is a DATE  1934  DATE\n",
      "15: \"W.F. Wells\" is a PERSON  W.F. Wells  PERSON\n",
      "16: \"the Harvard School of Public Health\" is a ORG  the Harvard School of Public Health  ORG\n",
      "17: \"two metres\" is a QUANTITY  two metres  QUANTITY\n",
      "18: \"Wells\" is a ORG  W.F. Wells  PERSON\n",
      "19: \"56,000\" is a CARDINAL  56,000  CARDINAL\n",
      "20: \"Canada\" is a GPE  Canada  GPE\n",
      "21: \"Saturday\" is a DATE  Saturday  DATE\n",
      "22: \"Lydia Bourouiba\" is a PERSON  Lydia Bourouiba  PERSON\n",
      "23: \"the Fluid Dynamics of Disease Transmission Laboratory\" is a ORG  the Fluid Dynamics of Disease Transmission Laboratory  ORG\n",
      "24: \"the Massachusetts Institute of Technology\" is a ORG  the Massachusetts Institute of Technology  ORG\n",
      "25: \"Bourouiba\" is a PERSON  Lydia Bourouiba  PERSON\n",
      "26: \"Canadian\" is a NORP  Canadian  NORP\n",
      "27: \"Mark Loeb\" is a PERSON  Mark Loeb  PERSON\n",
      "28: \"McMaster University\" is a ORG  McMaster University  ORG\n",
      "29: \"RNA\" is a ORG  RNA  ORG\n",
      "30: \"Wuhan\" is a GPE  Wuhan  GPE\n",
      "31: \"China\" is a GPE  China  GPE\n",
      "32: \"Nebraska\" is a GPE  Nebraska  GPE\n",
      "33: \"Canada\" is a GPE  Canada  GPE\n",
      "34: \"at least two metres\" is a CARDINAL  at least two metres  CARDINAL\n",
      "35: \"COVID-19\" is a ORG  COVID-19  ORG\n",
      "36: \"Gary Moore/CBC\" is a PERSON  Gary Moore/CBC  PERSON\n",
      "37: \"Allison McGeer\" is a PERSON  Allison McGeer  PERSON\n",
      "38: \"Sinai Health\" is a ORG  Sinai Health  ORG\n",
      "39: \"Toronto\" is a GPE  Toronto  GPE\n",
      "40: \"COVID-19\" is a PERSON  COVID-19  PERSON\n",
      "41: \"hundreds\" is a CARDINAL  hundreds  CARDINAL\n",
      "42: \"hours\" is a TIME  hours  TIME\n",
      "43: \"N-95\" is a PRODUCT  N-95  PRODUCT\n",
      "44: \"McGeer\" is a ORG  McGeer  ORG\n",
      "45: \"five minutes\" is a TIME  five minutes  TIME\n",
      "46: \"McGeer\" is a ORG  McGeer  ORG\n",
      "47: \"Bourouiba\" is a PERSON  Credit Lydia Bourouiba/MIT/JAMA Networks  ORG\n",
      "48: \"Bourouiba\" is a PERSON  Credit Lydia Bourouiba/MIT/JAMA Networks  ORG\n",
      "49: \"farther than two metres\" is a QUANTITY  farther than two metres  QUANTITY\n",
      "50: \"seven or eight metres\" is a QUANTITY  seven or eight metres  QUANTITY\n",
      "51: \"Credit Lydia Bourouiba/MIT/JAMA Networks\" is a ORG  Credit Lydia Bourouiba/MIT/JAMA Networks  ORG\n",
      "52: \"Canadian\" is a NORP  Canadian  NORP\n",
      "53: \"about one kilometre\" is a QUANTITY  about one kilometre  QUANTITY\n",
      "54: \"two-metre\" is a QUANTITY  two-metre  QUANTITY\n",
      "55: \"up to three minutes\" is a TIME  up to three minutes  TIME\n",
      "56: \"Samira Mubareka\" is a PERSON  Samira Mubareka  PERSON\n",
      "57: \"Sunnybrook Hospital\" is a FAC  Sunnybrook Hospital  FAC\n",
      "58: \"Toronto\" is a GPE  Toronto  GPE\n",
      "59: \"2-metre\" is a QUANTITY  2-metre  QUANTITY\n",
      "60: \"Bourouiba\" is a PERSON  Bourouiba  PERSON\n",
      "61: \"two metres\" is a QUANTITY  farther than two metres  QUANTITY\n",
      "62: \"March\" is a DATE  March  DATE\n",
      "63: \"farther than two metres\" is a QUANTITY  farther than two metres  QUANTITY\n",
      "64: \"two metres\" is a QUANTITY  farther than two metres  QUANTITY\n",
      "65: \"Mubareka\" is a PRODUCT  Mubareka  PRODUCT\n",
      "66: \"two-metre\" is a QUANTITY  two-metre  QUANTITY\n",
      "67: \"Second\" is a ORDINAL  Second  ORDINAL\n",
      "68: \"COVID-19\" is a ORG  COVID-19  ORG\n",
      "69: \"McMaster\" is a PERSON  McMaster  PERSON\n",
      "70: \"N95\" is a ORG  N95  ORG\n",
      "71: \"U.S.\" is a GPE  U.S.  GPE\n",
      "72: \"Canadian\" is a NORP  Canadian  NORP\n",
      "73: \"Justin Trudeau\" is a PERSON  Justin Trudeau  PERSON\n",
      "74: \"Mubareka\" is a PERSON  Mubareka  PERSON\n",
      "75: \"April 2020\" is a DATE  April 2020  DATE\n",
      "76: \"the New England Journal of Medicine\" is a ORG  the New England Journal of Medicine  ORG\n",
      "77: \"the U.S. National Institutes of Health\" is a ORG  the U.S. National Institutes of Health  ORG\n",
      "78: \"0:42\" is a DATE  0:42  DATE\n",
      "79: \"U.S. National Institutes of Health\" is a ORG  the U.S. National Institutes of Health  ORG\n",
      "80: \"less than 10\" is a CARDINAL  less than 10  CARDINAL\n",
      "81: \"COVID-19?\" is a ORG  COVID-19?  ORG\n",
      "82: \"2009\" is a DATE  2009  DATE\n",
      "83: \"Journal of the Royal Society Interface\" is a ORG  Journal of the Royal Society Interface  ORG\n",
      "84: \"2009\" is a DATE  2009  DATE\n",
      "85: \"U.S.\" is a GPE  U.S.  GPE\n",
      "86: \"Singapore\" is a GPE  Singapore  GPE\n",
      "87: \"N95\" is a ORG  N95  ORG\n",
      "88: \"Gary S. Settles\" is a PERSON  Gary S. Settles  PERSON\n",
      "89: \"Penn State University/Journal of the Royal Society Interface\" is a ORG  Penn State University/Journal of the Royal Society Interface  ORG\n",
      "90: \"The World Health Organization\" is a ORG  The World Health Organization  ORG\n",
      "91: \"Los Angeles\" is a GPE  Los Angeles  GPE\n",
      "92: \"Italy\" is a GPE  Italy  GPE\n",
      "93: \"Austria\" is a GPE  Austria  GPE\n",
      "94: \"Saturday\" is a DATE  Saturday  DATE\n",
      "95: \"morning\" is a TIME  morning  TIME\n"
     ]
    }
   ],
   "source": [
    "# RÉPONSE Q4(b)\n",
    "# Do a different test\n",
    "# This test checks for a normalized form in a range of the word\n",
    "def assign_normalized_form_range(entity, entities, index):\n",
    "    tmp = entity\n",
    "    for token in entities[index-5:index+5]:\n",
    "        res = token.text.find(entity.text) # -1 = not found\n",
    "        if(len(token.text) > len(tmp.text) and res != -1):\n",
    "            tmp = token\n",
    "    #entity.label_ = tmp.label_\n",
    "    return tmp  \n",
    "\n",
    "for i, token in enumerate(test_sp.ents):\n",
    "    ent = assign_normalized_form_range(test_sp.ents[i], test_sp.ents, i)\n",
    "    print(str(i) + \": \\\"\" + token.text + \"\\\" is a \" + token.label_ + \"  \" + ent.text + \"  \" + ent.label_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7VAQRFOtyMNS"
   },
   "source": [
    "**RÉPONSE Q4(b)**\n",
    "En regardant pour une forme normalisé dans un intervalle de 10 mots (5 en avant et 5 en arrière) on remarque que certains mot comme \"Mubareka\" et \"McMaster\" perdent de leur sens. \"Samira Mubareka\" passe de PERSON à PRODUCT ce qui est faut. Cependant, certains mots comme \"U.S.\" reprennent de leur sens en passant de ORG à GPE. En utilisant un intervalle plutot qu'un le texte au complet, dans certains cas les mots sont corrigé au bon sens, mais dans la majorité des cas la méthode avec intervalle introduit plus d'erreurs que de corrections. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IcGDYUR31aNt"
   },
   "source": [
    "**(TO DO) Q5 - 5 points**  \n",
    "\n",
    "Utilisez un autre article de nouvelle dans le corpus, le 7e article, donc index 6.\n",
    "\n",
    "(a) (2 points) Exécutez les deux approches (NER la plus fréquente, NER de la forme la plus longue). Pour chaque entité trouvée dans le texte, imprimez son type d'entité d'origine (tel que trouvé par spaCy, puis le type d'entité le plus courant (résultat de Q3), puis la forme normalisée avec son type d'entité (résultat de Q4). \\\n",
    "(b) (3 points) Analyser et discuter les résultats. Pensez-vous que ces approches de cohérence de texte aident ou sont-elles trop simples ? Y a-t-il des résultats contradictoires (les deux approches donnent des résultats différents). Si oui, montrez des exemples différents.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "id": "0ZzLi33Ly3lV"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: Canada\n",
      "spaCY: GPE\n",
      "Forme normalisée: ORG\n",
      "La plus fréquente: GPE\n",
      "\n",
      "1: C.D. Howe\n",
      "spaCY: ORG\n",
      "Forme normalisée: ORG\n",
      "La plus fréquente: ORG\n",
      "\n",
      "2: Ontario\n",
      "spaCY: PERSON\n",
      "Forme normalisée: PERSON\n",
      "La plus fréquente: PERSON\n",
      "\n",
      "3: Monday\n",
      "spaCY: DATE\n",
      "Forme normalisée: DATE\n",
      "La plus fréquente: DATE\n",
      "\n",
      "4: Alberta\n",
      "spaCY: GPE\n",
      "Forme normalisée: GPE\n",
      "La plus fréquente: GPE\n",
      "\n",
      "5: first\n",
      "spaCY: ORDINAL\n",
      "Forme normalisée: ORDINAL\n",
      "La plus fréquente: ORDINAL\n",
      "\n",
      "6: Saturday\n",
      "spaCY: DATE\n",
      "Forme normalisée: DATE\n",
      "La plus fréquente: DATE\n",
      "\n",
      "7: Air Canada\n",
      "spaCY: ORG\n",
      "Forme normalisée: ORG\n",
      "La plus fréquente: ORG\n",
      "\n",
      "8: Christmas\n",
      "spaCY: DATE\n",
      "Forme normalisée: DATE\n",
      "La plus fréquente: DATE\n",
      "\n",
      "9: more than $1.2 million\n",
      "spaCY: MONEY\n",
      "Forme normalisée: MONEY\n",
      "La plus fréquente: MONEY\n",
      "\n",
      "10: England\n",
      "spaCY: GPE\n",
      "Forme normalisée: GPE\n",
      "La plus fréquente: GPE\n",
      "\n",
      "11: Peter Cziborra/Reuters\n",
      "spaCY: PERSON\n",
      "Forme normalisée: PERSON\n",
      "La plus fréquente: PERSON\n",
      "\n",
      "12: months\n",
      "spaCY: DATE\n",
      "Forme normalisée: DATE\n",
      "La plus fréquente: DATE\n",
      "\n",
      "13: CBC\n",
      "spaCY: ORG\n",
      "Forme normalisée: ORG\n",
      "La plus fréquente: ORG\n",
      "\n",
      "14: Andre Mayer\n",
      "spaCY: PERSON\n",
      "Forme normalisée: PERSON\n",
      "La plus fréquente: PERSON\n",
      "\n",
      "15: Canada\n",
      "spaCY: GPE\n",
      "Forme normalisée: ORG\n",
      "La plus fréquente: GPE\n",
      "\n",
      "16: 19th-century\n",
      "spaCY: DATE\n",
      "Forme normalisée: DATE\n",
      "La plus fréquente: DATE\n",
      "\n",
      "17: cholera\n",
      "spaCY: ORG\n",
      "Forme normalisée: ORG\n",
      "La plus fréquente: ORG\n",
      "\n",
      "18: 2013\n",
      "spaCY: DATE\n",
      "Forme normalisée: DATE\n",
      "La plus fréquente: DATE\n",
      "\n",
      "19: Calgary\n",
      "spaCY: GPE\n",
      "Forme normalisée: GPE\n",
      "La plus fréquente: GPE\n",
      "\n",
      "20: John Brown\n",
      "spaCY: PERSON\n",
      "Forme normalisée: PERSON\n",
      "La plus fréquente: PERSON\n",
      "\n",
      "21: the University of Calgary\n",
      "spaCY: ORG\n",
      "Forme normalisée: ORG\n",
      "La plus fréquente: ORG\n",
      "\n",
      "22: two-metre\n",
      "spaCY: QUANTITY\n",
      "Forme normalisée: QUANTITY\n",
      "La plus fréquente: QUANTITY\n",
      "\n",
      "23: Last week\n",
      "spaCY: DATE\n",
      "Forme normalisée: DATE\n",
      "La plus fréquente: DATE\n",
      "\n",
      "24: Italian\n",
      "spaCY: NORP\n",
      "Forme normalisée: NORP\n",
      "La plus fréquente: NORP\n",
      "\n",
      "25: Milan\n",
      "spaCY: GPE\n",
      "Forme normalisée: GPE\n",
      "La plus fréquente: GPE\n",
      "\n",
      "26: 35 kilometres\n",
      "spaCY: QUANTITY\n",
      "Forme normalisée: QUANTITY\n",
      "La plus fréquente: QUANTITY\n",
      "\n",
      "27: Berlin\n",
      "spaCY: GPE\n",
      "Forme normalisée: GPE\n",
      "La plus fréquente: GPE\n",
      "\n",
      "28: Budapest\n",
      "spaCY: GPE\n",
      "Forme normalisée: GPE\n",
      "La plus fréquente: GPE\n",
      "\n",
      "29: Mexico City\n",
      "spaCY: GPE\n",
      "Forme normalisée: GPE\n",
      "La plus fréquente: GPE\n",
      "\n",
      "30: Ahsan Habib\n",
      "spaCY: PERSON\n",
      "Forme normalisée: PERSON\n",
      "La plus fréquente: PERSON\n",
      "\n",
      "31: Dalhousie University\n",
      "spaCY: ORG\n",
      "Forme normalisée: ORG\n",
      "La plus fréquente: ORG\n",
      "\n",
      "32: U.S.\n",
      "spaCY: GPE\n",
      "Forme normalisée: GPE\n",
      "La plus fréquente: GPE\n",
      "\n",
      "33: Atlanta\n",
      "spaCY: GPE\n",
      "Forme normalisée: GPE\n",
      "La plus fréquente: GPE\n",
      "\n",
      "34: Chicago\n",
      "spaCY: GPE\n",
      "Forme normalisée: GPE\n",
      "La plus fréquente: GPE\n",
      "\n",
      "35: Denver\n",
      "spaCY: GPE\n",
      "Forme normalisée: GPE\n",
      "La plus fréquente: GPE\n",
      "\n",
      "36: Habib\n",
      "spaCY: PERSON\n",
      "Forme normalisée: PERSON\n",
      "La plus fréquente: PERSON\n",
      "\n",
      "37: Brown\n",
      "spaCY: PERSON\n",
      "Forme normalisée: PERSON\n",
      "La plus fréquente: PERSON\n",
      "\n",
      "38: Calgary\n",
      "spaCY: GPE\n",
      "Forme normalisée: ORG\n",
      "La plus fréquente: GPE\n",
      "\n",
      "39: Housebrand\n",
      "spaCY: ORG\n",
      "Forme normalisée: ORG\n",
      "La plus fréquente: ORG\n",
      "\n",
      "40: The National The At\n",
      "spaCY: WORK_OF_ART\n",
      "Forme normalisée: WORK_OF_ART\n",
      "La plus fréquente: WORK_OF_ART\n",
      "\n",
      "41: Quebec\n",
      "spaCY: GPE\n",
      "Forme normalisée: GPE\n",
      "La plus fréquente: GPE\n",
      "\n",
      "42: Conservative\n",
      "spaCY: NORP\n",
      "Forme normalisée: NORP\n",
      "La plus fréquente: NORP\n",
      "\n",
      "43: Canada\n",
      "spaCY: GPE\n",
      "Forme normalisée: ORG\n",
      "La plus fréquente: GPE\n",
      "\n",
      "44: C.D. Howe\n",
      "spaCY: ORG\n",
      "Forme normalisée: ORG\n",
      "La plus fréquente: ORG\n",
      "\n",
      "45: Canada\n",
      "spaCY: GPE\n",
      "Forme normalisée: ORG\n",
      "La plus fréquente: GPE\n",
      "\n",
      "46: the C.D. Howe Institute's\n",
      "spaCY: ORG\n",
      "Forme normalisée: ORG\n",
      "La plus fréquente: ORG\n",
      "\n",
      "47: Business Cycle Council\n",
      "spaCY: ORG\n",
      "Forme normalisée: ORG\n",
      "La plus fréquente: ORG\n",
      "\n",
      "48: today\n",
      "spaCY: DATE\n",
      "Forme normalisée: DATE\n",
      "La plus fréquente: DATE\n",
      "\n",
      "49: Canada\n",
      "spaCY: GPE\n",
      "Forme normalisée: ORG\n",
      "La plus fréquente: GPE\n",
      "\n",
      "50: February\n",
      "spaCY: DATE\n",
      "Forme normalisée: DATE\n",
      "La plus fréquente: DATE\n",
      "\n",
      "51: one\n",
      "spaCY: CARDINAL\n",
      "Forme normalisée: CARDINAL\n",
      "La plus fréquente: CARDINAL\n",
      "\n",
      "52: two\n",
      "spaCY: CARDINAL\n",
      "Forme normalisée: QUANTITY\n",
      "La plus fréquente: CARDINAL\n",
      "\n",
      "53: three-month\n",
      "spaCY: DATE\n",
      "Forme normalisée: DATE\n",
      "La plus fréquente: DATE\n",
      "\n",
      "54: less than two months old\n",
      "spaCY: DATE\n",
      "Forme normalisée: DATE\n",
      "La plus fréquente: DATE\n",
      "\n",
      "55: Canada\n",
      "spaCY: GPE\n",
      "Forme normalisée: ORG\n",
      "La plus fréquente: GPE\n",
      "\n",
      "56: first\n",
      "spaCY: ORDINAL\n",
      "Forme normalisée: ORDINAL\n",
      "La plus fréquente: ORDINAL\n",
      "\n",
      "57: Canada\n",
      "spaCY: GPE\n",
      "Forme normalisée: ORG\n",
      "La plus fréquente: GPE\n",
      "\n",
      "58: 2008\n",
      "spaCY: DATE\n",
      "Forme normalisée: DATE\n",
      "La plus fréquente: DATE\n",
      "\n",
      "59: March\n",
      "spaCY: DATE\n",
      "Forme normalisée: DATE\n",
      "La plus fréquente: DATE\n",
      "\n",
      "60: April\n",
      "spaCY: DATE\n",
      "Forme normalisée: DATE\n",
      "La plus fréquente: DATE\n",
      "\n",
      "61: the entire month\n",
      "spaCY: DATE\n",
      "Forme normalisée: DATE\n",
      "La plus fréquente: DATE\n",
      "\n",
      "62: Canada\n",
      "spaCY: GPE\n",
      "Forme normalisée: ORG\n",
      "La plus fréquente: GPE\n",
      "\n",
      "63: Monday\n",
      "spaCY: DATE\n",
      "Forme normalisée: DATE\n",
      "La plus fréquente: DATE\n",
      "\n",
      "64: Alberta\n",
      "spaCY: GPE\n",
      "Forme normalisée: GPE\n",
      "La plus fréquente: GPE\n",
      "\n",
      "65: Saturday\n",
      "spaCY: DATE\n",
      "Forme normalisée: DATE\n",
      "La plus fréquente: DATE\n",
      "\n",
      "66: today\n",
      "spaCY: DATE\n",
      "Forme normalisée: DATE\n",
      "La plus fréquente: DATE\n",
      "\n",
      "67: Monday\n",
      "spaCY: DATE\n",
      "Forme normalisée: DATE\n",
      "La plus fréquente: DATE\n",
      "\n",
      "68: Today\n",
      "spaCY: DATE\n",
      "Forme normalisée: DATE\n",
      "La plus fréquente: DATE\n",
      "\n",
      "69: Doug Ford\n",
      "spaCY: PERSON\n",
      "Forme normalisée: PERSON\n",
      "La plus fréquente: PERSON\n",
      "\n",
      "70: Alberta\n",
      "spaCY: GPE\n",
      "Forme normalisée: GPE\n",
      "La plus fréquente: GPE\n",
      "\n",
      "71: Jason Kenney\n",
      "spaCY: PERSON\n",
      "Forme normalisée: PERSON\n",
      "La plus fréquente: PERSON\n",
      "\n",
      "72: first\n",
      "spaCY: ORDINAL\n",
      "Forme normalisée: ORDINAL\n",
      "La plus fréquente: ORDINAL\n",
      "\n",
      "73: Alberta\n",
      "spaCY: GPE\n",
      "Forme normalisée: GPE\n",
      "La plus fréquente: GPE\n",
      "\n",
      "74: Saturday\n",
      "spaCY: DATE\n",
      "Forme normalisée: DATE\n",
      "La plus fréquente: DATE\n",
      "\n",
      "75: mid-May.\n",
      "spaCY: DATE\n",
      "Forme normalisée: DATE\n",
      "La plus fréquente: DATE\n",
      "\n",
      "76: Kenney\n",
      "spaCY: ORG\n",
      "Forme normalisée: PERSON\n",
      "La plus fréquente: ORG\n",
      "\n",
      "77: Thursday\n",
      "spaCY: DATE\n",
      "Forme normalisée: DATE\n",
      "La plus fréquente: DATE\n",
      "\n",
      "78: Monday\n",
      "spaCY: DATE\n",
      "Forme normalisée: DATE\n",
      "La plus fréquente: DATE\n",
      "\n",
      "79: the academic year\n",
      "spaCY: DATE\n",
      "Forme normalisée: DATE\n",
      "La plus fréquente: DATE\n",
      "\n",
      "80: Kenney\n",
      "spaCY: ORG\n",
      "Forme normalisée: PERSON\n",
      "La plus fréquente: ORG\n",
      "\n",
      "81: summer\n",
      "spaCY: DATE\n",
      "Forme normalisée: DATE\n",
      "La plus fréquente: DATE\n",
      "\n",
      "82: Canada\n",
      "spaCY: GPE\n",
      "Forme normalisée: ORG\n",
      "La plus fréquente: GPE\n",
      "\n",
      "83: Christmas\n",
      "spaCY: DATE\n",
      "Forme normalisée: DATE\n",
      "La plus fréquente: DATE\n",
      "\n",
      "84: Air Canada\n",
      "spaCY: ORG\n",
      "Forme normalisée: ORG\n",
      "La plus fréquente: ORG\n",
      "\n",
      "85: Canadians\n",
      "spaCY: NORP\n",
      "Forme normalisée: NORP\n",
      "La plus fréquente: NORP\n",
      "\n",
      "86: Tim Strauss\n",
      "spaCY: PERSON\n",
      "Forme normalisée: PERSON\n",
      "La plus fréquente: PERSON\n",
      "\n",
      "87: Canadian\n",
      "spaCY: NORP\n",
      "Forme normalisée: NORP\n",
      "La plus fréquente: NORP\n",
      "\n",
      "88: Air Canada\n",
      "spaCY: ORG\n",
      "Forme normalisée: ORG\n",
      "La plus fréquente: ORG\n",
      "\n",
      "89: more than\n",
      "spaCY: CARDINAL\n",
      "Forme normalisée: MONEY\n",
      "La plus fréquente: CARDINAL\n",
      "\n",
      "90: Canadian Club Toronto\n",
      "spaCY: ORG\n",
      "Forme normalisée: ORG\n",
      "La plus fréquente: ORG\n",
      "\n",
      "91: today\n",
      "spaCY: DATE\n",
      "Forme normalisée: DATE\n",
      "La plus fréquente: DATE\n",
      "\n",
      "92: North American\n",
      "spaCY: NORP\n",
      "Forme normalisée: NORP\n",
      "La plus fréquente: NORP\n",
      "\n",
      "93: Air Canada\n",
      "spaCY: ORG\n",
      "Forme normalisée: ORG\n",
      "La plus fréquente: ORG\n",
      "\n",
      "94: Sunwing and American Airlines\n",
      "spaCY: ORG\n",
      "Forme normalisée: ORG\n",
      "La plus fréquente: ORG\n",
      "\n",
      "95: Canada\n",
      "spaCY: GPE\n",
      "Forme normalisée: ORG\n",
      "La plus fréquente: GPE\n",
      "\n",
      "96: two metres\n",
      "spaCY: QUANTITY\n",
      "Forme normalisée: QUANTITY\n",
      "La plus fréquente: QUANTITY\n",
      "\n",
      "97: Air Canada\n",
      "spaCY: ORG\n",
      "Forme normalisée: ORG\n",
      "La plus fréquente: ORG\n",
      "\n",
      "98: Christmas\n",
      "spaCY: DATE\n",
      "Forme normalisée: DATE\n",
      "La plus fréquente: DATE\n",
      "\n",
      "99: Helane Becker\n",
      "spaCY: PERSON\n",
      "Forme normalisée: PERSON\n",
      "La plus fréquente: PERSON\n",
      "\n",
      "100: first\n",
      "spaCY: ORDINAL\n",
      "Forme normalisée: ORDINAL\n",
      "La plus fréquente: ORDINAL\n",
      "\n",
      "101: Becker\n",
      "spaCY: PERSON\n",
      "Forme normalisée: PERSON\n",
      "La plus fréquente: PERSON\n",
      "\n",
      "102: Canada\n",
      "spaCY: GPE\n",
      "Forme normalisée: ORG\n",
      "La plus fréquente: GPE\n",
      "\n",
      "103: CBC News\n",
      "spaCY: ORG\n",
      "Forme normalisée: ORG\n",
      "La plus fréquente: ORG\n",
      "\n",
      "104: U.S.\n",
      "spaCY: GPE\n",
      "Forme normalisée: GPE\n",
      "La plus fréquente: GPE\n",
      "\n",
      "105: U.S.\n",
      "spaCY: GPE\n",
      "Forme normalisée: GPE\n",
      "La plus fréquente: GPE\n",
      "\n",
      "106: Anthony Fauci\n",
      "spaCY: PERSON\n",
      "Forme normalisée: PERSON\n",
      "La plus fréquente: PERSON\n",
      "\n",
      "107: Canada\n",
      "spaCY: GPE\n",
      "Forme normalisée: ORG\n",
      "La plus fréquente: GPE\n",
      "\n",
      "108: Canada\n",
      "spaCY: GPE\n",
      "Forme normalisée: ORG\n",
      "La plus fréquente: GPE\n",
      "\n",
      "109: Health Canada\n",
      "spaCY: ORG\n",
      "Forme normalisée: ORG\n",
      "La plus fréquente: ORG\n",
      "\n",
      "110: Gilead\n",
      "spaCY: ORG\n",
      "Forme normalisée: ORG\n",
      "La plus fréquente: ORG\n",
      "\n",
      "111: CBC News\n",
      "spaCY: ORG\n",
      "Forme normalisée: ORG\n",
      "La plus fréquente: ORG\n",
      "\n",
      "112: Gilead\n",
      "spaCY: ORG\n",
      "Forme normalisée: ORG\n",
      "La plus fréquente: ORG\n",
      "\n",
      "113: Canada\n",
      "spaCY: GPE\n",
      "Forme normalisée: ORG\n",
      "La plus fréquente: GPE\n",
      "\n",
      "114: Alberta\n",
      "spaCY: GPE\n",
      "Forme normalisée: GPE\n",
      "La plus fréquente: GPE\n",
      "\n",
      "115: daily\n",
      "spaCY: DATE\n",
      "Forme normalisée: DATE\n",
      "La plus fréquente: DATE\n",
      "\n",
      "116: Grace Horsfall Couldwell\n",
      "spaCY: PERSON\n",
      "Forme normalisée: PERSON\n",
      "La plus fréquente: PERSON\n",
      "\n",
      "117: daily\n",
      "spaCY: DATE\n",
      "Forme normalisée: DATE\n",
      "La plus fréquente: DATE\n",
      "\n",
      "118: Alberta\n",
      "spaCY: GPE\n",
      "Forme normalisée: GPE\n",
      "La plus fréquente: GPE\n",
      "\n",
      "119: MJ Stead\n",
      "spaCY: PERSON\n",
      "Forme normalisée: PERSON\n",
      "La plus fréquente: PERSON\n",
      "\n",
      "120: Lori Toma\n",
      "spaCY: PERSON\n",
      "Forme normalisée: PERSON\n",
      "La plus fréquente: PERSON\n",
      "\n",
      "121: Nancy Horsfall Couldwell\n",
      "spaCY: PERSON\n",
      "Forme normalisée: PERSON\n",
      "La plus fréquente: PERSON\n",
      "\n",
      "122: Cochrane\n",
      "spaCY: ORG\n",
      "Forme normalisée: ORG\n",
      "La plus fréquente: ORG\n",
      "\n",
      "123: Alta\n",
      "spaCY: ORG\n",
      "Forme normalisée: ORG\n",
      "La plus fréquente: ORG\n",
      "\n",
      "124: MJ Stead\n",
      "spaCY: PERSON\n",
      "Forme normalisée: PERSON\n",
      "La plus fréquente: PERSON\n",
      "\n",
      "125: Facebook\n",
      "spaCY: PRODUCT\n",
      "Forme normalisée: PRODUCT\n",
      "La plus fréquente: PRODUCT\n",
      "\n",
      "126: Stead\n",
      "spaCY: PERSON\n",
      "Forme normalisée: PERSON\n",
      "La plus fréquente: PERSON\n",
      "\n",
      "127: hour-long\n",
      "spaCY: TIME\n",
      "Forme normalisée: TIME\n",
      "La plus fréquente: TIME\n",
      "\n",
      "128: Facebook Live\n",
      "spaCY: PRODUCT\n",
      "Forme normalisée: PRODUCT\n",
      "La plus fréquente: PRODUCT\n",
      "\n",
      "129: 20\n",
      "spaCY: CARDINAL\n",
      "Forme normalisée: DATE\n",
      "La plus fréquente: CARDINAL\n",
      "\n",
      "130: 30\n",
      "spaCY: CARDINAL\n",
      "Forme normalisée: CARDINAL\n",
      "La plus fréquente: CARDINAL\n",
      "\n",
      "131: more than 1,500\n",
      "spaCY: CARDINAL\n",
      "Forme normalisée: CARDINAL\n",
      "La plus fréquente: CARDINAL\n",
      "\n",
      "132: more than one\n",
      "spaCY: CARDINAL\n",
      "Forme normalisée: CARDINAL\n",
      "La plus fréquente: CARDINAL\n",
      "\n",
      "133: Two years ago\n",
      "spaCY: DATE\n",
      "Forme normalisée: DATE\n",
      "La plus fréquente: DATE\n",
      "\n",
      "134: Stead\n",
      "spaCY: PERSON\n",
      "Forme normalisée: PERSON\n",
      "La plus fréquente: PERSON\n",
      "\n",
      "135: 100 days\n",
      "spaCY: DATE\n",
      "Forme normalisée: DATE\n",
      "La plus fréquente: DATE\n",
      "\n",
      "136: COVID-19\n",
      "spaCY: ORG\n",
      "Forme normalisée: ORG\n",
      "La plus fréquente: ORG\n",
      "\n",
      "137: Canada\n",
      "spaCY: GPE\n",
      "Forme normalisée: ORG\n",
      "La plus fréquente: GPE\n",
      "\n",
      "138: CBC News\n",
      "spaCY: ORG\n",
      "Forme normalisée: ORG\n",
      "La plus fréquente: ORG\n",
      "\n",
      "139: daily\n",
      "spaCY: DATE\n",
      "Forme normalisée: DATE\n",
      "La plus fréquente: DATE\n",
      "\n",
      "140: CBC News Network\n",
      "spaCY: ORG\n",
      "Forme normalisée: ORG\n",
      "La plus fréquente: ORG\n",
      "\n",
      "141: CBC News Network\n",
      "spaCY: ORG\n",
      "Forme normalisée: ORG\n",
      "La plus fréquente: ORG\n",
      "\n",
      "142: CBC\n",
      "spaCY: ORG\n",
      "Forme normalisée: ORG\n",
      "La plus fréquente: ORG\n",
      "\n",
      "143: CBC News Network\n",
      "spaCY: ORG\n",
      "Forme normalisée: ORG\n",
      "La plus fréquente: ORG\n",
      "\n",
      "144: CBC News\n",
      "spaCY: ORG\n",
      "Forme normalisée: ORG\n",
      "La plus fréquente: ORG\n",
      "\n",
      "145: NaN\n",
      "spaCY: DATE\n",
      "Forme normalisée: DATE\n",
      "La plus fréquente: DATE\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# RÉPONSE Q5(a) \n",
    "# Select document index 6\n",
    "doc = df[\"text\"][6]\n",
    "q5 = sp(doc)\n",
    "\n",
    "for i, token in enumerate(q5.ents):\n",
    "    print(str(i) + \": \" + token.text)\n",
    "    print(\"spaCY: \" + token.label_)\n",
    "    longest = assign_normalized_form(q5.ents[i], q5.ents[0:i-1])\n",
    "    print(\"Forme normalisée: \" + longest.label_)\n",
    "    mostFrequent = most_common_type(q5.ents[i], q5.ents)\n",
    "    print(\"La plus fréquente: \" + mostFrequent)\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Aozt4Y_a1aNu"
   },
   "source": [
    "**RÉPONSE Q5(b) - 3 point**     \n",
    "\n",
    "Ces approches sont trop simples. Pour l'approche de la forme normalisée, cette approche semble mieux fonctionner pour des noms de personne que celle de spaCY et l'approche de la plus fréquente. Exemple, pour le nom Kenney (76 et 80), spaCY et l'approche de la plus fréquente identifient ce mot comme étant une organisation tandis l'approche de la forme normalisée l'identifie comme étant une personne ce qui est la bonne réponse. Par contre, l'approche de la forme normalisé semble faire plus d'erreurs que l'approche spaCY et l'approche de la plus fréquente pour identifié des entités géopolitiques. Par exemples, le mot Canada et Calgary (0 et 38 respectivement) qui sont identifiés comme ORG par la forme normalisée tandis que la bonne réponse est GPE. On peut donc conclure que ces approches sont trop simples, car elles laissent encore trop d'erreurs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0TsrNmD71aNz"
   },
   "source": [
    "**PARTIE 3 - Linking d'entité / Enrichissement du texte**  \n",
    "\n",
    "Pour la troisième partie de ce notebook, nous explorerons comment nous pouvons fournir une \"valeur ajoutée\" au texte des documents. Dans ce scénario, nous enrichirons le texte en effectuant un linking d'entité. \n",
    "\n",
    "Cela signifie que nous tenterons de relier les entités détectées par le NER de spaCy à une page Web active sur laquelle un lecteur peut cliquer pour obtenir plus d'informations concernant l'entité. Wikipedia est une très bonne ressource pour trouver plus d'informations sur une entité, et nous utiliserons cette ressource pour le linking d'entités.\n",
    "\n",
    "Avant de tenter de faire cette opération automatiquement, voici un exemple de la façon dont un texte sans linking d'entité se compare à un texte enrichi avec linking d'entité fait manuellement:\n",
    "\n",
    "*Aucun linking d'entité:* \\\n",
    "Pendant la pandémie, des villes américaines telles que Atlanta, Chicago et Denver ont apporté plusieurs ajustements à leurs systèmes de transport en commun.\n",
    "\n",
    "*Avec linking d'entité:* \\\n",
    "Pendant la pandémie, des villes américaines telles que <a href=\"http://en.wikipedia.org/wiki/Atlanta\"> Atlanta </a>, <a href = \"http://en.wikipedia.org/wiki / Chicago \"> Chicago </a> et <a href=\"http://en.wikipedia.org/wiki/Denver\"> Denver </a> ont apporté plusieurs ajustements à leurs systèmes de transport en commun."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VgJ8_9oq1aNz"
   },
   "source": [
    "Transformer un texte automatiquement avec des liens cliquables demande plusieurs traitements au niveau des chaînes de caractères.  Nous nous contenterons dans ce Notebook de trouver les liens sans faire les remplacements directement dans le texte.  Cela nous permettra d'explorer la ressource Wikipedia, et comprendre les difficultés relatives au \"entity linking\" sans perdre trop de temps dans la manipulation complexe de chaînes de caractères.\n",
    "\n",
    "Par exemple, avec le document (index 6), nous voudrions pouvoir lier les entités trouvées par spaCy à la page wikipedia la plus probable donnant accès à de l'information supplémentaire sur cette entité.\n",
    "\n",
    "**Le format ci-bas de liste enrichie est le type de résultat demandé à la question Q6 ci-après.**  Pour simplifier votre code, nous utiliserons ce genre de sortie plutôt que d'avoir les liens directement dans le texte.\n",
    "\n",
    "0: \"Coronavirus Brief\" is a ORG found at http://en.wikipedia.org/wiki/Coronavirus_Brief \\\n",
    "1: \"CBC\" is a ORG found at http://en.wikipedia.org/wiki/CBC \\\n",
    "2: \"Canada\" is a GPE found at http://en.wikipedia.org/wiki/Canada \\\n",
    "3: \"C.D. Howe\" is a PERSON found at http://en.wikipedia.org/wiki/C.D._Howe \\\n",
    "4: ... \\\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DnoLBMST1h5-"
   },
   "source": [
    "**(TO DO) Q6 - 5 points**  \\\n",
    "Écrivez le code nécessaire pour faire la recherche d'une page wikipedia pour les entités trouvées par spaCy (tel qu'illustré ci-haut) dans un document particulier.\n",
    "\n",
    "*Vous pouvez écrire ce code comme vous le souhaitez, mais il faut inclure les éléments suivants :*\n",
    "\n",
    "* (a) Une restriction sur le type d'entités que vous liez. Par exemple, Wikipedia ne contient pas de quantités (tel \"two meters\") il serait alors inadéquat d'inclure un lien vers une quantité.\n",
    "* (b) L'utilisation de la *forme normalisée* de l'entité pour effectuer la liaison. Par exemple, *Allison McGeer* a une page Wikipédia (https://en.wikipedia.org/wiki/Allison_McGeer) vers laquelle vous pouvez créer un lien, même lorsque vous regardez l'entité avec l'étiquette *McGeer*. Assurez-vous donc d'utiliser la fonction que vous avez développée à la Question 4 (Q4).\n",
    "* (c) Attention : la page wikipedia utilise des traits de soulignement. Ainsi, par exemple, *McMaster University* doit être transformé en https://en.wikipedia.org/wiki/McMaster_University (avec un trait de soulignement entre *McMaster* et *University*)\n",
    "* (d) Inclure un élément de post-traitement sur la forme de surface la plus longue trouvée. Par exemple, *the C.D. Howe Institute's* est trouvé par spaCy, mais Wikipédia contiendra *C.D._Howe_Institute*. Vous pouvez supprimer les petites particules comme *the* pour augmenter les chances de lien.\n",
    "* (e) Pour un document à l'entrée, imprimez une liste des formes de surface, type d'entité et lien vers Wikipedia (tel que montré ci-haut)\n",
    "\n",
    "Assurez-vous de mettre des commentaires dans votre code pour indiquer clairement ce qui correspond aux parties (a), (b), (c), (d) et (e).\n",
    "\n",
    "Il y aura probablement de nombreux liens qui mènent vers des pages Wikipedia inexistante.  C'est bon, ne vous inquiétez pas pour ça. Wikipédia ne contient pas tout, et certaines formes normalisées n'y seront pas. On vous demandera de discuter les résultats du linking à la question 7.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "id": "cQtDrwKW1aN2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: \"Health Canada\" is a ORG found at https://en.wikipedia.org/wiki/Health_Canada\n",
      "1: \"C.D. Howe\" is a ORG found at https://en.wikipedia.org/wiki/C.D._Howe\n",
      "2: \"Ontario\" is a PERSON found at https://en.wikipedia.org/wiki/Ontario\n",
      "3: \"Monday\" is a DATE found at https://en.wikipedia.org/wiki/Monday\n",
      "4: \"Alberta\" is a GPE found at https://en.wikipedia.org/wiki/Alberta\n",
      "5: \"first\" is a ORDINAL found at https://en.wikipedia.org/wiki/first\n",
      "6: \"Saturday\" is a DATE found at https://en.wikipedia.org/wiki/Saturday\n",
      "7: \"Air Canada\" is a ORG found at https://en.wikipedia.org/wiki/Air_Canada\n",
      "8: \"Christmas\" is a DATE found at https://en.wikipedia.org/wiki/Christmas\n",
      "9: \"more than $1.2 million\" is a MONEY found at https://en.wikipedia.org/wiki/$1.2_million\n",
      "10: \"England\" is a GPE found at https://en.wikipedia.org/wiki/England\n",
      "11: \"Peter Cziborra/Reuters\" is a PERSON found at https://en.wikipedia.org/wiki/Peter_Cziborra/Reuters\n",
      "12: \"months\" is a DATE found at https://en.wikipedia.org/wiki/months\n",
      "13: \"CBC\" is a ORG found at https://en.wikipedia.org/wiki/CBC\n",
      "14: \"Andre Mayer\" is a PERSON found at https://en.wikipedia.org/wiki/Andre_Mayer\n",
      "15: \"Air Canada\" is a ORG found at https://en.wikipedia.org/wiki/Air_Canada\n",
      "16: \"19th-century\" is a DATE found at https://en.wikipedia.org/wiki/19th-century\n",
      "17: \"cholera\" is a ORG found at https://en.wikipedia.org/wiki/cholera\n",
      "18: \"2013\" is a DATE found at https://en.wikipedia.org/wiki/2013\n",
      "19: \"Calgary\" is a GPE found at https://en.wikipedia.org/wiki/Calgary\n",
      "20: \"John Brown\" is a PERSON found at https://en.wikipedia.org/wiki/John_Brown\n",
      "21: \"the University of Calgary\" is a ORG found at https://en.wikipedia.org/wiki/University_of_Calgary\n",
      "22: \"two-metre\" is a QUANTITY\n",
      "23: \"Last week\" is a DATE found at https://en.wikipedia.org/wiki/Last_week\n",
      "24: \"Italian\" is a NORP found at https://en.wikipedia.org/wiki/Italian\n",
      "25: \"Milan\" is a GPE found at https://en.wikipedia.org/wiki/Milan\n",
      "26: \"35 kilometres\" is a QUANTITY\n",
      "27: \"Berlin\" is a GPE found at https://en.wikipedia.org/wiki/Berlin\n",
      "28: \"Budapest\" is a GPE found at https://en.wikipedia.org/wiki/Budapest\n",
      "29: \"Mexico City\" is a GPE found at https://en.wikipedia.org/wiki/Mexico_City\n",
      "30: \"Ahsan Habib\" is a PERSON found at https://en.wikipedia.org/wiki/Ahsan_Habib\n",
      "31: \"Dalhousie University\" is a ORG found at https://en.wikipedia.org/wiki/Dalhousie_University\n",
      "32: \"U.S.\" is a GPE found at https://en.wikipedia.org/wiki/U.S.\n",
      "33: \"Atlanta\" is a GPE found at https://en.wikipedia.org/wiki/Atlanta\n",
      "34: \"Chicago\" is a GPE found at https://en.wikipedia.org/wiki/Chicago\n",
      "35: \"Denver\" is a GPE found at https://en.wikipedia.org/wiki/Denver\n",
      "36: \"Ahsan Habib\" is a PERSON found at https://en.wikipedia.org/wiki/Ahsan_Habib\n",
      "37: \"John Brown\" is a PERSON found at https://en.wikipedia.org/wiki/John_Brown\n",
      "38: \"the University of Calgary\" is a ORG found at https://en.wikipedia.org/wiki/University_of_Calgary\n",
      "39: \"Housebrand\" is a ORG found at https://en.wikipedia.org/wiki/Housebrand\n",
      "40: \"The National The At\" is a WORK_OF_ART found at https://en.wikipedia.org/wiki/The_National_The_At\n",
      "41: \"Quebec\" is a GPE found at https://en.wikipedia.org/wiki/Quebec\n",
      "42: \"Conservative\" is a NORP found at https://en.wikipedia.org/wiki/Conservative\n",
      "43: \"Air Canada\" is a ORG found at https://en.wikipedia.org/wiki/Air_Canada\n",
      "44: \"C.D. Howe\" is a ORG found at https://en.wikipedia.org/wiki/C.D._Howe\n",
      "45: \"Air Canada\" is a ORG found at https://en.wikipedia.org/wiki/Air_Canada\n",
      "46: \"the C.D. Howe Institute's\" is a ORG found at https://en.wikipedia.org/wiki/C.D._Howe_Institute\n",
      "47: \"Business Cycle Council\" is a ORG found at https://en.wikipedia.org/wiki/Business_Cycle_Council\n",
      "48: \"today\" is a DATE found at https://en.wikipedia.org/wiki/today\n",
      "49: \"Air Canada\" is a ORG found at https://en.wikipedia.org/wiki/Air_Canada\n",
      "50: \"February\" is a DATE found at https://en.wikipedia.org/wiki/February\n",
      "51: \"one\" is a CARDINAL\n",
      "52: \"two-metre\" is a QUANTITY\n",
      "53: \"three-month\" is a DATE found at https://en.wikipedia.org/wiki/three-month\n",
      "54: \"less than two months old\" is a DATE found at https://en.wikipedia.org/wiki/less__two_months_old\n",
      "55: \"Air Canada\" is a ORG found at https://en.wikipedia.org/wiki/Air_Canada\n",
      "56: \"first\" is a ORDINAL found at https://en.wikipedia.org/wiki/first\n",
      "57: \"Air Canada\" is a ORG found at https://en.wikipedia.org/wiki/Air_Canada\n",
      "58: \"2008\" is a DATE found at https://en.wikipedia.org/wiki/2008\n",
      "59: \"March\" is a DATE found at https://en.wikipedia.org/wiki/March\n",
      "60: \"April\" is a DATE found at https://en.wikipedia.org/wiki/April\n",
      "61: \"the entire month\" is a DATE found at https://en.wikipedia.org/wiki/entire_month\n",
      "62: \"Air Canada\" is a ORG found at https://en.wikipedia.org/wiki/Air_Canada\n",
      "63: \"Monday\" is a DATE found at https://en.wikipedia.org/wiki/Monday\n",
      "64: \"Alberta\" is a GPE found at https://en.wikipedia.org/wiki/Alberta\n",
      "65: \"Saturday\" is a DATE found at https://en.wikipedia.org/wiki/Saturday\n",
      "66: \"today\" is a DATE found at https://en.wikipedia.org/wiki/today\n",
      "67: \"Monday\" is a DATE found at https://en.wikipedia.org/wiki/Monday\n",
      "68: \"Today\" is a DATE found at https://en.wikipedia.org/wiki/Today\n",
      "69: \"Doug Ford\" is a PERSON found at https://en.wikipedia.org/wiki/Doug_Ford\n",
      "70: \"Alberta\" is a GPE found at https://en.wikipedia.org/wiki/Alberta\n",
      "71: \"Jason Kenney\" is a PERSON found at https://en.wikipedia.org/wiki/Jason_Kenney\n",
      "72: \"first\" is a ORDINAL found at https://en.wikipedia.org/wiki/first\n",
      "73: \"Alberta\" is a GPE found at https://en.wikipedia.org/wiki/Alberta\n",
      "74: \"Saturday\" is a DATE found at https://en.wikipedia.org/wiki/Saturday\n",
      "75: \"mid-May.\" is a DATE found at https://en.wikipedia.org/wiki/mid-May.\n",
      "76: \"Jason Kenney\" is a PERSON found at https://en.wikipedia.org/wiki/Jason_Kenney\n",
      "77: \"Thursday\" is a DATE found at https://en.wikipedia.org/wiki/Thursday\n",
      "78: \"Monday\" is a DATE found at https://en.wikipedia.org/wiki/Monday\n",
      "79: \"the academic year\" is a DATE found at https://en.wikipedia.org/wiki/academic_year\n",
      "80: \"Jason Kenney\" is a PERSON found at https://en.wikipedia.org/wiki/Jason_Kenney\n",
      "81: \"summer\" is a DATE found at https://en.wikipedia.org/wiki/summer\n",
      "82: \"Air Canada\" is a ORG found at https://en.wikipedia.org/wiki/Air_Canada\n",
      "83: \"Christmas\" is a DATE found at https://en.wikipedia.org/wiki/Christmas\n",
      "84: \"Air Canada\" is a ORG found at https://en.wikipedia.org/wiki/Air_Canada\n",
      "85: \"Canadians\" is a NORP found at https://en.wikipedia.org/wiki/Canadians\n",
      "86: \"Tim Strauss\" is a PERSON found at https://en.wikipedia.org/wiki/Tim_Strauss\n",
      "87: \"Canadians\" is a NORP found at https://en.wikipedia.org/wiki/Canadians\n",
      "88: \"Air Canada\" is a ORG found at https://en.wikipedia.org/wiki/Air_Canada\n",
      "89: \"more than $1.2 million\" is a MONEY found at https://en.wikipedia.org/wiki/$1.2_million\n",
      "90: \"Canadian Club Toronto\" is a ORG found at https://en.wikipedia.org/wiki/Canadian_Club_Toronto\n",
      "91: \"today\" is a DATE found at https://en.wikipedia.org/wiki/today\n",
      "92: \"North American\" is a NORP found at https://en.wikipedia.org/wiki/North_American\n",
      "93: \"Air Canada\" is a ORG found at https://en.wikipedia.org/wiki/Air_Canada\n",
      "94: \"Sunwing and American Airlines\" is a ORG found at https://en.wikipedia.org/wiki/Sunwing__American_Airlines\n",
      "95: \"Air Canada\" is a ORG found at https://en.wikipedia.org/wiki/Air_Canada\n",
      "96: \"two metres\" is a QUANTITY\n",
      "97: \"Air Canada\" is a ORG found at https://en.wikipedia.org/wiki/Air_Canada\n",
      "98: \"Christmas\" is a DATE found at https://en.wikipedia.org/wiki/Christmas\n",
      "99: \"Helane Becker\" is a PERSON found at https://en.wikipedia.org/wiki/Helane_Becker\n",
      "100: \"first\" is a ORDINAL found at https://en.wikipedia.org/wiki/first\n",
      "101: \"Helane Becker\" is a PERSON found at https://en.wikipedia.org/wiki/Helane_Becker\n",
      "102: \"Air Canada\" is a ORG found at https://en.wikipedia.org/wiki/Air_Canada\n",
      "103: \"CBC News\" is a ORG found at https://en.wikipedia.org/wiki/CBC_News\n",
      "104: \"U.S.\" is a GPE found at https://en.wikipedia.org/wiki/U.S.\n",
      "105: \"U.S.\" is a GPE found at https://en.wikipedia.org/wiki/U.S.\n",
      "106: \"Anthony Fauci\" is a PERSON found at https://en.wikipedia.org/wiki/Anthony_Fauci\n",
      "107: \"Air Canada\" is a ORG found at https://en.wikipedia.org/wiki/Air_Canada\n",
      "108: \"Air Canada\" is a ORG found at https://en.wikipedia.org/wiki/Air_Canada\n",
      "109: \"Health Canada\" is a ORG found at https://en.wikipedia.org/wiki/Health_Canada\n",
      "110: \"Gilead\" is a ORG found at https://en.wikipedia.org/wiki/Gilead\n",
      "111: \"CBC News\" is a ORG found at https://en.wikipedia.org/wiki/CBC_News\n",
      "112: \"Gilead\" is a ORG found at https://en.wikipedia.org/wiki/Gilead\n",
      "113: \"Health Canada\" is a ORG found at https://en.wikipedia.org/wiki/Health_Canada\n",
      "114: \"Alberta\" is a GPE found at https://en.wikipedia.org/wiki/Alberta\n",
      "115: \"daily\" is a DATE found at https://en.wikipedia.org/wiki/daily\n",
      "116: \"Grace Horsfall Couldwell\" is a PERSON found at https://en.wikipedia.org/wiki/Grace_Horsfall_Couldwell\n",
      "117: \"daily\" is a DATE found at https://en.wikipedia.org/wiki/daily\n",
      "118: \"Alberta\" is a GPE found at https://en.wikipedia.org/wiki/Alberta\n",
      "119: \"MJ Stead\" is a PERSON found at https://en.wikipedia.org/wiki/MJ_Stead\n",
      "120: \"Lori Toma\" is a PERSON found at https://en.wikipedia.org/wiki/Lori_Toma\n",
      "121: \"Nancy Horsfall Couldwell\" is a PERSON found at https://en.wikipedia.org/wiki/Nancy_Horsfall_Couldwell\n",
      "122: \"Cochrane\" is a ORG found at https://en.wikipedia.org/wiki/Cochrane\n",
      "123: \"Alta\" is a ORG found at https://en.wikipedia.org/wiki/Alta\n",
      "124: \"MJ Stead\" is a PERSON found at https://en.wikipedia.org/wiki/MJ_Stead\n",
      "125: \"Facebook\" is a PRODUCT found at https://en.wikipedia.org/wiki/Facebook\n",
      "126: \"MJ Stead\" is a PERSON found at https://en.wikipedia.org/wiki/MJ_Stead\n",
      "127: \"hour-long\" is a TIME found at https://en.wikipedia.org/wiki/hour-long\n",
      "128: \"Facebook Live\" is a PRODUCT found at https://en.wikipedia.org/wiki/Facebook_Live\n",
      "129: \"2013\" is a DATE found at https://en.wikipedia.org/wiki/2013\n",
      "130: \"30\" is a CARDINAL\n",
      "131: \"more than 1,500\" is a CARDINAL\n",
      "132: \"more than one\" is a CARDINAL\n",
      "133: \"Two years ago\" is a DATE found at https://en.wikipedia.org/wiki/Two_years_ago\n",
      "134: \"MJ Stead\" is a PERSON found at https://en.wikipedia.org/wiki/MJ_Stead\n",
      "135: \"100 days\" is a DATE found at https://en.wikipedia.org/wiki/100_days\n",
      "136: \"COVID-19\" is a ORG found at https://en.wikipedia.org/wiki/COVID-19\n",
      "137: \"Health Canada\" is a ORG found at https://en.wikipedia.org/wiki/Health_Canada\n",
      "138: \"CBC News\" is a ORG found at https://en.wikipedia.org/wiki/CBC_News\n",
      "139: \"daily\" is a DATE found at https://en.wikipedia.org/wiki/daily\n",
      "140: \"CBC News Network\" is a ORG found at https://en.wikipedia.org/wiki/CBC_News_Network\n",
      "141: \"CBC News Network\" is a ORG found at https://en.wikipedia.org/wiki/CBC_News_Network\n",
      "142: \"CBC News Network\" is a ORG found at https://en.wikipedia.org/wiki/CBC_News_Network\n",
      "143: \"CBC News Network\" is a ORG found at https://en.wikipedia.org/wiki/CBC_News_Network\n",
      "144: \"CBC News Network\" is a ORG found at https://en.wikipedia.org/wiki/CBC_News_Network\n",
      "145: \"NaN\" is a DATE found at https://en.wikipedia.org/wiki/NaN\n"
     ]
    }
   ],
   "source": [
    "# RÉPONSE Q6 -\n",
    "docq6 = df[\"text\"][6]\n",
    "q6 = sp(docq6)\n",
    "\n",
    "for i, token in enumerate(q6.ents):\n",
    "    # (b) using normalized form\n",
    "    ent = assign_normalized_form(q5.ents[i], q5.ents[0:i-1])\n",
    "    # (a) \n",
    "    if(ent.label_ == \"QUANTITY\" or ent.label_ == \"CARDINAL\"):\n",
    "        # (e) printing surface form, entity type\n",
    "        print(str(i) + \": \\\"\" + ent.text + \"\\\" is a \" + ent.label_)\n",
    "    else:\n",
    "        # (d) remove stop words from string\n",
    "        stop_words = [\"more\", \"than\",\"the\",\"a\",\"about\",\"above\",\"after\",\"again\",\"against\",\"all\",\"am\",\"an\",\"and\",\"any\",\"are\",\"aren't\",\"as\",\"at\",\"be\",\"because\",\"been\",\"before\",\"being\",\"below\",\"between\",\"both\",\"but\",\"by\",\"can't\",\"cannot\",\"could\",\"couldn't\",\"did\"]\n",
    "        res = ent.text\n",
    "        for word in ent.text.split():\n",
    "            if(word in stop_words):\n",
    "                res = res.replace(word, \"\")\n",
    "                # remove fornt and back white spaces\n",
    "                res = res.strip()\n",
    "                # remove 's form string\n",
    "                res = res.replace(\"'s\", \"\")\n",
    "        # (c) using ent.text.replace(\" \", \"_\") to transform white spaces to underscrores\n",
    "        res = res.replace(\" \", \"_\")\n",
    "        # (e) printing surface form, entity type and Wikipedia link \n",
    "        print(str(i) + \": \\\"\" + ent.text +\"\\\" is a \" + ent.label_ + \" found at \" + \"https://en.wikipedia.org/wiki/\" + res)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v_7EfNtK1aN2"
   },
   "source": [
    "**(TO DO) Q7 - 5 points**  \n",
    "\n",
    "Effectuez une évaluation qualitative de la méthode de linking d'entités que vous avez écrite en Q6. Pour votre évaluation qualitative, vous devez choisir un document (celui que vous voulez dans le corpus de nouvelles sur Covid-19, et assurez-vous de mentionner lequel) et exécuter votre méthode sur ce document. Répondez aux questions suivantes :\n",
    "\n",
    "* a. Donnez 2 exemples d'entités où la forme plus longue a été trouvée dans Wikipedia. La page trouvée est-elle appropriée ? La forme plus courte serait-elle également trouvée? Serait-elle liée à la même page?\n",
    "* b. Donnez 2 exemples d'entités où la page wikipedia n'existait pas. Pourquoi? La forme recherchée était-elle incorrecte ou l'entité était-elle peu connue (et donc sans page Wikipedia)?\n",
    "* c. Essayez de restreindre votre recherche avec différents types d'entités. Pensez-vous que les DATE sont couvertes par Wikipédia ? Qu'en est-il de PERSON ou de GPE ? Discutez de la couverture des différents types d'entités en donnant des exemples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kQ4MtlmS4nle"
   },
   "source": [
    "**RÉPONSE Q7**\n",
    "Pour cette partie, j'ai utilisé la document 7 soit l'index 6.\n",
    "\n",
    "a) Pour l'entité \"Air Canada\", la forme courte était \"Canada\" (entité 55). La page trouvé pour cette entité est appropriée tandis que si on aurait utilisé la forme plus courte on aurait trouvé une autre page web soit celle du Canada, une entité complètement différente.\n",
    "\n",
    "Même chose pour l'entité \"Jason Kenney\" (76). La forme courte de cette entité était \"Kenney\". La page trouvé pour cette entité est appropriée tandis que si on aurait utilisé la forme plus courte on aurait trouvé aucune page web.\n",
    "\n",
    "b) Pour l'entité \"Grace Horsfall Couldwell\" (116) aucune page wikipedia n'existait. Ceci est du au fait que cette personne est très peu connu, donc elle n'a pas de page wikipedia, même si le nom est bien écrit.\n",
    "\n",
    "Pour l'entité \"the entire month\" (61) aucune page wikipedia n'existait, car l'entité recherché dans wikipedia était \"entire_month\". La forme recherché était donc incorrecte. La bonne forme aurait été \"month\".\n",
    "\n",
    "c) Pour la plupart des entités DATE, elles sont couvertes par wikipedia sauf si ces dates sont de mauvaise forme (\"the entire month\", entité (61)) ou référent à des événements historiques (\"100 days\", entité 135).\n",
    "\n",
    "Pour les entités de type PERSON ou GPE, la plupart sont couvert sauf si la personne ou l'entité géopolitique n'est pas très connu ou bien cette personne ou cette entité géopolitique est dans un mauvais format. En grande majorité, la couverture est très grande.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S41KwFDE1aN7"
   },
   "source": [
    "***SIGNATURE:***\n",
    "Mon nom est Mark-Olivier Poulin.\n",
    "Mon numéro d'étudiant(e) est 300058025.\n",
    "J'atteste être l'auteur(e) de ce Notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "CSI4506-KR_Automne2021.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

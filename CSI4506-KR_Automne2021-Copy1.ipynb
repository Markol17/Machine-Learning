{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2-V6SMps1aMz"
   },
   "source": [
    "# Notebook 8 - Représentation des connaissances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LWzoA8kN1aNK"
   },
   "source": [
    "CSI4506 Intelligence Artificielle  \n",
    "Automne 2021 \\\n",
    "Versions 1 (2020) préparée par Julian Templeton, Caroline Barrière et Joel Muteba.  Version 2 (2021) modifiée par Caroline Barrière."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-f2sWDLa1aNM"
   },
   "source": [
    "***INTRODUCTION***:  \n",
    "\n",
    "Lors de la lecture de texte, comprendre les type d'entités utilisées dans le texte permet d'inférer des informations supplémentaires sur ces entités.  Par exemple, si un texte mentionne *Canada*, le fait de savoir que c'est une GPE (entité géo-politique), nous indique déjà que cette entité a une supercifie, une population, etc.  Grâce à l'utilisation de la reconnaissance d'entités nommées (Named Entity Recognition, NER), nous sommes en mesure de déterminer si une entité est une personne, une organisation, un pays, ... \n",
    "\n",
    "Lors de l'exploration de texte en version électronique, nous voyons aussi occasionnellement que les entités ont des liens cliquables vers des pages Web avec plus d'informations sur l'entité. Il s'agit d'une forme d'amélioration du texte pour permettre aux lecteurs d'accéder facilement à des informations supplémentaires.  Si nous prenons encore l'exemple de *Canada*, si nous le transformons en [Canada](https://en.wikipedia.org/wiki/Canada), à l'aide du linking d'entités (entity linking) nous accédons à d'avantage d'informations. \n",
    "\n",
    "Dans ce notebook, nous revisiterons l'ensemble de données d'actualités liées à Covid-19 du notebook 7 pour explorer comment nous pouvons améliorer les résultats de NER de spaCy et aider à la compréhension des articles de presse grâce à l'utilisation du linking d'entités. Cela se fera en trois parties, soit \n",
    "\n",
    "(1) nous explorerons d'abord les résultats du NER de spaCy \\\n",
    "(2) nous utiliserons la cohérence du texte pour un post-traitement au NER de spaCy\\\n",
    "(3) puis nous effectuons des ajouts (*enrichissement*) au texte avec le linking d'entités.\n",
    "\n",
    "Ce notebook utilise des bibliothèques qui ont été utilisées dans les notebooks précédents, notamment spaCy et pandas. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g3lw1Bam1aNP"
   },
   "source": [
    "***DEVOIR***:  \n",
    "\n",
    "Parcourez le notebook en exécutant chaque cellule, une à la fois. \\\n",
    "Recherchez **(TO DO)** pour les tâches que vous devez effectuer. Ne modifiez pas le code en dehors des questions auxquelles vous êtes invité à répondre à moins que cela ne vous soit spécifiquement demandé. Une fois que vous avez terminé, signez le notebook (à la fin du notebook), renommez-le *NumEtudiant-NomFamille-Notebook8.ipynb* et soumettez-le.\n",
    "\n",
    "*Le notebook sera noté le 30.  \\\n",
    "Chaque **(TO DO)** est associé à un certain nombre de points.*\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "IvqAEm8o1aNR"
   },
   "outputs": [],
   "source": [
    "# Before starting we will import every module that we will be using\n",
    "import spacy\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "z0Qx9Rvk1aNT"
   },
   "outputs": [],
   "source": [
    "# The core spacy object can be used for tokenization, lemmatization, POS Tagging, NER ...\n",
    "# Note that this is specifically for the English language and requires the English package to be installed\n",
    "# via pip to work as intended.\n",
    "\n",
    "# sp = spacy.load('en')\n",
    "\n",
    "# If the above causes an error then install the package as below\n",
    "# !spacy download en_core_web_sm\n",
    "sp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VmPRH8H9royU"
   },
   "source": [
    "Comme pour le dernier notebook, l'ensemble de données est fourni sur Brightspace (Module 8) avec ce notebook, mais les détails le concernant peuvent être trouvés [ici](https://www.kaggle.com/ryanxjhan/cbc-news-coronavirus-articles-march-26?select=news.csv). La première chose que nous allons faire, comme d'habitude, est de charger le fichier dans un dataframe pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "32ACx3Cy1aNY"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>authors</th>\n",
       "      <th>title</th>\n",
       "      <th>publish_date</th>\n",
       "      <th>description</th>\n",
       "      <th>text</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>'More vital now:' Gay-straight alliances go vi...</td>\n",
       "      <td>2020-05-03 1:30</td>\n",
       "      <td>Lily Overacker and Laurell Pallot start each g...</td>\n",
       "      <td>Lily Overacker and Laurell Pallot start each g...</td>\n",
       "      <td>https://www.cbc.ca/news/canada/calgary/gay-str...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "      <td>Scientists aim to 'see' invisible transmission...</td>\n",
       "      <td>2020-05-02 8:00</td>\n",
       "      <td>Some researchers aim to learn more about how t...</td>\n",
       "      <td>This is an excerpt from Second Opinion, a week...</td>\n",
       "      <td>https://www.cbc.ca/news/technology/droplet-tra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>['The Canadian Press']</td>\n",
       "      <td>Coronavirus: What's happening in Canada and ar...</td>\n",
       "      <td>2020-05-02 11:28</td>\n",
       "      <td>Canada's chief public health officer struck an...</td>\n",
       "      <td>The latest:  The lives behind the numbers: Wha...</td>\n",
       "      <td>https://www.cbc.ca/news/canada/coronavirus-cov...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>[]</td>\n",
       "      <td>B.C. announces 26 new coronavirus cases, new c...</td>\n",
       "      <td>2020-05-02 18:45</td>\n",
       "      <td>B.C. provincial health officer Dr. Bonnie Henr...</td>\n",
       "      <td>B.C. provincial health officer Dr. Bonnie Henr...</td>\n",
       "      <td>https://www.cbc.ca/news/canada/british-columbi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>[]</td>\n",
       "      <td>B.C. announces 26 new coronavirus cases, new c...</td>\n",
       "      <td>2020-05-02 18:45</td>\n",
       "      <td>B.C. provincial health officer Dr. Bonnie Henr...</td>\n",
       "      <td>B.C. provincial health officer Dr. Bonnie Henr...</td>\n",
       "      <td>https://www.cbc.ca/news/canada/british-columbi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>['Senior Writer', 'Chris Arsenault Is A Senior...</td>\n",
       "      <td>Brazil has the most confirmed COVID-19 cases i...</td>\n",
       "      <td>2020-05-02 8:00</td>\n",
       "      <td>From describing coronavirus as a \"little flu,\"...</td>\n",
       "      <td>With infection rates spiralling, some big city...</td>\n",
       "      <td>https://www.cbc.ca/news/world/brazil-has-the-m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>['Cbc News']</td>\n",
       "      <td>The latest on the coronavirus outbreak for May 1</td>\n",
       "      <td>2020-05-01 20:43</td>\n",
       "      <td>The latest on the coronavirus outbreak from CB...</td>\n",
       "      <td>Coronavirus Brief (CBC)  Canada is officiall...</td>\n",
       "      <td>https://www.cbc.ca/news/the-latest-on-the-coro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>['Cbc News']</td>\n",
       "      <td>Coronavirus: What's happening in Canada and ar...</td>\n",
       "      <td>2020-05-01 11:51</td>\n",
       "      <td>Nova Scotia announced Friday it is immediately...</td>\n",
       "      <td>The latest:  The lives behind the numbers: Wha...</td>\n",
       "      <td>https://www.cbc.ca/news/canada/coronavirus-cov...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>['Senior Writer', \"Adam Miller Is Senior Digit...</td>\n",
       "      <td>Did the WHO mishandle the global coronavirus p...</td>\n",
       "      <td>2020-04-30 8:00</td>\n",
       "      <td>The World Health Organization has come under f...</td>\n",
       "      <td>The World Health Organization has come under f...</td>\n",
       "      <td>https://www.cbc.ca/news/health/coronavirus-who...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>['Thomson Reuters']</td>\n",
       "      <td>Armed people in Michigan's legislature protest...</td>\n",
       "      <td>2020-04-30 21:37</td>\n",
       "      <td>Hundreds of protesters, some armed, gathered a...</td>\n",
       "      <td>Hundreds of protesters, some armed, gathered a...</td>\n",
       "      <td>https://www.cbc.ca/news/world/protesters-michi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Unnamed: 0                                            authors  \\\n",
       "0          0                                                 []   \n",
       "1          1                                                 []   \n",
       "2          2                             ['The Canadian Press']   \n",
       "3          3                                                 []   \n",
       "4          4                                                 []   \n",
       "5          5  ['Senior Writer', 'Chris Arsenault Is A Senior...   \n",
       "6          6                                       ['Cbc News']   \n",
       "7          7                                       ['Cbc News']   \n",
       "8          8  ['Senior Writer', \"Adam Miller Is Senior Digit...   \n",
       "9          9                                ['Thomson Reuters']   \n",
       "\n",
       "                                               title      publish_date  \\\n",
       "0  'More vital now:' Gay-straight alliances go vi...   2020-05-03 1:30   \n",
       "1  Scientists aim to 'see' invisible transmission...   2020-05-02 8:00   \n",
       "2  Coronavirus: What's happening in Canada and ar...  2020-05-02 11:28   \n",
       "3  B.C. announces 26 new coronavirus cases, new c...  2020-05-02 18:45   \n",
       "4  B.C. announces 26 new coronavirus cases, new c...  2020-05-02 18:45   \n",
       "5  Brazil has the most confirmed COVID-19 cases i...   2020-05-02 8:00   \n",
       "6   The latest on the coronavirus outbreak for May 1  2020-05-01 20:43   \n",
       "7  Coronavirus: What's happening in Canada and ar...  2020-05-01 11:51   \n",
       "8  Did the WHO mishandle the global coronavirus p...   2020-04-30 8:00   \n",
       "9  Armed people in Michigan's legislature protest...  2020-04-30 21:37   \n",
       "\n",
       "                                         description  \\\n",
       "0  Lily Overacker and Laurell Pallot start each g...   \n",
       "1  Some researchers aim to learn more about how t...   \n",
       "2  Canada's chief public health officer struck an...   \n",
       "3  B.C. provincial health officer Dr. Bonnie Henr...   \n",
       "4  B.C. provincial health officer Dr. Bonnie Henr...   \n",
       "5  From describing coronavirus as a \"little flu,\"...   \n",
       "6  The latest on the coronavirus outbreak from CB...   \n",
       "7  Nova Scotia announced Friday it is immediately...   \n",
       "8  The World Health Organization has come under f...   \n",
       "9  Hundreds of protesters, some armed, gathered a...   \n",
       "\n",
       "                                                text  \\\n",
       "0  Lily Overacker and Laurell Pallot start each g...   \n",
       "1  This is an excerpt from Second Opinion, a week...   \n",
       "2  The latest:  The lives behind the numbers: Wha...   \n",
       "3  B.C. provincial health officer Dr. Bonnie Henr...   \n",
       "4  B.C. provincial health officer Dr. Bonnie Henr...   \n",
       "5  With infection rates spiralling, some big city...   \n",
       "6    Coronavirus Brief (CBC)  Canada is officiall...   \n",
       "7  The latest:  The lives behind the numbers: Wha...   \n",
       "8  The World Health Organization has come under f...   \n",
       "9  Hundreds of protesters, some armed, gathered a...   \n",
       "\n",
       "                                                 url  \n",
       "0  https://www.cbc.ca/news/canada/calgary/gay-str...  \n",
       "1  https://www.cbc.ca/news/technology/droplet-tra...  \n",
       "2  https://www.cbc.ca/news/canada/coronavirus-cov...  \n",
       "3  https://www.cbc.ca/news/canada/british-columbi...  \n",
       "4  https://www.cbc.ca/news/canada/british-columbi...  \n",
       "5  https://www.cbc.ca/news/world/brazil-has-the-m...  \n",
       "6  https://www.cbc.ca/news/the-latest-on-the-coro...  \n",
       "7  https://www.cbc.ca/news/canada/coronavirus-cov...  \n",
       "8  https://www.cbc.ca/news/health/coronavirus-who...  \n",
       "9  https://www.cbc.ca/news/world/protesters-michi...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the dataset, show top ten rows\n",
    "df = pd.read_csv(\"news.csv\")\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N13QcJqR1aNV"
   },
   "source": [
    "**PARTIE 1 - Le NER de spaCy**  \n",
    "  \n",
    "Commençons par regarder le NER qui est effectué par spaCy. La documentation de SpaCy ne nous dit pas exactement comment leur NER est fait (certainement leur secret commercial), mais nous pouvons au moins regarder les résultats.\n",
    "\n",
    "Comme nous en avons discuté dans les notebooks précédents, lors de l'évaluation d'un processus, d'un modèle ou d'un outil, nous pouvons faire une évaluation quantitative ou une **évaluation qualitative** des résultats. Dans ce notebook, nous travaillons à un niveau qualitatif, ce qui signifie que nous ne mesurons pas des métriques telles que la précision/rappel, mais imprimons plutôt les résultats de quelques exemples et essayons de comprendre ces résultats.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kIQI-Fwi1aNa"
   },
   "source": [
    "Vous trouverez ci-dessous la même phrase exemple que dans le dernier Notebook, pour laquelle nous avions examiné l'étiquetage des parties du discours (POS tagging) et d'autres processus linguistiques.  Nous utilisons cette phrase exemple pour illustrer maintenant comment obtenir les prédictions de type NER de spaCy pour les tokens dans un texte."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "syOIDbsa1aNc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Canada\" is a GPE\n",
      "\"at least two metres\" is a CARDINAL\n",
      "\"COVID-19\" is a ORG\n"
     ]
    }
   ],
   "source": [
    "# Same example from notebook 7, recall that we loop through the iterator found in the .ents property of a parsed sentence\n",
    "sentence_example = \"Government guidelines in Canada recommend that people stay at least two metres away from others as part of physical distancing measures to curb the spread of COVID-19.\"\n",
    "sentence_example_content = sp(sentence_example)\n",
    "# Loop through all tokens that contain a NER type and print the token along with the corresponding NER type\n",
    "for token in sentence_example_content.ents:\n",
    "    print(\"\\\"\" + token.text + \"\\\" is a \" + token.label_ )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J9VAgeEA1aNe"
   },
   "source": [
    "**(TO DO) Q1 - 5 points**  \n",
    "\n",
    "Dans le texte du ***second document*** (index 1) de notre corpus de documents, quels mots sont *PER* (spaCy utilise le type *PERSON*, plutôt que *PER*), *ORG* (Organisation) et *GPE* (entité géopolitique). Vous devez effectuer les opérations suivantes pour cette question:\n",
    "\n",
    "a) (2 points) Imprimez chaque *PERSON*, *ORG* et *GPE* avec son type NER tel que trouvé par spaCy.\n",
    "\n",
    "b) (1 points) Est-ce que la majorité des prédictions de spaCy sont correctes? Donnez deux exemples de sorties obtenues en (a) qui sont incorrectes selon vous.\n",
    "\n",
    "c) (2 points) Il arrive parfois que des problèmes avec les prédictions de type NER proviennent d'erreurs dans des étapes antérieures dans la pipeline TAL (e.g. tokenization, POS tagging).  Utilisez 2 exemples de sorties obtenues en (a) pour illustrer cette possibilité, et tentez d'offrir un diagnostic (que s'est-il passé?)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "7bIvPeBI1aNf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"COVID-19\": PERSON\n",
      "\"the World Health Organization\": ORG\n",
      "\"WHO\": ORG\n",
      "\"the Public Health Agency\": ORG\n",
      "\"Canada\": GPE\n",
      "\"W.F. Wells\": PERSON\n",
      "\"the Harvard School of Public Health\": ORG\n",
      "\"Wells\": ORG\n",
      "\"Canada\": GPE\n",
      "\"Lydia Bourouiba\": PERSON\n",
      "\"the Fluid Dynamics of Disease Transmission Laboratory\": ORG\n",
      "\"the Massachusetts Institute of Technology\": ORG\n",
      "\"Bourouiba\": PERSON\n",
      "\"Mark Loeb\": PERSON\n",
      "\"McMaster University\": ORG\n",
      "\"RNA\": ORG\n",
      "\"Wuhan\": GPE\n",
      "\"China\": GPE\n",
      "\"Nebraska\": GPE\n",
      "\"Canada\": GPE\n",
      "\"COVID-19\": ORG\n",
      "\"Gary Moore/CBC\": PERSON\n",
      "\"Allison McGeer\": PERSON\n",
      "\"Sinai Health\": ORG\n",
      "\"Toronto\": GPE\n",
      "\"COVID-19\": PERSON\n",
      "\"McGeer\": ORG\n",
      "\"McGeer\": ORG\n",
      "\"Bourouiba\": PERSON\n",
      "\"Bourouiba\": PERSON\n",
      "\"Credit Lydia Bourouiba/MIT/JAMA Networks\": ORG\n",
      "\"Samira Mubareka\": PERSON\n",
      "\"Toronto\": GPE\n",
      "\"Bourouiba\": PERSON\n",
      "\"COVID-19\": ORG\n",
      "\"McMaster\": PERSON\n",
      "\"N95\": ORG\n",
      "\"U.S.\": GPE\n",
      "\"Justin Trudeau\": PERSON\n",
      "\"Mubareka\": PERSON\n",
      "\"the New England Journal of Medicine\": ORG\n",
      "\"the U.S. National Institutes of Health\": ORG\n",
      "\"U.S. National Institutes of Health\": ORG\n",
      "\"COVID-19?\": ORG\n",
      "\"Journal of the Royal Society Interface\": ORG\n",
      "\"U.S.\": GPE\n",
      "\"Singapore\": GPE\n",
      "\"N95\": ORG\n",
      "\"Gary S. Settles\": PERSON\n",
      "\"Penn State University/Journal of the Royal Society Interface\": ORG\n",
      "\"The World Health Organization\": ORG\n",
      "\"Los Angeles\": GPE\n",
      "\"Italy\": GPE\n",
      "\"Austria\": GPE\n"
     ]
    }
   ],
   "source": [
    "# RÉPONSE Q1(a) - 2 points\n",
    "# Select the second document (index 1)\n",
    "doc = df[\"text\"][1]\n",
    "# SHOW PERSON, ORG, GPE\n",
    "content = sp(doc)\n",
    "for token in content.ents:\n",
    "    if(token.label_ == \"PERSON\" or token.label_ == \"ORG\" or token.label_ == \"GPE\"):\n",
    "        print(\"\\\"\" + token.text + \"\\\": \" + token.label_ )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xVuqciJz1aNg"
   },
   "source": [
    "**RÉPONSE Q1(b) - 1 point**   \n",
    "\"Covid-19\" est parfois associé à une organisation ou une personne ce qui n'est pas le cas.\n",
    "\"McGeer\" est associé à une organisation, mais est en réalité une personne.\n",
    "La majorité des prédictions de spaCY sont correctes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E2K3_74F1aNi"
   },
   "source": [
    "**RÉPONSE Q1 (c) - 2 points**   \n",
    "\"Gary Moore/CBC\" est une erreur de tokenization, car Gary Moore est une personne et CBC est une organisation. Cette erreur est sans doute dû au \"/\" entre les deux mots.\n",
    "\n",
    "\"McGeer\" est identifié comme une organisation, mais fait fort probablement référence à une personne, donc il y a eu une erreur de POS tagging. Cette erreur doit être dû au fait que le prénom n'était pas présent avant le nom \"McGeer\", donc spaCY à traité \"McGeer\" comme le nom d'une organisation. De plus, spaCY ne tient pas compte de l'entièreté du document."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OltjfgOl1aNj"
   },
   "source": [
    "**PARTIE 2 - Cohérence du texte et chaînes de coréférences**  \n",
    "\n",
    "Comme vous avez vu, les résultats du spaCy NER sont très bons, mais pas parfait.  Un problème principal avec NER (pas seulement dans spaCy mais dans de nombreux outils) est que l'annotation est effectuée une entité à la fois sans tenir compte du document global.\n",
    "\n",
    "Mais en regardant l'ensemble du document, et sachant que le texte est généralement cohérent, nous pouvons effectuer un post-traitement dans le module NER de spaCy et corriger certaines erreurs. Par texte cohérent, nous entendons, par exemple, que si une personne est désignée avec un nom particulier, par ex. *McGeer*, il y a de fortes chances qu'à chaque fois que l'on voit *McGeer* dans le document, ce soit la même personne.  Toutes les mentions *McGeer* formeraient une chaîne de coréférences vers la même entité.  Il est donc peu probable que *McGeer* soit une fois une personne et une fois une organisation. Ce n'est pas toujours vrai, il existe de nombreux contre-exemples, mais c'est une hypothèse courante. Cette idée est même le sujet d'un article de la PNL plus ancien et très cité intitulé « One sense per discourse » (Gale et al. 1992).\n",
    "\n",
    "Avec cette idée de \"One sense per discourse\", nous explorerons deux stratégies différentes pour utiliser la cohérence du texte pour post-traiter la sortie du module spaCy NER.\n",
    "\n",
    "La première stratégie (*explorée en Q2 / Q3*) est de trouver, parmi tous les types de NER assignés, lequel est le plus fréquent. Par exemple, l'entité *Bourouiba* s'est vu attribuer 1 fois ORG et 2 fois PERSON, donc ces informations peuvent être utilisées pour modifier le type ORG et le changer en PERSON.\n",
    "\n",
    "La deuxième stratégie (explorée à la Q4) est d'essayer de trouver une forme plus longue dans le texte. Puisque cette forme plus longue devrait être moins ambiguë, nous pouvons l'utiliser pour lever l'ambiguïté des formes plus courtes et plus ambiguës. Par exemple, *Lydia Bourouiba* apparaît dans le texte et se voit attribuer PERSON. Nous pouvons utiliser cette information pour attribuer à d'autres occurrences de la forme abrégée *Bourouiba* le même type PERSON.\n",
    "\n",
    "Bien sûr, utiliser ces méthodes pour la cohérence du texte ne fonctionnera pas à tous les coups, et introduira malheureusement quelques erreurs... Mais essayons. C'est le but des études empiriques, nous essayons des idées."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7VH5BjZl1aNk"
   },
   "source": [
    "Reprenons notre nouvelle utilisée pour Q1, mais cette fois, montrons non seulement GPE, PER, ORG, mais plutôt toutes les entités nommées trouvées par spaCy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "vMWdFIsi1aNl"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: \"weekly\" is a DATE\n",
      "1: \"Saturday\" is a DATE\n",
      "2: \"morning\" is a TIME\n",
      "3: \"two metres\" is a QUANTITY\n",
      "4: \"COVID-19\" is a PERSON\n",
      "5: \"the World Health Organization\" is a ORG\n",
      "6: \"WHO\" is a ORG\n",
      "7: \"more than one metre\" is a QUANTITY\n",
      "8: \"the Public Health Agency\" is a ORG\n",
      "9: \"Canada\" is a GPE\n",
      "10: \"at least two metres\" is a QUANTITY\n",
      "11: \"two\" is a CARDINAL\n",
      "12: \"2 metres\" is a QUANTITY\n",
      "13: \"the 19th century\" is a DATE\n",
      "14: \"1934\" is a DATE\n",
      "15: \"W.F. Wells\" is a PERSON\n",
      "16: \"the Harvard School of Public Health\" is a ORG\n",
      "17: \"two metres\" is a QUANTITY\n",
      "18: \"Wells\" is a ORG\n",
      "19: \"56,000\" is a CARDINAL\n",
      "20: \"Canada\" is a GPE\n",
      "21: \"Saturday\" is a DATE\n",
      "22: \"Lydia Bourouiba\" is a PERSON\n",
      "23: \"the Fluid Dynamics of Disease Transmission Laboratory\" is a ORG\n",
      "24: \"the Massachusetts Institute of Technology\" is a ORG\n",
      "25: \"Bourouiba\" is a PERSON\n",
      "26: \"Canadian\" is a NORP\n",
      "27: \"Mark Loeb\" is a PERSON\n",
      "28: \"McMaster University\" is a ORG\n",
      "29: \"RNA\" is a ORG\n",
      "30: \"Wuhan\" is a GPE\n",
      "31: \"China\" is a GPE\n",
      "32: \"Nebraska\" is a GPE\n",
      "33: \"Canada\" is a GPE\n",
      "34: \"at least two metres\" is a CARDINAL\n",
      "35: \"COVID-19\" is a ORG\n",
      "36: \"Gary Moore/CBC\" is a PERSON\n",
      "37: \"Allison McGeer\" is a PERSON\n",
      "38: \"Sinai Health\" is a ORG\n",
      "39: \"Toronto\" is a GPE\n",
      "40: \"COVID-19\" is a PERSON\n",
      "41: \"hundreds\" is a CARDINAL\n",
      "42: \"hours\" is a TIME\n",
      "43: \"N-95\" is a PRODUCT\n",
      "44: \"McGeer\" is a ORG\n",
      "45: \"five minutes\" is a TIME\n",
      "46: \"McGeer\" is a ORG\n",
      "47: \"Bourouiba\" is a PERSON\n",
      "48: \"Bourouiba\" is a PERSON\n",
      "49: \"farther than two metres\" is a QUANTITY\n",
      "50: \"seven or eight metres\" is a QUANTITY\n",
      "51: \"Credit Lydia Bourouiba/MIT/JAMA Networks\" is a ORG\n",
      "52: \"Canadian\" is a NORP\n",
      "53: \"about one kilometre\" is a QUANTITY\n",
      "54: \"two-metre\" is a QUANTITY\n",
      "55: \"up to three minutes\" is a TIME\n",
      "56: \"Samira Mubareka\" is a PERSON\n",
      "57: \"Sunnybrook Hospital\" is a FAC\n",
      "58: \"Toronto\" is a GPE\n",
      "59: \"2-metre\" is a QUANTITY\n",
      "60: \"Bourouiba\" is a PERSON\n",
      "61: \"two metres\" is a QUANTITY\n",
      "62: \"March\" is a DATE\n",
      "63: \"farther than two metres\" is a QUANTITY\n",
      "64: \"two metres\" is a QUANTITY\n",
      "65: \"Mubareka\" is a PRODUCT\n",
      "66: \"two-metre\" is a QUANTITY\n",
      "67: \"Second\" is a ORDINAL\n",
      "68: \"COVID-19\" is a ORG\n",
      "69: \"McMaster\" is a PERSON\n",
      "70: \"N95\" is a ORG\n",
      "71: \"U.S.\" is a GPE\n",
      "72: \"Canadian\" is a NORP\n",
      "73: \"Justin Trudeau\" is a PERSON\n",
      "74: \"Mubareka\" is a PERSON\n",
      "75: \"April 2020\" is a DATE\n",
      "76: \"the New England Journal of Medicine\" is a ORG\n",
      "77: \"the U.S. National Institutes of Health\" is a ORG\n",
      "78: \"0:42\" is a DATE\n",
      "79: \"U.S. National Institutes of Health\" is a ORG\n",
      "80: \"less than 10\" is a CARDINAL\n",
      "81: \"COVID-19?\" is a ORG\n",
      "82: \"2009\" is a DATE\n",
      "83: \"Journal of the Royal Society Interface\" is a ORG\n",
      "84: \"2009\" is a DATE\n",
      "85: \"U.S.\" is a GPE\n",
      "86: \"Singapore\" is a GPE\n",
      "87: \"N95\" is a ORG\n",
      "88: \"Gary S. Settles\" is a PERSON\n",
      "89: \"Penn State University/Journal of the Royal Society Interface\" is a ORG\n",
      "90: \"The World Health Organization\" is a ORG\n",
      "91: \"Los Angeles\" is a GPE\n",
      "92: \"Italy\" is a GPE\n",
      "93: \"Austria\" is a GPE\n",
      "94: \"Saturday\" is a DATE\n",
      "95: \"morning\" is a TIME\n"
     ]
    }
   ],
   "source": [
    "# Select document 2\n",
    "doc = df[\"text\"][1]\n",
    "# NER\n",
    "doc_sp = sp(doc)\n",
    "# Display all entities from the text along with their index in the .ents iterator and the\n",
    "# corresponding NER type\n",
    "for i, token in enumerate(doc_sp.ents):\n",
    "    print(str(i) + \": \\\"\" + token.text + \"\\\" is a \" + token.label_ )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MpPGxf9J1aNm"
   },
   "source": [
    "**(TO DO) Q2 - 3 points**  \n",
    "Comme vous pouvez le voir dans les résultats, parfois la même entité s'est vu attribuer différents types d'entités.  Par exemple, *McGeer* est une fois ORG, une fois PERSON, puisque l'algorithme NER regarde phrase par phrase. Dans la fonction suivante, le but sera de trouver tous les types d'entités possibles affectés à une seule entité.\n",
    "\n",
    "Complétez la définition de la fonction *find_entity_types* ci-dessous. Cette fonction accepte en entrée une entité spaCy spécifique définie par le paramètre *entity* et une liste de toutes les entités spaCy du définies par le paramètre *entities*.\n",
    "\n",
    "La fonction doit trouver toutes les entités ayant la même forme de surface que *entity* dans l'ensemble *entities*. Pour chaque correspondance entre les entités, ajoutez le type NER trouvé au dictionnaire *type_counts* et mettez à jour la fréquence de ce type.\n",
    "\n",
    "Le dictionnaire *type_counts* contiendrait par exemple *McGeer* avec ORG = 1, et PERSON = 1, car la fonction a trouvé 2 mentions de *McGeer*, chacune avec un type différent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "id": "6V3v0gqj1aNn"
   },
   "outputs": [],
   "source": [
    "# RÉPONSE Q2\n",
    "def find_entity_types(entity, entities):\n",
    "    '''\n",
    "    Given a specific entity and a list of entities, finds all entities from the list that match surface form of the specified\n",
    "    entity, but that could be of a different type.\n",
    "    \n",
    "    Returns the different NER types that have been classified for an entity and the count per NER type\n",
    "    as a dictionary with the keys as the NER type and the value as the count\n",
    "    '''\n",
    "    type_counts = { }\n",
    "    for token in entities:\n",
    "        if(token.text == entity.text):\n",
    "            if(token.label_ in type_counts):\n",
    "                type_counts[token.label_] += 1  \n",
    "            else:\n",
    "                type_counts[token.label_] = 1  \n",
    "    return type_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "id": "Oz_ONmNt1aNo"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All possible NER types for \"2-metre\" are {'QUANTITY': 1}\n"
     ]
    }
   ],
   "source": [
    "# Test the above to find the result when checking for the types of the entity 'Bourouiba' \n",
    "# from the document loaded above\n",
    "print(\"All possible NER types for \\\"\" + doc_sp.ents[59].text + \"\\\" are \" + str(find_entity_types(doc_sp.ents[59], doc_sp.ents)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MpkfKthN1aNp"
   },
   "source": [
    "**(TO DO) Q3 - 2 points**  \n",
    "\n",
    "Dans la méthode précédente, *find_entity_types*, nous avons trouvé tous les types d'entités possibles pour chaque mention. Par exemple, dans le cas de *McGeer*, c'est une égalité. Mais pour *Bourouiba*, il existe un type ORG et 2 types PERSON, donc le plus courant serait PERSON.\n",
    "\n",
    "Complétez la définition de la fonction *most_common_type* ci-dessous. Cette fonction accepte en entrée une entité spaCy spécifique définie par le paramètre *entity* et une liste de toutes les entités spaCy définies par le paramètre *entities*.\n",
    "\n",
    "Remarque: vous pouvez régler les cas d'égalité à votre guise.  Aussi, assurez-vous d'utiliser la méthode *find_entity_types* que vous avez écrite précédemment.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "id": "IqxDmjpk1aNq"
   },
   "outputs": [],
   "source": [
    "# RÉPONSE Q3 \n",
    "def most_common_type(entity, entities):\n",
    "    '''\n",
    "    Given a specific entity and a list of entities, find the most similar entities and assign the\n",
    "    NER type to entity based on the most common NER type assigned to entities of the same name (if there\n",
    "    is a tie, you decide how to handle this).\n",
    "    \n",
    "    Returns the most common NER type based on similar entities\n",
    "    '''\n",
    "    dic = find_entity_types(entity, entities)\n",
    "    max_key = max(dic, key=dic.get)\n",
    "    entity.label_ = max_key\n",
    "    return max_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "id": "5akWFe_d1aNr"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The most common NER type to \"2-metre\" is QUANTITY\n"
     ]
    }
   ],
   "source": [
    "# Test the above to find the result when checking for the types of the entity 'Bourouiba' \n",
    "# from the document loaded above\n",
    "print(\"The most common NER type to \\\"\" + doc_sp.ents[59].text + \"\\\" is \" + most_common_type(doc_sp.ents[59], doc_sp.ents))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SfhMQveBvrD2"
   },
   "source": [
    "\n",
    "Notre première exploration (au Q2/Q3) portait sur la fréquence d'occurrence. Nous avons supposé que le type d'entité le plus courant pourrait être le bon. Maintenant, nous allons explorer l'idée que la mention la moins ambiguë à une entité pourrait être la bonne. Par exemple, *McGeer* est plus ambigu (forme plus courte) que *Allison McGeer* (forme plus longue). Souvent, la forme la plus longue de référence à une entité est la moins ambiguë. Mais parce que cette forme est longue à écrire, nous l'utilisons souvent avec parcimonie dans un texte (peut-être une seule fois) et les mentions subséquentes de la même entité utiliseront la forme courte. Par exemple, le texte peut mentionner *Allison McGeer* une fois, puis utiliser la forme abrégée *McGeer* pour faire référence à la même personne plusieurs fois dans le document.\n",
    "\n",
    "Dans les vidéos du cours, nous avons parlé de chaîne de coréférences.  Ainsi, une chaîne contient des mentions longues et courtes, référant toutes à la même entités.\n",
    "\n",
    "La forme plus longue est souvent appelée forme normalisée, et c'est une forme que nous sommes susceptibles de trouver dans une ressource externe. Nous verrons dans la partie 3 de ce Notebook, lorsque nous ferons des liens d'entités, qu'il existe une entrée Wikipedia pour *Allison McGeer* vers laquelle nous pourrions établir un lien. Nous pouvons considérer la forme plus longue de *Allison McGeer* comme la forme normalisée."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NEQ1Wek51aNr"
   },
   "source": [
    "**(TO DO) Q4 (a) - 3 points**  \n",
    "\n",
    "Vous devez écrire une fonction qui trouvera la forme la plus longue pouvant correspondre à une mention.\n",
    "\n",
    "Votre fonction aura les mêmes paramètres *entity* et *entities*, mais cette fois la fonction devra attribuer à *entité* le type NER d'une autre entité dans l'itérateur *entities*, soit le NER de la forme la plus longue.\n",
    "\n",
    "Plus précisément, vous devez parcourir les *entités* pour trouver une forme normalisée de *entité*. Dans ce scénario, l'entité avec la forme la plus longue contenant *entité* en tant que sous-chaîne sera considérée comme la forme normalisée et sera retournée.\n",
    "\n",
    "Ex : *Lydia Bourouiba* est la forme normalisée de *Bourouiba*. Ainsi, l'entité ayant cette forme doit être retournée. Mais *McMaster University* est déjà la forme la plus longue, donc si nous recherchons une forme normalisée pour cette entité, la fonction devrait renvoyer l'entité elle-même."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "id": "xEH_uYVZ1aNs"
   },
   "outputs": [],
   "source": [
    "# RÉPONSE Q4(a)\n",
    "# Find the longest surface form within \"entities\" for which the surface for of \"entity\" is a substring\n",
    "def assign_normalized_form(entity, entities):\n",
    "    tmp = None\n",
    "    for token in entities:\n",
    "        res = token.text.find(entity.text) # -1 = not found\n",
    "        if(len(token.text) > len(tmp.text) and res != -1):\n",
    "            tmp = token\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1lZqi5gRGWmn"
   },
   "source": [
    "Testons la fonction ci-haut, en supposant que les candidats se retrouvent uniquement dans les mentions précédentes, car souvent une forme longue est d'abord donnée *Allison McGeer* et les formes subséquentes sont les formes courtes *McGeer*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P5litMpf1aNs"
   },
   "outputs": [],
   "source": [
    "# Testing using only the previous references as candidates\n",
    "test = df[\"text\"][1]\n",
    "# Parse the text with spaCy\n",
    "test_sp = sp(test)\n",
    "for i, token in enumerate(test_sp.ents):\n",
    "    ent = assign_normalized_form(test_sp.ents[i], test_sp.ents[0:i-1])\n",
    "    print(str(i) + \": \\\"\" + token.text + \"\\\" is a \" + token.label_ + \"  \" + ent.text + \"  \" + ent.label_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "peqky9sNx2u-"
   },
   "source": [
    "**(TO DO) Q4(b) - 2 points**\n",
    "\n",
    "Faites d'autres tests sans vous limiter à chercher des formes de surfaces plus longues mentionnées avant une entité (voir *test_sp.ents[0:i-1]* dans le code ci-haut), et chercher avant ou après. Ou chercher dans un intervalle (par exemple, max N entités avant ou après). Est-ce que cela fait une différence? Expliquez ce que vous avez testé et fournissez au moins 2 exemples de changements que vous remarquez."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TVBUJXKz1ODh"
   },
   "outputs": [],
   "source": [
    "# RÉPONSE Q4(b)\n",
    "# Do a different test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7VAQRFOtyMNS"
   },
   "source": [
    "**RÉPONSE Q4(b)**\n",
    "\n",
    "...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IcGDYUR31aNt"
   },
   "source": [
    "**(TO DO) Q5 - 5 points**  \n",
    "\n",
    "Utilisez un autre article de nouvelle dans le corpus, le 7e article, donc index 6.\n",
    "\n",
    "(a) (2 points) Exécutez les deux approches (NER la plus fréquente, NER de la forme la plus longue). Pour chaque entité trouvée dans le texte, imprimez son type d'entité d'origine (tel que trouvé par spaCy, puis le type d'entité le plus courant (résultat de Q3), puis la forme normalisée avec son type d'entité (résultat de Q4). \\\n",
    "(b) (3 points) Analyser et discuter les résultats. Pensez-vous que ces approches de cohérence de texte aident ou sont-elles trop simples ? Y a-t-il des résultats contradictoires (les deux approches donnent des résultats différents). Si oui, montrez des exemples différents.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0ZzLi33Ly3lV"
   },
   "outputs": [],
   "source": [
    "# RÉPONSE Q5(a) \n",
    "# Select document index 6\n",
    "doc = df[\"text\"][6]\n",
    "...\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Aozt4Y_a1aNu"
   },
   "source": [
    "**RÉPONSE Q5(b) - 3 point**     \n",
    "\n",
    "...."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0TsrNmD71aNz"
   },
   "source": [
    "**PARTIE 3 - Linking d'entité / Enrichissement du texte**  \n",
    "\n",
    "Pour la troisième partie de ce notebook, nous explorerons comment nous pouvons fournir une \"valeur ajoutée\" au texte des documents. Dans ce scénario, nous enrichirons le texte en effectuant un linking d'entité. \n",
    "\n",
    "Cela signifie que nous tenterons de relier les entités détectées par le NER de spaCy à une page Web active sur laquelle un lecteur peut cliquer pour obtenir plus d'informations concernant l'entité. Wikipedia est une très bonne ressource pour trouver plus d'informations sur une entité, et nous utiliserons cette ressource pour le linking d'entités.\n",
    "\n",
    "Avant de tenter de faire cette opération automatiquement, voici un exemple de la façon dont un texte sans linking d'entité se compare à un texte enrichi avec linking d'entité fait manuellement:\n",
    "\n",
    "*Aucun linking d'entité:* \\\n",
    "Pendant la pandémie, des villes américaines telles que Atlanta, Chicago et Denver ont apporté plusieurs ajustements à leurs systèmes de transport en commun.\n",
    "\n",
    "*Avec linking d'entité:* \\\n",
    "Pendant la pandémie, des villes américaines telles que <a href=\"http://en.wikipedia.org/wiki/Atlanta\"> Atlanta </a>, <a href = \"http://en.wikipedia.org/wiki / Chicago \"> Chicago </a> et <a href=\"http://en.wikipedia.org/wiki/Denver\"> Denver </a> ont apporté plusieurs ajustements à leurs systèmes de transport en commun."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VgJ8_9oq1aNz"
   },
   "source": [
    "Transformer un texte automatiquement avec des liens cliquables demande plusieurs traitements au niveau des chaînes de caractères.  Nous nous contenterons dans ce Notebook de trouver les liens sans faire les remplacements directement dans le texte.  Cela nous permettra d'explorer la ressource Wikipedia, et comprendre les difficultés relatives au \"entity linking\" sans perdre trop de temps dans la manipulation complexe de chaînes de caractères.\n",
    "\n",
    "Par exemple, avec le document (index 6), nous voudrions pouvoir lier les entités trouvées par spaCy à la page wikipedia la plus probable donnant accès à de l'information supplémentaire sur cette entité.\n",
    "\n",
    "**Le format ci-bas de liste enrichie est le type de résultat demandé à la question Q6 ci-après.**  Pour simplifier votre code, nous utiliserons ce genre de sortie plutôt que d'avoir les liens directement dans le texte.\n",
    "\n",
    "0: \"Coronavirus Brief\" is a ORG found at http://en.wikipedia.org/wiki/Coronavirus_Brief \\\n",
    "1: \"CBC\" is a ORG found at http://en.wikipedia.org/wiki/CBC \\\n",
    "2: \"Canada\" is a GPE found at http://en.wikipedia.org/wiki/Canada \\\n",
    "3: \"C.D. Howe\" is a PERSON found at http://en.wikipedia.org/wiki/C.D._Howe \\\n",
    "4: ... \\\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DnoLBMST1h5-"
   },
   "source": [
    "**(TO DO) Q6 - 5 points**  \\\n",
    "Écrivez le code nécessaire pour faire la recherche d'une page wikipedia pour les entités trouvées par spaCy (tel qu'illustré ci-haut) dans un document particulier.\n",
    "\n",
    "*Vous pouvez écrire ce code comme vous le souhaitez, mais il faut inclure les éléments suivants :*\n",
    "\n",
    "* (a) Une restriction sur le type d'entités que vous liez. Par exemple, Wikipedia ne contient pas de quantités (tel \"two meters\") il serait alors inadéquat d'inclure un lien vers une quantité.\n",
    "* (b) L'utilisation de la *forme normalisée* de l'entité pour effectuer la liaison. Par exemple, *Allison McGeer* a une page Wikipédia (https://en.wikipedia.org/wiki/Allison_McGeer) vers laquelle vous pouvez créer un lien, même lorsque vous regardez l'entité avec l'étiquette *McGeer*. Assurez-vous donc d'utiliser la fonction que vous avez développée à la Question 4 (Q4).\n",
    "* (c) Attention : la page wikipedia utilise des traits de soulignement. Ainsi, par exemple, *McMaster University* doit être transformé en https://en.wikipedia.org/wiki/McMaster_University (avec un trait de soulignement entre *McMaster* et *University*)\n",
    "* (d) Inclure un élément de post-traitement sur la forme de surface la plus longue trouvée. Par exemple, *the C.D. Howe Institute's* est trouvé par spaCy, mais Wikipédia contiendra *C.D._Howe_Institute*. Vous pouvez supprimer les petites particules comme *the* pour augmenter les chances de lien.\n",
    "* (e) Pour un document à l'entrée, imprimez une liste des formes de surface, type d'entité et lien vers Wikipedia (tel que montré ci-haut)\n",
    "\n",
    "Assurez-vous de mettre des commentaires dans votre code pour indiquer clairement ce qui correspond aux parties (a), (b), (c), (d) et (e).\n",
    "\n",
    "Il y aura probablement de nombreux liens qui mènent vers des pages Wikipedia inexistante.  C'est bon, ne vous inquiétez pas pour ça. Wikipédia ne contient pas tout, et certaines formes normalisées n'y seront pas. On vous demandera de discuter les résultats du linking à la question 7.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cQtDrwKW1aN2"
   },
   "outputs": [],
   "source": [
    "# RÉPONSE Q6 -\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v_7EfNtK1aN2"
   },
   "source": [
    "**(TO DO) Q7 - 5 points**  \n",
    "\n",
    "Effectuez une évaluation qualitative de la méthode de linking d'entités que vous avez écrite en Q6. Pour votre évaluation qualitative, vous devez choisir un document (celui que vous voulez dans le corpus de nouvelles sur Covid-19, et assurez-vous de mentionner lequel) et exécuter votre méthode sur ce document. Répondez aux questions suivantes :\n",
    "\n",
    "* a. Donnez 2 exemples d'entités où la forme plus longue a été trouvée dans Wikipedia. La page trouvée est-elle appropriée ? La forme plus courte serait-elle également trouvée? Serait-elle liée à la même page?\n",
    "* b. Donnez 2 exemples d'entités où la page wikipedia n'existait pas. Pourquoi? La forme recherchée était-elle incorrecte ou l'entité était-elle peu connue (et donc sans page Wikipedia)?\n",
    "* c. Essayez de restreindre votre recherche avec différents types d'entités. Pensez-vous que les DATE sont couvertes par Wikipédia ? Qu'en est-il de PERSON ou de GPE ? Discutez de la couverture des différents types d'entités en donnant des exemples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kQ4MtlmS4nle"
   },
   "source": [
    "**RÉPONSE Q7**\n",
    "\n",
    "...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S41KwFDE1aN7"
   },
   "source": [
    "***SIGNATURE:***\n",
    "Mon nom est --------------------------.\n",
    "Mon numéro d'étudiant(e) est -----------------.\n",
    "J'atteste être l'auteur(e) de ce Notebook."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "CSI4506-KR_Automne2021.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

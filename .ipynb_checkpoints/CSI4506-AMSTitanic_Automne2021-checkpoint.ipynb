{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_vPcs4urY4HF"
   },
   "source": [
    "# Notebook 5 - Prédiction sur le Titanic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FYr8wzAoY4HO"
   },
   "source": [
    "CSI4506 Intelligence Artificielle  \n",
    "Automne 2021  \n",
    "Version 1 (2020) preparée par Joel Muteba, Julian Templeton et Caroline Barrière.  Version 2 (2021) modifiée par Caroline Barrière."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "accIOu8zY4HP"
   },
   "source": [
    "***INTRODUCTION***:\n",
    "\n",
    "La tâche de classification supervisée abordée dans ce notebook est de déterminer si un passager a survécu ou non sur le Titanic. Il s'agit d'un problème d'introduction courant à l'apprentissage machine supervisé et constitue un défi sur un site populaire appelé Kaggle. Kaggle contient des compétitions auxquelles les utilisateurs peuvent participer. Ces compétitions fournissent généralement un ensemble de données et une description du problème à résoudre. Cela dit, tous les ensembles de données n'incluront pas la valeur à prédire pour l'ensemble de test. Ou bien, un concours peut uniquement fournir un ensemble d'entraînement et de validation, pas l'ensemble de test. Cela signifie que les participants ne sauront pas comment leurs modèles fonctionnent sur les données réelles invisibles jusqu'à ce que le ou les hôtes testent la soumission du participant sur l'ensemble de test privé et publient les résultats.\n",
    "\n",
    "Ce notebook enrichira vos connaissances du notebook précédent et présentera le concept de gestion du déséquilibre de classe grâce à l'utilisation d'une technique appelée suréchantillonnage. Vous verrez également comment un ensemble de données peut avoir des problèmes avec ses données et que tous les attributs ne doivent pas être utilisées pour entraîner et tester un modèle. Vous effectuerez également l'entraînement, les tests et l'évaluation de manière légèrement nouvelle puisque nous travaillerons avec un type différent d'ensemble de données.\n",
    "\n",
    "Encore une fois, ce notebook utilise **scikit-learn** (http://scikit-learn.org/stable/), **Matplot**, **Numpy** et **Pandas**. De plus, nous utiliserons **imblearn** qui fournit des techniques robustes pour équilibrer le nombre d'instances de différentes classes. Pour installer ce package, utilisez la commande ***pip install imbalanced-learn***. Si cela pose des problèmes, vous pouvez également essayer *pip install imblearn*.  Comme mentionné dans le notebook précédent, si une installation locale pose un problème, n'hésitez pas à passer à *colab*, un environnement fourni par Google dans lequel vous pouvez exécuter vos notebooks.\n",
    "\n",
    "Dans ce notebook, nous utiliserons l'algorithme Naive Bayes et l'algorithme de régression logistique pour effectuer une classification binaire de la survie (ou non) des passagers du Titanic. Après avoir évalué les deux modèles, vous déterminerez celui qui a le mieux fonctionné et pourquoi. Enfin, vous recommencerez le processus pour déterminer si une technique de suréchantillonnage commune améliorera ou non les résultats obtenus."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ICmG8RMBY4HQ"
   },
   "source": [
    "***DEVOIR***:\n",
    "\n",
    "Parcourez le notebook en exécutant chaque cellule, une à la fois. \\\n",
    "Recherchez **(TO DO)** pour les tâches que vous devez effectuer. Ne modifiez pas le code en dehors des questions auxquelles vous êtes invité à répondre à moins que cela ne vous soit spécifiquement demandé. Une fois que vous avez terminé, signez le notebook (à la fin du notebook), renommez-le NuméroEtudiant-NomFamille-Notebook5.ipynb, et soumettez-le.\n",
    "\n",
    "*Le notebook sera noté sur 30. \\\n",
    "Chaque **(TO DO)** a un certain nombre de points qui lui sont associés.*\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jErxShcIY4HQ"
   },
   "source": [
    "**1. Exploration de l'ensemble de données**   \n",
    "\n",
    "Tout d'abord, nous allons configurer les données avec lesquelles nous travaillerons. Ces données sont incluses avec le notebook et peuvent être trouvées auprès de Kaggle, qui contient également une description des données avec lesquelles nous travaillerons (https://www.kaggle.com/c/titanic/data). \n",
    "\n",
    "Il est fortement recommandé de ***consulter la description des attributs*** dans la section Overview qui est disponible via le lien ci-dessus. Cela vous aidera à comprendre les données avec lesquelles nous travaillerons.\n",
    "\n",
    "Comme évoqué dans l'introduction, ce concours Kaggle ne fournit que des données d'entraînement annotées, tandis que les données de test ne sont pas annotées. Les valeurs de sorties (prédites) de l'ensemble de données de test peuvent être trouvées en ligne, mais nous nous concentrerons uniquement sur l'utilisation de l'ensemble de données d'entraînement pour créer et valider notre modèle.\n",
    "\n",
    "En général, une compétition ne donnera qu'un ensemble d'entraînement, nous essaierons donc de savoir si un passager a survécu ou non sur le Titanic à partir de ces données d'entraînement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zD7VFTKFY4HQ"
   },
   "outputs": [],
   "source": [
    "# Import the required packages for data analysis and machine learning\n",
    "import seaborn as sns\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GN48oMrhY4HS"
   },
   "source": [
    "Tout d'abord, nous allons charger l'ensemble de données d'entraînement (*train.csv*) dans un dataframe avec Pandas et explorer les dix premiers échantillons. Notez que cet ensemble de données contient une variété de colonnes (features) potentielles, contrairement aux critiques de films avec lesquelles nous avons travaillé dans le dernier notebook qui contenait des critiques de films (format textuel) que nous devions transformer. Le présent ensemble de données contient à la fois des valeurs continues et discrètes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "H29pOfWyY4HS"
   },
   "outputs": [],
   "source": [
    "# Read the dataset, show top ten rows\n",
    "X = pd.read_csv(\"train.csv\")\n",
    "X.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G5S1mxecY4HT"
   },
   "source": [
    "De ce qui précède, nous pouvons voir une variété de colonnes. Sur ces colonnes, la colonne ***Survived*** représente les valeurs de classe que nous souhaitons prédire. Un passager a survécu du Titanic si *Survived* vaut 1 et n'a pas survécu du Titanic si *Survived* est 0. Ce sont nos deux classes que nous prédirons (1 et 0). Les autres colonnes représentent des attributs potentiels qui peuvent être utilisées par les algorithmes d'apprentissage machine pour apprendre à prédire avec précision la classe cible.\n",
    "\n",
    "Une remarque importante des données ci-dessus est que tous les échantillons ne contiennent pas de données pour chaque colonne. Par exemple, le passager 6 (Moran, M. James) ne contient pas de valeur pour son *âge* et ne contient pas la *cabine* dans laquelle il résidait. Étant donné que les algorithmes d'apprentissage machine apprennent à partir de données, un expert en apprentissage machine (ou un scientifique des données) devra apprendre à remplir avec précision les données manquantes. Les méthodes robustes pour ce faire dépassent le cadre de ce notebook, mais nous remplirons plus tard la plupart des données manquantes par des moyens simples.\n",
    "\n",
    "Une autre remarque est qu'il est important de déterminer si une classe est vue plus fréquemment qu'une autre classe dans les données. Une classe avec le plus d'instances est appelée la classe *majoritaire* et une classe avec le moins d'instances est appelée la classe *minoritaire*. Si une classe contient plus d'instances qu'une autre classe, l'algorithme peut se concentrer sur l'apprentissage de cette classe majoritaire plus que de la classe minoritaire. Dans des problèmes tels que le diagnostic du cancer, il s'agit d'un problème majeur (car beaucoup plus de personnes n'ont pas de cancer). Ainsi, un autre problème que nous explorerons dans ce notebook est le concept d'utilisation du suréchantillonnage pour équilibrer la distribution des classes. Ce concept sera expliqué en détail plus loin dans le notebook.  \n",
    "\n",
    "Vous trouverez ci-dessous un graphique du nombre d'instances pour chaque classe. Dans ce scénario, sur la base des données disponibles de l'ensemble d'entraînement, plus de personnes n'ont pas survécu sur le Titanic que celles qui ont survécu (comme on pourrait s'y attendre dans ce scénario). Puisque nous ne pouvons pas simplement collecter plus de données sur les passagers qui ont survécu au Titanic, nous devrons réfléchir à des moyens d'équilibrer la répartition des classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mkt9XB82Y4HT"
   },
   "outputs": [],
   "source": [
    "plt.figure() # Creates a new figure\n",
    "X[\"Survived\"].value_counts().plot(kind=\"bar\", title=\"Survived Distribution\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YMssc22sY4HT"
   },
   "source": [
    "Nous allons maintenant déplacer les valeurs de classe (de sortie) du dataframe X de pandas dans un tableau numpy appelé y. X est généralement utilisé pour désigner les attributs d'entrées et y est généralement utilisé pour représenter les valeurs de classe (ou sortie)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IetkU1myY4HT"
   },
   "outputs": [],
   "source": [
    "# This can ONLY BE DONE ONCE, as we pop the values into a new variable to be used as predicted class\n",
    "y = X.pop(\"Survived\").values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iGRx12z5Y4HU"
   },
   "source": [
    "Puisque nous avons examiné la distribution des classes, nous allons maintenant examiner les autres attributs disponibles dans l'ensemble de données. Ci-dessous, nous imprimons une liste de tous les attributs disponibles et explorons les propriétés de la colonne *Embarked* (port d'embarquement des passagers)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zAROUGt3Y4HU"
   },
   "outputs": [],
   "source": [
    "# Show all attributes\n",
    "print(list(X))\n",
    "# Examples of data exploration\n",
    "print(X.shape)\n",
    "print(X['Embarked'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ar9AJb8kY4HU"
   },
   "source": [
    "D'après le résultat ci-dessus, on peut voir que l'attribut *Embarked* contient 644 valeurs *S*, 168 valeurs *C*  et 77 valeurs *Q*. Mais c'est en fait deux de moins que le total de 891 instances. Ainsi, il y a deux valeurs manquantes dans cet attribut. Nous pouvons trouver ces instances via le code ci-dessous:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "42C7kikbY4HU"
   },
   "outputs": [],
   "source": [
    "# Find the rows with a null Embarked value\n",
    "X[X['Embarked'].isnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hJG01TDcY4HU"
   },
   "source": [
    "**(TO DO) Q1 - 2 points**   \n",
    "En vous basant sur l'exemple ci-dessus, explorez les attributs *Age* et *Cabin* en imprimant les valeurs possibles qu'ils contiennent. Notez que lorsqu'un attribut contient trop de valeurs possibles (e.g. Age), seulement les premières et dernières valeurs seront affichées (et des ... entre les deux). \n",
    "\n",
    "Imprimez aussi les lignes de l'ensemble d'entraînement où des valeurs sont manquantes pour ces attributs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q7TOP_0NY4HV"
   },
   "outputs": [],
   "source": [
    "# RÉPONSE Q1: For the Age attribute\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bei3DGr5Y4HV"
   },
   "outputs": [],
   "source": [
    "# RÉPONSE Q1: For the Cabin attribute\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8vTX9wBcY4HV"
   },
   "source": [
    "**2. Nettoyage des données**    \n",
    "\n",
    "Après avoir exploré l'ensemble de données, nous allons maintenant travailler sur le nettoyage de certaines des valeurs manquantes dans les attributs que nous utiliserons pour les algorithmes d'apprentissage machine.  Nous regarderons par la suite les attributs discrets et continus.\n",
    "\n",
    "***2.1. Valeurs manquantes***\n",
    "\n",
    "Tentons de remplir les valeurs manquantes pour les attributs *Age* et *Embarked*. Bien qu'il soit également possible de le faire pour l'attribut *Cabin*, cet attribut nécessite des précautions supplémentaires lors du remplissage de ses valeurs manquantes. Ainsi, ce notebook n'explorera pas l'attribut *Cabin* malgré son importance (puisque la localisation du passager est un identifiant important pour savoir s'il a survécu ou non).\n",
    "\n",
    "Pour votre propre intérêt, l'article suivant fait un bon travail en discutant de certaines des méthodes disponibles pour l'*imputation*: https://towardsdatascience.com/how-to-handle-missing-data-8646b18db0d4. Notez que le terme *imputation* fait référence au processus de remplissage des valeurs manquantes.  Mais pour notre notebook, nous utiliserons des méthodes triviales d'imputation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RP1K7Q4tY4HV"
   },
   "source": [
    "Pour l'attribut *Age*, nous remplirons les valeurs manquantes avec **l'âge moyen** des passagers qui contiennent une valeur d'âge non nulle. Bien que cela causera probablement des problèmes, comme faire apprendre à l'algorithme des modèles inexacts à partir des valeurs d'âge moyennes, il s'agit de l'une des nombreuses approches trivales pour remplir les données manquantes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3BEXUpWeY4HV"
   },
   "outputs": [],
   "source": [
    "# Update the dataframe by filling in all missing age values as the mean of existing age values.\n",
    "X[\"Age\"].fillna(X[\"Age\"].mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gGrXA7tnY4HV"
   },
   "source": [
    "Pour l'attribut Embarqué, nous utiliserons également une approche triviale. Nous allons simplement faire un **choix aléatoire** entre les trois possibilités ('S', 'C', 'Q')."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tD4sAoSWY4HW"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "poss = X['Embarked'].value_counts().index.tolist()\n",
    "print(poss)\n",
    "X[\"Embarked\"].fillna(random.choice(poss), inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6FuGXa0KY4HW"
   },
   "source": [
    "***2.2 Attributs discrets et continus***\n",
    "\n",
    "Avant de sélectionner les attributs à utiliser, nous convertirons les données catégorielles (attributs discrets) dans les colonnes *Sex* et *Embarked* en numériques. Cela se fera via un le one-hot-encoding, où chaque valeur catégorielle possible pour un attribut devient son propre attribut. Ensuite, un seul de ces trois attributs contiendra la valeur 1 pour une ligne, où les autres contiennent 0. Dans le prochain notebook, nous explorerons le OneHotEncoder fourni par sklearn, mais nous traiterons cela manuellement dans ce notebook (via la fonction *get_dummies*).\n",
    "\n",
    "Cet encodage one-hot sera nécessaire pour le classificateur de type régression logistique (que nous utiliserons plus tard). Nous utiliserons également plus tard un classificateur Naive Bayes qui fonctionne bien sur les attributs discrets, mais son implémentation dans sklearn incorpore un bin-splitting (discrétisation), et donc si tous nos attributs sont numériques, ça ira."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HVMdqaSvY4HX"
   },
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lVsYoC0jY4HX"
   },
   "outputs": [],
   "source": [
    "# Convert the categorical values stored within the Sex column to be numerical via One-Hot-Encoding\n",
    "X = pd.concat([X, pd.get_dummies(X['Sex'], prefix='Sex')], axis=1)\n",
    "# Drop the original column\n",
    "X.drop(['Sex'], axis=1, inplace=True)\n",
    "# Convert the categorical values stored within the Embarked column to be numerical via One-Hot-Encoding\n",
    "X = pd.concat([X, pd.get_dummies(X['Embarked'], prefix='Embarked')], axis=1)\n",
    "# Drop the original column\n",
    "X.drop(['Embarked'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Nx6Zx7wdY4HX"
   },
   "source": [
    "Jetons un dernier coup d'œil aux 5 premières entrées de notre ensemble de données. Regardez en quoi les colonnes diffèrent de la sortie ci-dessus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8V_5fHujY4HX"
   },
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i_tSlhXdY4HX"
   },
   "source": [
    "**3. Sélection des attributs et définition des ensembles de test et validation**    \n",
    "\n",
    "Maintenant que les données sont prêtes à être utilisées, nous allons maintenant sélectionner les attributs avec lesquels nous allons travailler et définir les ensembles d'entraînement et de validation à partir des données disponibles. Pour notre sélection d'attributs, nous sélectionnerons simplement tous les attributs non nuls à l'exception de *PassengerId*, *Ticket* et *Name*.\n",
    "\n",
    "*PassengerId* est un numéro unique pour chaque passager et ne peut donc pas permettre de généralisation utile à un modèle prédictif. Il est également peu probable que les noms (attribut *Name*) permettent de savoir si un passager a survécu ou non.\n",
    "\n",
    "*Ticket* est une valeur qui ne semble pas non plus fournir d'informations utiles, et par conséquent, nous ne l'utiliserons pas.\n",
    "\n",
    "Regardons s'il reste encore des attributs avec des valeurs manquantes parmi les attributs choisis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j-OPaPWmY4HX"
   },
   "outputs": [],
   "source": [
    "# Look at what is null\n",
    "X.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VEvc2evNY4HX"
   },
   "source": [
    "Comme nous pouvons le voir, tous les attributs à l'exception de *Cabin* ne contiennent aucune valeur manquante. Bien que *Cabin* soit important, nous l'exclurons car nous ne l'avons pas correctement nettoyé et il manque une valeur à la majorité des données. Bien que nous puissions ignorer toutes les lignes qui ne contiennent pas de valeur *Cabin* ou que nous puissions attribuer une valeur «inconnue» aux valeurs manquantes, il y a trop de valeurs manquantes pour que cela soit raisonnable.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a3flpT8NY4HX"
   },
   "outputs": [],
   "source": [
    "# Define the list of attributes to use as features for the algorithms.\n",
    "featureSet = ['Pclass', 'Sex_female', 'Sex_male', 'Age', 'SibSp', \n",
    "              'Parch', 'Fare', 'Embarked_C', 'Embarked_Q', 'Embarked_S']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ki65ftHvY4HX"
   },
   "outputs": [],
   "source": [
    "# Set the dataframe to only contain the desired variables\n",
    "X = X[featureSet].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cfoOLGqtY4HY"
   },
   "source": [
    "Une fois les attributs sélectionnées, nous allons maintenant diviser les données en un ensemble d'entraînement et de validation à partir des données disponibles. Malgré le nom \"train_test_split\" de sklearn, nous savons qu'il s'agit d'une division de l'ensemble original d'entrainement en ensemble d'entrainement et de validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2qqb9O-pY4HY"
   },
   "outputs": [],
   "source": [
    "# split the large dataset into train and test\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size = 0.2, random_state=2)\n",
    "# Look at the shape of the outputs\n",
    "print(X_train.shape)\n",
    "print(y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2daoErGNY4HY"
   },
   "outputs": [],
   "source": [
    "# Look at the training set\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yA8-H_xjY4HY"
   },
   "outputs": [],
   "source": [
    "# Look at the validation set\n",
    "X_val.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fA_5bgUkg15T"
   },
   "source": [
    "**Comprendre les relations entre les attributs par la visualisation des données :** \\\n",
    "Nous pouvons continuer à analyser les attributs en utilisant des visualisations. Les histogrammes peuvent nous aider à visualiser la relation entre différentes caractéristiques, telles que l'âge et le genre dans la figure ci-dessous.  Dans les 2 figures ci-dessous, nous voyons une distribution légèrement différente entre les hommes et les femmes, en lien à l'âge.  Chez les hommes, cette distribution est relativement uniforme (sauf pour un pic vers 30 ans), mais pour les femmes, il y a une plus grande proportion entre 18 et 30 ans.  La visualisation aide pour se donner rapidement une idée des distributions des attributs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pHQUeTW8hZGE"
   },
   "outputs": [],
   "source": [
    "# Y = pd.read_csv(\"train.csv\")\n",
    "data_vis= sns.FacetGrid(X_train, col='Sex_female')\n",
    "data_vis.map(plt.hist, 'Age', bins=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PyxiGCI_hhl0"
   },
   "source": [
    "**(TO DO) Q2 - 2 points** \\\n",
    "(partie a) Utilisez la visualisation des données (comme ci-dessus) pour montrer la relation entre :\n",
    "\n",
    "1. Genre et tarif payé (fare).\n",
    "2. Genre et port d'embarquement (embarked C, Q or S).\n",
    "\n",
    "Discutez (partie b) de ce que les histogrammes montrent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xF6MpeSgh5GT"
   },
   "outputs": [],
   "source": [
    "# RÉPONSE Q2 (part a):\n",
    "#data_vis=....."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LT_zX9l2h8Vx"
   },
   "source": [
    "**RÉPONSE Q2 - partie b**\\\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t4o9AKFUY4HY"
   },
   "source": [
    "**4. Techniques d'évaluation**    \n",
    "\n",
    "Maintenant que nous avons notre ensemble d'entraînement et de validation, nous sommes presque prêts à apprendre des modèles avec divers algorithmes d'apprentissage.  Mais une fois ces modèles appris, nous voudrons les évaluer.  Donc définissons d'abord nos mesures d'évaluation.\n",
    "\n",
    "Plus tard, nous utiliserons davantage de techniques d'évaluation pour mieux évaluer les performances des modèles. Pour l'instant, nous allons définir des fonctions pour calculer les métriques *Précision*, *Rappel* et *Accuracy*. \n",
    "\n",
    "Précision et rappel ont été abordés dans le notebook précédent. L'accuracy représente le pourcentage de classifications correctement effectuées par le modèle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "s7eKN-CpY4HY"
   },
   "outputs": [],
   "source": [
    "def precision(actualTags, predictions, classOfInterest):\n",
    "    '''\n",
    "    Calculates the precision for a specific class, given the ground truth and predicted values.\n",
    "    '''\n",
    "    totalFound = 0\n",
    "    for i in range(len(actualTags)):\n",
    "        if (actualTags[i] == classOfInterest and actualTags[i] == predictions[i]):\n",
    "            totalFound += 1\n",
    "    return totalFound / np.count_nonzero(predictions == classOfInterest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QDeweNfHY4HY"
   },
   "outputs": [],
   "source": [
    "def recall(actualTags, predictions, classOfInterest):\n",
    "    '''\n",
    "    Calculates the recall for a specific class, given the ground truth and predicted values.\n",
    "    '''\n",
    "    totalFound = 0\n",
    "    for i in range(len(actualTags)):\n",
    "        if (actualTags[i] == classOfInterest and actualTags[i] == predictions[i]):\n",
    "            totalFound += 1\n",
    "    return totalFound / np.count_nonzero(actualTags == classOfInterest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JCDm2q8XY4HY"
   },
   "outputs": [],
   "source": [
    "def accuracy(actualTags, predictions):\n",
    "    '''\n",
    "    Calculates the average number of correct predictions.\n",
    "        - actualTags: The ground truth\n",
    "        - predictions: What the model predicts\n",
    "    '''\n",
    "    totalFound = 0\n",
    "    for i in range(len(actualTags)):\n",
    "        if (actualTags[i] == predictions[i]):\n",
    "            totalFound += 1\n",
    "    return totalFound / len(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jbahpyAaY4HY"
   },
   "outputs": [],
   "source": [
    "# Example of calculating accuracy\n",
    "accuracy([0, 1, 1, 1, 0], [1, 1, 1, 0, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GvdaPGUeY4HY"
   },
   "source": [
    "**5. Naive Bayes**    \n",
    "\n",
    "Avec les données prétraitées et plusieurs fonctions d'évaluation définies, nous sommes maintenant prêts à utiliser certains algorithmes d'apprentissage machine pour effectuer les prédictions permettant de savoir si un passager a survécu ou non sur le Titanic.\n",
    "\n",
    "La première approche que nous utiliserons est l'algorithme Naive Bayes fourni par scikit-learn. Ce sera un processus très similaire à ce que vous avez fait dans le notebook 4. Vous entraînerez le modèle en appelant la fonction *fit* et récupérerez les prédictions du modèle en appelant la fonction *predict*. Contrairement au dernier notebook, nous avons déjà toutes nos données prétraitées en tant qu'attributs numériques dans un dataframe pandas, avec les étiquettes de classe sous forme de tableaux numpy (y_train et y_val). Ainsi, nous n'aurons pas besoin d'effectuer des transformations, telles que celles qui ont été effectuées dans le notebook 3.\n",
    "\n",
    "La première tâche consiste à entraîner le modèle avec la fonction .fit()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Bstnr7rfY4HY"
   },
   "outputs": [],
   "source": [
    "# Train the model with the training set by calling the .fit() function\n",
    "# X_train contains the features used to train the model\n",
    "# y_train contains the class labels for the samples from X_train\n",
    "clf_nb = MultinomialNB().fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WJc93qfkY4HZ"
   },
   "source": [
    "Nous pouvons ensuite voir comment l'algorithme fonctionne lors de la prédiction des échantillons dans l'ensemble d'apprentissage via le code suivant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-ore5s_2Y4HZ"
   },
   "outputs": [],
   "source": [
    "print(\"Comparing the first ten actual values to the predicted values:\")\n",
    "# Print the first ten class labels for the training set\n",
    "print(y_train[0:10])\n",
    "# Predict whether the passengers did or did not survive the Titanic on the training set\n",
    "nb_train_predictions = clf_nb.predict(X_train)\n",
    "# Print the first ten predictions\n",
    "print(nb_train_predictions[0:10])\n",
    "print(\"Calculating the total accuracy for the training set:\")\n",
    "print(accuracy(y_train, nb_train_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h5f50uyyY4HZ"
   },
   "source": [
    "D'après ce qui précède, nous pouvons voir qu'après avoir été entraîné, le modèle peut prédire correctement un peu moins de 70% de tous les échantillons de l'ensemble d'apprentissage. Mais comment fonctionne-t-il sur l'ensemble de validation?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RYSvonFkY4HZ"
   },
   "source": [
    "**(TO DO) Q3 - 3 points**   \n",
    "En suivant l'exemple fourni ci-dessus, obtenez les prédictions du modèle Naive Bayes sur l'ensemble de validation (X_val, y_val) et imprimez la précision, le rappel et l'accuracy de l'ensemble de validation (pour la précision et le rappel, nous regardons les deux classes, 1 et 0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gMZSLBcjY4HZ"
   },
   "outputs": [],
   "source": [
    "# RÉPONSE Q3\n",
    "\n",
    "# Get the predictions for the validation set\n",
    "nb_val_predictions = ...\n",
    "# Retrieve and print the precision values for class 1 and class 0\n",
    "print(\"Precision when class = 0: \" + ...)\n",
    "print(\"Precision when class = 1: \" + ...)\n",
    "# Retrieve and print the recall values for class 1 and class 0\n",
    "print(\"Recall when class = 0: \" + ...)\n",
    "print(\"Recall when class = 1: \" + ...)\n",
    "# Retrieve and print the accuracy for the model\n",
    "print(\"Accuracy: \" + ...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VFlFGMJuY4HZ"
   },
   "source": [
    "**6. Régression Logistique**    \n",
    "\n",
    "Nous allons essayer d'utiliser un autre algorithme d'apprentissage machine qui peut ou non fonctionner mieux que l'approche Naive Bayes. Plus précisément, nous utiliserons l'algorithme d'apprentissage machine de régression logistique pour prédire qui a survécu et n'a pas survécu sur le Titanic.\n",
    "\n",
    "Puisque l'algorithme de régression logistique que nous allons utiliser provient également de scikit-learn, le processus général sera presque identique à ce que nous avons fait pour le classificateur Naive Bayes. La principale différence est que nous allons maintenant utiliser un algorithme différent contenant certaines options que nous devrons définir. Tous les détails des façons possibles d'ajuster le modèle de régression logistique sont disponibles [ici](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html).\n",
    "\n",
    "Nous allons d'abord initialiser et entraîner le modèle avec les données d'apprentissage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fRp6mYVeY4HZ"
   },
   "outputs": [],
   "source": [
    "# Train the model with the training set by calling the .fit() function\n",
    "# X_train contains the features used to train the model\n",
    "# y_train contains the class labels for the samples from X_train\n",
    "clf_lr = LogisticRegression(solver='lbfgs', max_iter=1000, random_state=1).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "79Fvd242Y4HZ"
   },
   "source": [
    "Ensuite, nous verrons comment le modèle fonctionne sur les données d'entraînement pour avoir une idée de la façon dont l'entraînement s'est déroulé. Puisque nous nous sommes entraînés sur ces données, nous espérons obtenir des résultats solides."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R8hV1eC7Y4HZ"
   },
   "outputs": [],
   "source": [
    "print(\"Comparing the first ten actual values to the predicted values:\")\n",
    "# Print the first ten class labels for the training set\n",
    "print(y_train[0:10])\n",
    "# Predict whether the passengers did or did not survive the Titanic on the training set\n",
    "lr_train_predictions = clf_lr.predict(X_train)\n",
    "# Print the first ten predictions\n",
    "print(lr_train_predictions[0:10])\n",
    "print(\"Calculating the total accuracy for the training set:\")\n",
    "print(accuracy(y_train, lr_train_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VKlMz6SoY4HZ"
   },
   "source": [
    "**(TO DO) Q4 - 3 points**   \n",
    "En suivant l'exemple fourni ci-dessus, obtenez les prédictions du modèle de régression logistique sur l'ensemble de validation (X_val, y_val) et imprimez la précision, le rappel et l'accuracy de l'ensemble de validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3ELtGPFFY4HZ"
   },
   "outputs": [],
   "source": [
    "# RÉPONSE Q4\n",
    "\n",
    "# Get the predictions for the validation set\n",
    "lr_val_predictions = ...\n",
    "# Retrieve and print the precision values for class 1 and class 0\n",
    "print(\"Precision when class = 0: \" + ...)\n",
    "print(\"Precision when class = 1: \" + ...)\n",
    "# Retrieve and print the recall values for class 1 and class 0\n",
    "print(\"Recall when class = 0: \" + ...)\n",
    "print(\"Recall when class = 1: \" + ...)\n",
    "# Retrieve and print the accuracy for the model\n",
    "print(\"Accuracy: \" + ...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8qJdjlh-Y4Ha"
   },
   "source": [
    "**7. Plus de techniques d'évaluation**    \n",
    "\n",
    "Maintenant que vous avez entraîné et testé les modèles ci-dessus, vous allez définir deux méthodes d'évaluation supplémentaires. La première sera la micro-moyenne sur les précisions et la seconde sera la macro-moyenne sur les précisions. Les définitions de ces méthodes ont été présentées dans le Module 4 sur l'apprentissage machine (partie 4 - Évaluation).\n",
    "\n",
    "Bien que nous puissions également définir la micro-moyenne et la macro-moyenne pour les rappels, nous ne le ferons pas pour ce notebook afin d'éviter d'avoir trop de mesures d'évaluation à prendre en compte. En réalité, chaque ensemble de données aura des critères d'évaluation qui sont plus ou moins importants en fonction du problème."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xf9ct03XY4Ha"
   },
   "source": [
    "**(TO DO) Q5 - 2 points**   \n",
    "\n",
    "Dans la cellule ci-dessous, complétez la définition de la fonction micro_precision_average. Vous devez utiliser uniquement les paramètres fournis et ne pouvez utiliser aucune fonctionnalité de la bibliothèque de scikit-learn.  Il serait plus facile d'utiliser les fonctions de sklearn, mais le but ici est d'apprendre comment les écrire."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OctqeDRXY4Ha"
   },
   "outputs": [],
   "source": [
    "# RÉPONSE Q5 - \n",
    "def micro_precision_average(actualTags, predictions, class1, class2):\n",
    "    '''\n",
    "    Calculates the Micro-average on precisions.\n",
    "        - actualTags: The ground truth\n",
    "        - predictions: The predicted class values\n",
    "        - class1: The value of the first class\n",
    "        - class2: The value of the second class\n",
    "    '''\n",
    "    ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IdIiYcs9Y4Ha"
   },
   "source": [
    "**(TO DO) Q6 - 2 points**   \n",
    "Dans la cellule ci-dessous, complétez la définition de la fonction macro_precision_average. Vous devez utiliser uniquement les paramètres fournis et ne pouvez utiliser aucune fonctionnalité de la bibliothèque de scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jEAF6xRjY4Ha"
   },
   "outputs": [],
   "source": [
    "# RÉPONSE Q6 - \n",
    "def macro_precision_average(actualTags, predictions, class1, class2):\n",
    "    '''\n",
    "    Calculates the Macro-average on precisions.\n",
    "        - actualTags: The ground truth\n",
    "        - predictions: The predicted class values\n",
    "        - class1: The value of the first class\n",
    "        - class2: The value of the second class\n",
    "    '''\n",
    "    ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fmi4uEXUY4Ha"
   },
   "source": [
    "**(TO DO) Q7 - 2 points**   \n",
    "Pour tester ces fonctions d'évaluation, évaluez la micro-moyenne et la macro-moyenne sur les précisions de vos tests sur l'ensemble de validation avec les modèles Naive Bayes et de régression logistique. Imprimez les résultats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Z5LioWfUY4Ha"
   },
   "outputs": [],
   "source": [
    "# RÉPONSE Q7 - \n",
    "\n",
    "print(\"For Naive Bayes:\")\n",
    "...\n",
    "print(\"For Logistic Regression:\")\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tnYAo_XvY4Ha"
   },
   "source": [
    "**8. Discussion**    \n",
    "\n",
    "Comme pour toutes les expériences d'apprentissage machine, nous devons utiliser les résultats obtenus pour comprendre quel modèle est le meilleur et pourquoi. Dans ce scénario, nous avons les valeurs de précision, de rappel, de moyenne, de micro-moyenne de précisionn et de macro-moyenne de précision."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ePwJ-bAPY4Ha"
   },
   "source": [
    "**(TO DO) Q8 (a) - 2 points**   \n",
    "Copiez les sorties pour la précision, le rappel, l'accuracy, la micro-moyenne et la macro-moyenne obtenues pour les deux modèles dans le tableau ci-dessous (uniquement à partir des résultats sur l'ensemble de validation). Entrez chaque valeur dans la balise <td\\> </td\\> correspondante. Pour chaque approche d'évaluation, indiquez quel modèle d'apprentissage machine fournit les meilleurs résultats."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zY9dr0IfY4Ha"
   },
   "source": [
    "**ANSWER Q8 - partie (a)**\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <td></td>\n",
    "        <td><strong>Naive Bayes</strong></td>\n",
    "        <td><strong>Régression Logistique</strong></td>\n",
    "        <td><strong>Meilleur modèle</strong></td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td><strong>Précision (classe=0)</strong></td>\n",
    "        <td></td>\n",
    "        <td></td>\n",
    "        <td></td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td><strong>Précision (classe=1)</strong></td>\n",
    "        <td></td>\n",
    "        <td></td>\n",
    "        <td></td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td><strong>Rappel (classe=0)</strong></td>\n",
    "        <td></td>\n",
    "        <td></td>\n",
    "        <td></td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td><strong>Rappel (classe=1)</strong></td>\n",
    "        <td></td>\n",
    "        <td></td>\n",
    "        <td></td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td><strong>Accuracy</strong></td>\n",
    "        <td></td>\n",
    "        <td></td>\n",
    "        <td></td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td><strong>Micro-moyenne précision</strong></td>\n",
    "        <td></td>\n",
    "        <td></td>\n",
    "        <td></td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td><strong>Macro-moyenne précision</strong></td>\n",
    "        <td></td>\n",
    "        <td></td>\n",
    "        <td></td>\n",
    "    </tr>    \n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xPz8adNMY4Ha"
   },
   "source": [
    "**(TO DO) Q8 (b) - 2 points**   \n",
    "D'après vos résultats, quel modèle est le plus performant pour prédire si un passager survit ou non sur le Titanic? Justifiez votre réponse."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qwEZS_UBY4Ha"
   },
   "source": [
    "**RÉPONSE Q8 - partie b** \\\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ww1rnLVrY4Hb"
   },
   "source": [
    "**9. Équilibrer la distribution des classes**    \n",
    "\n",
    "Comme mentionné au début du notebook, cet ensemble d'entraînement contient plus de passagers qui n'ont pas survécu sur le Titanic que ceux qui ont survécu. Il en résulte un déséquilibre de classe où la classe majoritaire (0) contient plus d'instances que la classe minoritaire (1). Il existe de nombreuses méthodes pour gérer ce problème. Une méthode consiste simplement à prendre la classe minoritaire et, grâce à une méthode, à produire plus d'instances de cette classe. Par exemple, une méthode triviale pourrait consister à sélectionner au hasard un nombre d'instances et à les dupliquer pour correspondre au nombre d'instances de la classe majoritaire. Ce concept est appelé * suréchantillonnage *. Vous pouvez également supprimer des instances de la classe majoritaire pour équilibrer la distribution de classe (appelée * sous-échantillonnage *).\n",
    "\n",
    "Pour ce notebook, le suréchantillonnage sera effectué via l'implémentation par imblearn d'une technique appelée SMOTE. Comprendre SMOTE dépasse le cadre de ce notebook, mais plus d'informations peuvent être trouvées [ici](https://machinelearningmastery.com/smote-oversampling-for-imbalanced-classification/). La chose importante à comprendre est que le nombre d'instances pour chaque valeur de classe sera le même en créant artificiellement de nouvelles instances de passagers ayant survécu au Titanic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2izi_4L6Y4Hb"
   },
   "outputs": [],
   "source": [
    "# Define the SMOTE instance\n",
    "smote = SMOTE(random_state=0, sampling_strategy=\"minority\")\n",
    "# Retrieve the oevrsampled data\n",
    "X_os, y_os = smote.fit_sample(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vFdtoLIXY4Hb"
   },
   "source": [
    "\n",
    "Notez que l'ensemble de données suréchantillonné est maintenant défini dans X_os et y_os, et non dans X et y. Nous utiliserons ces valeurs pour le reste du notebook. Ci-dessous, nous examinons maintenant combien d'instances de notre nouvel ensemble de données contiennent la classe 0 et combien contiennent la classe 1. Ces valeurs sont maintenant équilibrées par rapport au graphique présenté dans la section 1 de ce notebook. Notez que X_os est maintenant un tableau numpy plutôt qu'une dataframe en raison de cette conversion. Cela ne change rien à la façon dont nous l'utilisons, mais change la méthode de traçage (graphique) des données."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "W-Z-mt9yY4Hb"
   },
   "outputs": [],
   "source": [
    "# Print the number of instances for each class\n",
    "class_names, totals = np.unique(y_os, return_counts=True)\n",
    "print(str(class_names[0]) + \" contains \" + str(totals[0]) + \" instances.\")\n",
    "print(str(class_names[1]) + \" contains \" + str(totals[1]) + \" instances.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CZ4m31gBY4Hb"
   },
   "source": [
    "Avec l'ensemble de données suréchantillonné, nous allons maintenant définir nos nouveaux ensembles de train et de validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Mh1nopndY4Hb"
   },
   "outputs": [],
   "source": [
    "# split the large dataset into train and test\n",
    "X_train_os, X_val_os, y_train_os, y_val_os = train_test_split(X_os, y_os, test_size = 0.2, random_state=2)\n",
    "# Look at the shape of the outputs\n",
    "print(X_train_os.shape)\n",
    "print(y_val_os.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NwUn3fepY4Hb"
   },
   "source": [
    "Avec tout cela défini, nous allons maintenant entraîner et tester un nouveau modèle Naive Bayes et de régression logistique, évaluer les modèles et déterminer si le suréchantillonnage a donné de meilleurs résultats que sans le suréchantillonnage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "beTH0GViY4Hb"
   },
   "source": [
    "**(TO DO) Q9 - 10 points au total**   \n",
    "Répétez l'expérience d'apprentissage machine effectuée dans les sections précédentes sur les nouvelles données suréchantillonnées. Assurez-vous d'utiliser les noms appropriés (***ne pas oublier les _os dans les noms*** pour éviter les solutions incorrectes)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sQ1acInDY4Hb"
   },
   "source": [
    "**(TO DO) Q9 (a) - 3 points**   \n",
    "Entraîner, tester et évaluer l'ensemble de validation (avec toutes les métriques d'évaluation) avec un classificateur Naive Bayes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bFlSpKxVY4Hb"
   },
   "outputs": [],
   "source": [
    "# RÉPONSE: Q9 (a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qRM39K5VY4Hb"
   },
   "source": [
    "**(TO DO) Q9 (b) - 3 points**   \n",
    "Entraîner, tester et évaluer l'ensemble de validation (avec toutes les métriques d'évaluation) avec un classificateur régression logistique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2a2fTZwEY4Hb"
   },
   "outputs": [],
   "source": [
    "# RÉPONSE: Q9 (b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KJLBOFqWY4Hb"
   },
   "source": [
    "**(TO DO) Q9 (c) - 2 points**   \n",
    "Comparez les résultats entre les deux expériences ci-dessus (de Q9 (a) et Q9 (b)), quel modèle est le meilleur et pourquoi?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UMWbMNdmY4Hc"
   },
   "source": [
    "**RÉPONSE Q9 - partie c** \\\n",
    "   \n",
    "<table>\n",
    "    <tr>\n",
    "        <td></td>\n",
    "        <td><strong>Naive Bayes (avec suréchantillonnage) </strong></td>\n",
    "        <td><strong>Régression Logistique (avec suréchantillonnage) </strong></td>\n",
    "        <td><strong>Meilleur modèle</strong></td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td><strong>Précision (classe=0)</strong></td>\n",
    "        <td></td>\n",
    "        <td></td>\n",
    "        <td></td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td><strong>Précision (classe=1)</strong></td>\n",
    "        <td></td>\n",
    "        <td></td>\n",
    "        <td></td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td><strong>Rappel (classe=0)</strong></td>\n",
    "        <td></td>\n",
    "        <td></td>\n",
    "        <td></td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td><strong>Rappel (classe=1)</strong></td>\n",
    "        <td></td>\n",
    "        <td></td>\n",
    "        <td></td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td><strong>Accuracy</strong></td>\n",
    "        <td></td>\n",
    "        <td></td>\n",
    "        <td></td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td><strong>Micro-moyenne précision</strong></td>\n",
    "        <td></td>\n",
    "        <td></td>\n",
    "        <td></td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td><strong>Macro-moyenne précision</strong></td>\n",
    "        <td></td>\n",
    "        <td></td>\n",
    "        <td></td>\n",
    "    </tr>    \n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1H3ouqeOY4Hc"
   },
   "source": [
    "TODO: ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ss_f_Ax8Y4Hc"
   },
   "source": [
    "**(TO DO) Q9 (d) - 2 points**   \n",
    "Le modèle sélectionné à partir de Q9 (c) fonctionne-t-il mieux ou moins bien que le modèle sélectionné à Q8 (b)? Cela signifie-t-il que le suréchantillonnage aide l'apprentissage machine à mieux ou moins bien apprendre dans ce scénario? Justifiez votre réponse.\n",
    "\n",
    "Remarque: il n'est pas nécessaire de mettre toutes les données dans un autre tableau (vous pouvez certainement le faire si vous souhaitez mieux l'organiser). Fournissez simplement les réponses et les justifications expliquant pourquoi."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mRdGXLBiY4Hc"
   },
   "source": [
    "**RÉPONSE Q9 - partie d** \\\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b5o0YikFY4Hc"
   },
   "source": [
    "***SIGNATURE:***\n",
    "Mon nom est --------------------------.\n",
    "Mon numéro d'étudiant(e) est -----------------.\n",
    "Je certifie être l'auteur(e) de ce devoir."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "CSI4506-AMSTitanic_Automne2021.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
